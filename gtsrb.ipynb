{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gtsrb.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjkioY9RNaVkCO9fGJy2xD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiwNim15/ML-projects/blob/main/gtsrb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkW-FUmzYbZP",
        "outputId": "c94b0d0d-dcdd-4fce-f9dc-b15017cb1f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.1.0`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ]
        }
      ],
      "source": [
        "#Importing essential libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import math\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import pathlib\n",
        "\n",
        "#Tensorflow stable version\n",
        "%tensorflow_version 2.1.0\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from tensorflow.keras.initializers import he_normal, zeros, glorot_normal, RandomNormal\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
        "\n",
        "#Fixing python random seed\n",
        "random.seed(42)\n",
        "#fixing numpy random seed\n",
        "np.random.seed(21)\n",
        "#fixing tensorflow random seed\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_dataset_from_kaggle() :\n",
        "  '''\n",
        "  This function downloads the German traffic sign\n",
        "  dataset from kaggle and stores it in temporary\n",
        "  session memory of google colab and unzips it.\n",
        "  '''\n",
        "  #Upload the kaggle api token\n",
        "  print('Please upload the kaggle api token :')\n",
        "  files.upload() #this will prompt you to update the json\n",
        "  !pip install -q kaggle\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !ls ~/.kaggle\n",
        "  !chmod 600 /root/.kaggle/kaggle.json  # set permission\n",
        "\n",
        "  #Downloading and unzipping the dataset\n",
        "  !kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
        "  !unzip -q /content/gtsrb-german-traffic-sign.zip -d Data\n",
        "  \n",
        "\n",
        "#Calling the function\n",
        "download_dataset_from_kaggle()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "SzSp0Z6nbQ16",
        "outputId": "945652bb-1add-4673-9adf-c37a2fa5a465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the kaggle api token :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c848c8e2-d27e-4436-a807-16de97ec186e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c848c8e2-d27e-4436-a807-16de97ec186e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "kaggle.json\n",
            "Downloading gtsrb-german-traffic-sign.zip to /content\n",
            " 98% 601M/612M [00:22<00:00, 26.0MB/s]\n",
            "100% 612M/612M [00:22<00:00, 28.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this only once\n",
        "#Creating validation directory\n",
        "val_dir = \"/content/Data/Validation\"\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "n_classes = 43\n",
        "train_dir = \"/content/Data/Train{0}\"\n",
        "\n",
        "#Moving files from train to validation directory\n",
        "for n in tqdm(range(n_classes)) :\n",
        "  path = os.path.join(val_dir, str(n))\n",
        "  os.mkdir(path)\n",
        "  src_path = train_dir.format('/' + str(n))\n",
        "  files = os.listdir(src_path)\n",
        "  rand_idx = random.sample(range(len(files)), math.ceil(len(files)/4))\n",
        "  for idx in rand_idx :\n",
        "    src = src_path + \"/\" + files[idx]\n",
        "    shutil.move(src, path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DRdmvJobqGc",
        "outputId": "3835f55c-9101-4e83-ec89-ad2f0bf7cdf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 43/43 [00:00<00:00, 80.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up variables\n",
        "IMG_WIDTH = 30\n",
        "IMG_HEIGHT = 30\n",
        "N_CHANNELS = 3\n",
        "BATCH_SIZE = 32\n",
        "N_EPOCHS = 200\n",
        "VAL_BATCH_SIZE = 32\n",
        "CLASS_NAMES = list(range(43))\n",
        "N_CLASSES = 43\n",
        "train_path = \"/content/Data/Train\"         #Train dataset path\n",
        "val_path = \"/content/Data/Validation\"      #Validation dataset path\n",
        "\n",
        "\n",
        "#Path to train and validation datasets\n",
        "data_root_train = pathlib.Path(train_path)\n",
        "data_root_val = pathlib.Path(val_path)\n",
        "\n",
        "#Getting paths to all the images in train and validation sets\n",
        "all_image_paths_train = list(data_root_train.glob('*/*'))\n",
        "all_image_paths_train = [str(path) for path in all_image_paths_train]\n",
        "\n",
        "all_image_paths_val = list(data_root_val.glob('*/*'))\n",
        "all_image_paths_val = [str(path) for path in all_image_paths_val]\n",
        "\n",
        "#Counting number of images in each sets\n",
        "image_count_train = len(all_image_paths_train)\n",
        "image_count_val = len(all_image_paths_val)"
      ],
      "metadata": {
        "id": "ZVKvZ0Fmbwoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting labels for each image\n",
        "label_names_train = sorted(int(item.name) for item in data_root_train.glob('*/') if item.is_dir())\n",
        "label_names_val = sorted(int(item.name) for item in data_root_val.glob('*/') if item.is_dir())\n",
        "label_to_index_train = dict((name, index) for index,name in enumerate(label_names_train))\n",
        "label_to_index_val = dict((name, index) for index,name in enumerate(label_names_val))\n",
        "all_image_labels_train = [label_to_index_train[int(pathlib.Path(path).parent.name)] for path in all_image_paths_train]\n",
        "all_image_labels_val = [label_to_index_val[int(pathlib.Path(path).parent.name)] for path in all_image_paths_val]"
      ],
      "metadata": {
        "id": "s4PKpIDkb2On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading dataframe\n",
        "df_train = pd.read_csv(\"/content/Data/Train.csv\")\n",
        "\n",
        "#Updating coordinates\n",
        "for idx, row in df_train.iterrows() :\n",
        "  w = row['Width']\n",
        "  h = row['Height']\n",
        "  if w > IMG_WIDTH :\n",
        "    diff = w-IMG_WIDTH\n",
        "    df_train.iloc[idx, 4] = df_train.iloc[idx]['Roi.X2'] - diff\n",
        "  else :\n",
        "    diff = IMG_WIDTH-w\n",
        "    df_train.iloc[idx, 4] = df_train.iloc[idx]['Roi.X2'] + diff\n",
        "  if h > IMG_HEIGHT :\n",
        "    diff = h - IMG_HEIGHT\n",
        "    df_train.iloc[idx, 5] = df_train.iloc[idx]['Roi.Y2'] - diff\n",
        "  else :\n",
        "    diff = IMG_HEIGHT - h\n",
        "    df_train.iloc[idx, 5] = df_train.iloc[idx]['Roi.Y2'] + diff"
      ],
      "metadata": {
        "id": "j7qeXxdJcMwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx_list = []\n",
        "val_idx_list = []\n",
        "\n",
        "for path_tr in tqdm(all_image_paths_train) :\n",
        "  train_idx_list.append(df_train[df_train['Path'] == path_tr[14 : ]].index[0])\n",
        "for path_val in tqdm(all_image_paths_val) :\n",
        "  path_val = \"Train/\" + path_val[25:]\n",
        "  val_idx_list.append(df_train[df_train['Path'] == path_val].index[0])\n",
        "\n",
        "new_df_train = pd.DataFrame()\n",
        "new_df_val = pd.DataFrame()\n",
        "\n",
        "new_df_train = new_df_train.append(df_train.iloc[train_idx_list], ignore_index = True)\n",
        "new_df_val = new_df_val.append(df_train.iloc[val_idx_list], ignore_index = True)\n",
        "\n",
        "new_df_train = new_df_train.drop(['Height', 'Width', 'ClassId', 'Path'], axis = 1)\n",
        "new_df_val = new_df_val.drop(['Height', 'Width', 'ClassId', 'Path'], axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzJ2cqK3cUWI",
        "outputId": "789b5430-69bf-4368-ff8b-2570284a85d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29397/29397 [01:52<00:00, 260.91it/s]\n",
            "100%|██████████| 9812/9812 [00:41<00:00, 234.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tfdata_generator(images, labels, df, is_training, batch_size=32):\n",
        "  '''Construct a data generator using tf.Dataset'''\n",
        "  def parse_function(filename, labels, df):\n",
        "    '''Function to preprocess the images'''\n",
        "    #reading path \n",
        "    image_string = tf.io.read_file(filename)\n",
        "    #decoding image\n",
        "    image = tf.image.decode_png(image_string, channels=N_CHANNELS)\n",
        "    # This will convert to float values in [0, 1]\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    #Adjusting contrast and brightness of the image\n",
        "    if tf.math.reduce_mean(image) < 0.3 :\n",
        "      image = tf.image.adjust_contrast(image, 5)\n",
        "      image = tf.image.adjust_brightness(image, 0.2)\n",
        "    #resize the image\n",
        "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=\"nearest\", preserve_aspect_ratio=False)\n",
        "    image = image/255.0\n",
        "    #one hot coding for label\n",
        "    #y = tf.one_hot(tf.cast(label, tf.uint8), N_CLASSES)\n",
        "    return image, {\"classification\" : labels, \"regression\" : df}\n",
        "  ##creating a dataset from tensorslices\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((images, labels, df))\n",
        "  if is_training:\n",
        "    dataset = dataset.shuffle(30000)  # depends on sample size\n",
        "  # Transform and batch data at the same time\n",
        "  dataset = dataset.map(parse_function, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  #prefetch the data into CPU/GPU\n",
        "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return dataset\n",
        "\n",
        "#Train and Validation data generators :\n",
        "tf_image_generator_train = tfdata_generator(all_image_paths_train, all_image_labels_train, new_df_train, is_training=True, batch_size=32)\n",
        "tf_image_generator_val = tfdata_generator(all_image_paths_val, all_image_labels_val, new_df_val, is_training=False, batch_size=32)"
      ],
      "metadata": {
        "id": "ZQZ9YPkVcZAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sharpen(tf.keras.layers.Layer):\n",
        "  \n",
        "    def __init__(self, num_outputs) :\n",
        "        super(Sharpen, self).__init__()\n",
        "        self.num_outputs = num_outputs\n",
        "\n",
        "    def build(self, input_shape) :\n",
        "        self.kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "        self.kernel = tf.expand_dims(self.kernel, 0)\n",
        "        self.kernel = tf.expand_dims(self.kernel, 0)\n",
        "        self.kernel = tf.cast(self.kernel, tf.float32)\n",
        "\n",
        "    def call(self, input_) :\n",
        "        return tf.nn.conv2d(input_, self.kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
        "      \n",
        "def get_model() :\n",
        "  #Input layer\n",
        "  input_layer = Input(shape=(IMG_HEIGHT, IMG_WIDTH, N_CHANNELS, ), name=\"input_layer\", dtype='float32')\n",
        "  #Sharpen Layer to sharpen the edges of the image.\n",
        "  sharp = Sharpen(num_outputs=(IMG_HEIGHT, IMG_WIDTH, N_CHANNELS, ))(input_layer)\n",
        "  #Convolution, maxpool and dropout layers\n",
        "  conv_1 = Conv2D(filters=32, kernel_size=(5,5), activation=relu,\n",
        "                  kernel_initializer=he_normal(seed=54), bias_initializer=zeros(),\n",
        "                  name=\"first_convolutional_layer\") (sharp)\n",
        "  conv_2 = Conv2D(filters=64, kernel_size=(3,3), activation=relu,\n",
        "                  kernel_initializer=he_normal(seed=55), bias_initializer=zeros(),\n",
        "                  name=\"second_convolutional_layer\") (conv_1)                  \n",
        "  maxpool_1 = MaxPool2D(pool_size=(2,2), name = \"first_maxpool_layer\")(conv_2)\n",
        "  dr1 = Dropout(0.25)(maxpool_1)\n",
        "  conv_3 = Conv2D(filters=64, kernel_size=(3,3), activation=relu,\n",
        "                  kernel_initializer=he_normal(seed=56), bias_initializer=zeros(),\n",
        "                  name=\"third_convolutional_layer\") (dr1)\n",
        "  maxpool_2 = MaxPool2D(pool_size=(2,2), name = \"second_maxpool_layer\")(conv_3)\n",
        "  dr2 = Dropout(0.25)(maxpool_2) \n",
        "  flat = Flatten(name=\"flatten_layer\")(dr2)\n",
        "\n",
        "  #Fully connected layers\n",
        "  d1 = Dense(units=256, activation=relu, kernel_initializer=he_normal(seed=45),\n",
        "             bias_initializer=zeros(), name=\"first_dense_layer_classification\", kernel_regularizer = l2(0.001))(flat)\n",
        "  dr3 = Dropout(0.5)(d1)\n",
        "  \n",
        "  classification = Dense(units = 43, activation=None, name=\"classification\",  kernel_regularizer = l2(0.0001))(dr3)\n",
        "  \n",
        "  regression = Dense(units = 4, activation = 'linear', name = \"regression\", \n",
        "                     kernel_initializer=RandomNormal(seed=43), kernel_regularizer = l2(0.1))(dr3)\n",
        "  #Model\n",
        "  model = Model(inputs = input_layer, outputs = [classification, regression])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "4lqxYFN9csl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, auc\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "#Defining cusotm callback for F1-Score\n",
        "class Metrics(Callback) :\n",
        "  \"\"\"\n",
        "  Custom callback to print the weighted F1-Score\n",
        "  at the end of each training epoch.\n",
        "  \"\"\"\n",
        "  def __init__(self, validation_data_generator) :\n",
        "    self.validation_data_generator = validation_data_generator\n",
        "\n",
        "  def on_train_begin(self, logs={}) :\n",
        "    '''\n",
        "    This function initializes lists to store AUC and Micro F1 scores\n",
        "    '''\n",
        "    self.val_f1s = []\n",
        "    self.val_precisions = []\n",
        "    self.val_recalls = []\n",
        "    self.batches = self.validation_data_generator.as_numpy_iterator()\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs = {}) :\n",
        "    '''\n",
        "    This function calculates the micro f1 and auc scores\n",
        "    at the end of each epochs\n",
        "    '''\n",
        "    current_batch = self.batches.next()\n",
        "    images = current_batch[0]\n",
        "    labels = current_batch[1]\n",
        "    labels = labels[\"classification\"]\n",
        "    labels = np.array(labels)\n",
        "    pred = self.model.predict(images)\n",
        "    pred = pred[0]\n",
        "    val_predict = (np.asarray(pred)).round()\n",
        "    idx = np.argmax(val_predict, axis=-1)\n",
        "    a = np.zeros( val_predict.shape )\n",
        "    a[ np.arange(a.shape[0]), idx] = 1\n",
        "    val_predict = [np.where(r==1)[0][0] for r in a]\n",
        "    val_predict = np.array(val_predict)\n",
        "    val_targ = labels\n",
        "    _val_f1 = f1_score(val_targ, val_predict, average = 'weighted')\n",
        "    _val_precision = precision_score(val_targ, val_predict, average='weighted')\n",
        "    _val_recall = recall_score(val_targ, val_predict, average='weighted')\n",
        "    print(\"\\nEpoch : {0} -  Precision_Score : {1:.2f} - Recall_Score : {2:.2f} - F1_Score : {3:.2f}\\n\".format(epoch, _val_precision, _val_recall, _val_f1))\n",
        "    self.val_f1s.append(_val_f1)\n",
        "    self.val_precisions.append(_val_precision)\n",
        "    self.val_recalls.append(_val_recall)\n",
        "    return\n",
        "\n",
        "#Defining loss functions for classification and regression\n",
        "#Loss function for bounding box regression\n",
        "def r2_keras(y_true, y_pred):\n",
        "  SS_res =  K.sum(K.square(y_true - y_pred)) \n",
        "  SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
        "  return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
        "\n",
        "#loss function for classification\n",
        "loss = SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "#Compiling the model\n",
        "model = get_model()\n",
        "model.compile(optimizer=\"adam\", loss = {\"classification\" : loss, \"regression\" : \"mse\"}, \n",
        "              metrics={\"classification\" : \"acc\", \"regression\" : r2_keras}, loss_weights = {\"classification\" : 5, \"regression\" : 1})\n",
        "\n",
        "#Callbacks\n",
        "#Tensorboard callback\n",
        "%load_ext tensorboard\n",
        "log_dir=\"/content/drive/My Drive/CaseStudy2/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,\n",
        "                                   write_images = True)\n",
        "#ModelCheckpoint\n",
        "NAME = \"TrafficSignRecog-first-cut-{0}\".format(int(time.time()))\n",
        "save_best_model = ModelCheckpoint(filepath='/content/drive/My Drive/CaseStudy2/best_models/{0}'.format(NAME), monitor='val_loss',\n",
        "                                  save_best_only = True, mode = 'min', save_freq = 'epoch')\n",
        "\n",
        "#Early stopping to avoide model overfitting\n",
        "early_stop = EarlyStopping(monitor='loss', min_delta=0.0001, patience=5)\n",
        "metrics = Metrics(tf_image_generator_val)\n",
        "\n",
        "#Training\n",
        "history = model.fit_generator(\n",
        "    generator = tf_image_generator_train, steps_per_epoch = 200, #train batch size\n",
        "    epochs = N_EPOCHS,\n",
        "    validation_data = tf_image_generator_val, validation_steps = 32, #val batch size\n",
        "    callbacks = [save_best_model, tensorboard_callback, metrics, early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHMDUraBc_Ar",
        "outputId": "9538ae9c-a6ad-4a62-8e00-ea0d4026c8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_layer (InputLayer)       [(None, 30, 30, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " sharpen_1 (Sharpen)            (None, 30, 30, 3)    0           ['input_layer[0][0]']            \n",
            "                                                                                                  \n",
            " first_convolutional_layer (Con  (None, 26, 26, 32)  2432        ['sharpen_1[0][0]']              \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " second_convolutional_layer (Co  (None, 24, 24, 64)  18496       ['first_convolutional_layer[0][0]\n",
            " nv2D)                                                           ']                               \n",
            "                                                                                                  \n",
            " first_maxpool_layer (MaxPoolin  (None, 12, 12, 64)  0           ['second_convolutional_layer[0][0\n",
            " g2D)                                                            ]']                              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 12, 12, 64)   0           ['first_maxpool_layer[0][0]']    \n",
            "                                                                                                  \n",
            " third_convolutional_layer (Con  (None, 10, 10, 64)  36928       ['dropout_3[0][0]']              \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " second_maxpool_layer (MaxPooli  (None, 5, 5, 64)    0           ['third_convolutional_layer[0][0]\n",
            " ng2D)                                                           ']                               \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 5, 5, 64)     0           ['second_maxpool_layer[0][0]']   \n",
            "                                                                                                  \n",
            " flatten_layer (Flatten)        (None, 1600)         0           ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " first_dense_layer_classificati  (None, 256)         409856      ['flatten_layer[0][0]']          \n",
            " on (Dense)                                                                                       \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 256)          0           ['first_dense_layer_classificatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " classification (Dense)         (None, 43)           11051       ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " regression (Dense)             (None, 4)            1028        ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 479,791\n",
            "Trainable params: 479,791\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
            "Layer Sharpen has arguments ['self', 'num_outputs']\n",
            "in `__init__` and therefore must override `get_config()`.\n",
            "\n",
            "Example:\n",
            "\n",
            "class CustomLayer(keras.layers.Layer):\n",
            "    def __init__(self, arg1, arg2):\n",
            "        super().__init__()\n",
            "        self.arg1 = arg1\n",
            "        self.arg2 = arg2\n",
            "\n",
            "    def get_config(self):\n",
            "        config = super().get_config()\n",
            "        config.update({\n",
            "            \"arg1\": self.arg1,\n",
            "            \"arg2\": self.arg2,\n",
            "        })\n",
            "        return config\n",
            "Epoch 1/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 56.0825 - classification_loss: 5.8779 - regression_loss: 26.0694 - classification_acc: 0.0400 - regression_r2_keras: 0.7008INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 0 -  Precision_Score : 0.00 - Recall_Score : 0.00 - F1_Score : 0.00\n",
            "\n",
            "200/200 [==============================] - 34s 161ms/step - loss: 56.0825 - classification_loss: 5.8779 - regression_loss: 26.0694 - classification_acc: 0.0400 - regression_r2_keras: 0.7008 - val_loss: 34.0762 - val_classification_loss: 3.5639 - val_regression_loss: 15.6690 - val_classification_acc: 0.0000e+00 - val_regression_r2_keras: 0.8095\n",
            "Epoch 2/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 28.2838 - classification_loss: 4.3328 - regression_loss: 6.0089 - classification_acc: 0.0394 - regression_r2_keras: 0.9300\n",
            "Epoch : 1 -  Precision_Score : 0.00 - Recall_Score : 0.00 - F1_Score : 0.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 28.2838 - classification_loss: 4.3328 - regression_loss: 6.0089 - classification_acc: 0.0394 - regression_r2_keras: 0.9300 - val_loss: 37.3722 - val_classification_loss: 3.5377 - val_regression_loss: 19.0478 - val_classification_acc: 0.0000e+00 - val_regression_r2_keras: 0.7684\n",
            "Epoch 3/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 26.0249 - classification_loss: 3.9527 - regression_loss: 5.6037 - classification_acc: 0.0455 - regression_r2_keras: 0.9346\n",
            "Epoch : 2 -  Precision_Score : 0.00 - Recall_Score : 0.00 - F1_Score : 0.00\n",
            "\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 26.0249 - classification_loss: 3.9527 - regression_loss: 5.6037 - classification_acc: 0.0455 - regression_r2_keras: 0.9346 - val_loss: 42.1389 - val_classification_loss: 3.6171 - val_regression_loss: 23.3752 - val_classification_acc: 0.0000e+00 - val_regression_r2_keras: 0.7159\n",
            "Epoch 4/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 24.7948 - classification_loss: 3.7909 - regression_loss: 5.1447 - classification_acc: 0.0520 - regression_r2_keras: 0.9400INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 3 -  Precision_Score : 0.00 - Recall_Score : 0.00 - F1_Score : 0.00\n",
            "\n",
            "200/200 [==============================] - 31s 157ms/step - loss: 24.7948 - classification_loss: 3.7909 - regression_loss: 5.1447 - classification_acc: 0.0520 - regression_r2_keras: 0.9400 - val_loss: 33.1334 - val_classification_loss: 3.5313 - val_regression_loss: 14.7650 - val_classification_acc: 0.0039 - val_regression_r2_keras: 0.8197\n",
            "Epoch 5/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 24.0780 - classification_loss: 3.6942 - regression_loss: 4.8768 - classification_acc: 0.0519 - regression_r2_keras: 0.9434INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 4 -  Precision_Score : 0.00 - Recall_Score : 0.00 - F1_Score : 0.00\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 24.0780 - classification_loss: 3.6942 - regression_loss: 4.8768 - classification_acc: 0.0519 - regression_r2_keras: 0.9434 - val_loss: 31.7863 - val_classification_loss: 3.1652 - val_regression_loss: 15.2129 - val_classification_acc: 0.5088 - val_regression_r2_keras: 0.8143\n",
            "Epoch 6/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 22.7319 - classification_loss: 3.4570 - regression_loss: 4.6809 - classification_acc: 0.0980 - regression_r2_keras: 0.9458INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 5 -  Precision_Score : 1.00 - Recall_Score : 0.12 - F1_Score : 0.22\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 22.7319 - classification_loss: 3.4570 - regression_loss: 4.6809 - classification_acc: 0.0980 - regression_r2_keras: 0.9458 - val_loss: 22.3002 - val_classification_loss: 2.9965 - val_regression_loss: 6.5301 - val_classification_acc: 0.2012 - val_regression_r2_keras: 0.9190\n",
            "Epoch 7/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 20.9739 - classification_loss: 2.9718 - regression_loss: 5.3150 - classification_acc: 0.2048 - regression_r2_keras: 0.9380INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 6 -  Precision_Score : 1.00 - Recall_Score : 0.47 - F1_Score : 0.64\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 20.9739 - classification_loss: 2.9718 - regression_loss: 5.3150 - classification_acc: 0.2048 - regression_r2_keras: 0.9380 - val_loss: 22.1513 - val_classification_loss: 2.0035 - val_regression_loss: 11.3259 - val_classification_acc: 0.5508 - val_regression_r2_keras: 0.8611\n",
            "Epoch 8/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 18.6704 - classification_loss: 2.4660 - regression_loss: 5.5328 - classification_acc: 0.3052 - regression_r2_keras: 0.9356\n",
            "Epoch : 7 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 18.6704 - classification_loss: 2.4660 - regression_loss: 5.5328 - classification_acc: 0.3052 - regression_r2_keras: 0.9356 - val_loss: 23.8871 - val_classification_loss: 1.4098 - val_regression_loss: 16.0337 - val_classification_acc: 0.7441 - val_regression_r2_keras: 0.8045\n",
            "Epoch 9/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 16.9907 - classification_loss: 2.0805 - regression_loss: 5.7882 - classification_acc: 0.3897 - regression_r2_keras: 0.9327INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 8 -  Precision_Score : 1.00 - Recall_Score : 0.88 - F1_Score : 0.93\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 16.9907 - classification_loss: 2.0805 - regression_loss: 5.7882 - classification_acc: 0.3897 - regression_r2_keras: 0.9327 - val_loss: 13.0479 - val_classification_loss: 0.9462 - val_regression_loss: 7.5215 - val_classification_acc: 0.8037 - val_regression_r2_keras: 0.9071\n",
            "Epoch 10/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 15.5209 - classification_loss: 1.8204 - regression_loss: 5.6249 - classification_acc: 0.4512 - regression_r2_keras: 0.9344INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 9 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 31s 157ms/step - loss: 15.5209 - classification_loss: 1.8204 - regression_loss: 5.6249 - classification_acc: 0.4512 - regression_r2_keras: 0.9344 - val_loss: 10.8865 - val_classification_loss: 0.8297 - val_regression_loss: 5.9508 - val_classification_acc: 0.8320 - val_regression_r2_keras: 0.9258\n",
            "Epoch 11/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 14.7638 - classification_loss: 1.6693 - regression_loss: 5.6315 - classification_acc: 0.4925 - regression_r2_keras: 0.9345INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 10 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 14.7638 - classification_loss: 1.6693 - regression_loss: 5.6315 - classification_acc: 0.4925 - regression_r2_keras: 0.9345 - val_loss: 9.0487 - val_classification_loss: 0.6593 - val_regression_loss: 4.9674 - val_classification_acc: 0.8408 - val_regression_r2_keras: 0.9383\n",
            "Epoch 12/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 14.0660 - classification_loss: 1.5140 - regression_loss: 5.7183 - classification_acc: 0.5261 - regression_r2_keras: 0.9336\n",
            "Epoch : 11 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 14.0660 - classification_loss: 1.5140 - regression_loss: 5.7183 - classification_acc: 0.5261 - regression_r2_keras: 0.9336 - val_loss: 11.1592 - val_classification_loss: 0.6316 - val_regression_loss: 7.2292 - val_classification_acc: 0.8535 - val_regression_r2_keras: 0.9104\n",
            "Epoch 13/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 13.1776 - classification_loss: 1.3804 - regression_loss: 5.5032 - classification_acc: 0.5661 - regression_r2_keras: 0.9359\n",
            "Epoch : 12 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 146ms/step - loss: 13.1776 - classification_loss: 1.3804 - regression_loss: 5.5032 - classification_acc: 0.5661 - regression_r2_keras: 0.9359 - val_loss: 10.6270 - val_classification_loss: 0.4504 - val_regression_loss: 7.6032 - val_classification_acc: 0.8965 - val_regression_r2_keras: 0.9060\n",
            "Epoch 14/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 12.5522 - classification_loss: 1.2562 - regression_loss: 5.4981 - classification_acc: 0.6087 - regression_r2_keras: 0.9360INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 13 -  Precision_Score : 1.00 - Recall_Score : 0.88 - F1_Score : 0.93\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 12.5522 - classification_loss: 1.2562 - regression_loss: 5.4981 - classification_acc: 0.6087 - regression_r2_keras: 0.9360 - val_loss: 8.0189 - val_classification_loss: 0.3756 - val_regression_loss: 5.3660 - val_classification_acc: 0.9111 - val_regression_r2_keras: 0.9331\n",
            "Epoch 15/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 12.2147 - classification_loss: 1.1723 - regression_loss: 5.5747 - classification_acc: 0.6277 - regression_r2_keras: 0.9354INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 14 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 12.2147 - classification_loss: 1.1723 - regression_loss: 5.5747 - classification_acc: 0.6277 - regression_r2_keras: 0.9354 - val_loss: 7.2171 - val_classification_loss: 0.3778 - val_regression_loss: 4.5450 - val_classification_acc: 0.9131 - val_regression_r2_keras: 0.9431\n",
            "Epoch 16/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 11.8488 - classification_loss: 1.1050 - regression_loss: 5.5387 - classification_acc: 0.6514 - regression_r2_keras: 0.9356\n",
            "Epoch : 15 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 11.8488 - classification_loss: 1.1050 - regression_loss: 5.5387 - classification_acc: 0.6514 - regression_r2_keras: 0.9356 - val_loss: 9.7523 - val_classification_loss: 0.4169 - val_regression_loss: 6.8782 - val_classification_acc: 0.8887 - val_regression_r2_keras: 0.9144\n",
            "Epoch 17/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 11.3143 - classification_loss: 1.0369 - regression_loss: 5.3310 - classification_acc: 0.6742 - regression_r2_keras: 0.9380\n",
            "Epoch : 16 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 11.3143 - classification_loss: 1.0369 - regression_loss: 5.3310 - classification_acc: 0.6742 - regression_r2_keras: 0.9380 - val_loss: 7.2661 - val_classification_loss: 0.2958 - val_regression_loss: 4.9824 - val_classification_acc: 0.9229 - val_regression_r2_keras: 0.9379\n",
            "Epoch 18/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 10.8097 - classification_loss: 0.9284 - regression_loss: 5.3634 - classification_acc: 0.7080 - regression_r2_keras: 0.9377INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 17 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 157ms/step - loss: 10.8097 - classification_loss: 0.9284 - regression_loss: 5.3634 - classification_acc: 0.7080 - regression_r2_keras: 0.9377 - val_loss: 6.6079 - val_classification_loss: 0.3148 - val_regression_loss: 4.2234 - val_classification_acc: 0.9082 - val_regression_r2_keras: 0.9468\n",
            "Epoch 19/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 10.7643 - classification_loss: 0.8773 - regression_loss: 5.5647 - classification_acc: 0.7166 - regression_r2_keras: 0.9353\n",
            "Epoch : 18 -  Precision_Score : 1.00 - Recall_Score : 0.94 - F1_Score : 0.97\n",
            "\n",
            "200/200 [==============================] - 29s 146ms/step - loss: 10.7643 - classification_loss: 0.8773 - regression_loss: 5.5647 - classification_acc: 0.7166 - regression_r2_keras: 0.9353 - val_loss: 12.6503 - val_classification_loss: 0.3315 - val_regression_loss: 10.1811 - val_classification_acc: 0.9082 - val_regression_r2_keras: 0.8746\n",
            "Epoch 20/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 10.5208 - classification_loss: 0.8399 - regression_loss: 5.5019 - classification_acc: 0.7344 - regression_r2_keras: 0.9359\n",
            "Epoch : 19 -  Precision_Score : 1.00 - Recall_Score : 0.88 - F1_Score : 0.93\n",
            "\n",
            "200/200 [==============================] - 29s 146ms/step - loss: 10.5208 - classification_loss: 0.8399 - regression_loss: 5.5019 - classification_acc: 0.7344 - regression_r2_keras: 0.9359 - val_loss: 8.0659 - val_classification_loss: 0.2474 - val_regression_loss: 6.0040 - val_classification_acc: 0.9434 - val_regression_r2_keras: 0.9252\n",
            "Epoch 21/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 9.9155 - classification_loss: 0.7786 - regression_loss: 5.1974 - classification_acc: 0.7519 - regression_r2_keras: 0.9397\n",
            "Epoch : 20 -  Precision_Score : 1.00 - Recall_Score : 0.88 - F1_Score : 0.93\n",
            "\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 9.9155 - classification_loss: 0.7786 - regression_loss: 5.1974 - classification_acc: 0.7519 - regression_r2_keras: 0.9397 - val_loss: 8.2570 - val_classification_loss: 0.2589 - val_regression_loss: 6.1361 - val_classification_acc: 0.9365 - val_regression_r2_keras: 0.9236\n",
            "Epoch 22/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 10.0995 - classification_loss: 0.7638 - regression_loss: 5.4455 - classification_acc: 0.7616 - regression_r2_keras: 0.9367\n",
            "Epoch : 21 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 10.0995 - classification_loss: 0.7638 - regression_loss: 5.4455 - classification_acc: 0.7616 - regression_r2_keras: 0.9367 - val_loss: 7.4719 - val_classification_loss: 0.1920 - val_regression_loss: 5.6743 - val_classification_acc: 0.9502 - val_regression_r2_keras: 0.9293\n",
            "Epoch 23/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 9.4911 - classification_loss: 0.6746 - regression_loss: 5.2755 - classification_acc: 0.7862 - regression_r2_keras: 0.9386INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 22 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 9.4911 - classification_loss: 0.6746 - regression_loss: 5.2755 - classification_acc: 0.7862 - regression_r2_keras: 0.9386 - val_loss: 5.5967 - val_classification_loss: 0.2063 - val_regression_loss: 3.7185 - val_classification_acc: 0.9473 - val_regression_r2_keras: 0.9531\n",
            "Epoch 24/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 9.7154 - classification_loss: 0.6887 - regression_loss: 5.4213 - classification_acc: 0.7845 - regression_r2_keras: 0.9366\n",
            "Epoch : 23 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 28s 142ms/step - loss: 9.7154 - classification_loss: 0.6887 - regression_loss: 5.4213 - classification_acc: 0.7845 - regression_r2_keras: 0.9366 - val_loss: 6.2043 - val_classification_loss: 0.1255 - val_regression_loss: 4.7205 - val_classification_acc: 0.9717 - val_regression_r2_keras: 0.9407\n",
            "Epoch 25/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 9.1758 - classification_loss: 0.6438 - regression_loss: 5.0931 - classification_acc: 0.7914 - regression_r2_keras: 0.9410\n",
            "Epoch : 24 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 9.1758 - classification_loss: 0.6438 - regression_loss: 5.0931 - classification_acc: 0.7914 - regression_r2_keras: 0.9410 - val_loss: 6.5331 - val_classification_loss: 0.1577 - val_regression_loss: 4.8789 - val_classification_acc: 0.9688 - val_regression_r2_keras: 0.9392\n",
            "Epoch 26/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 9.1248 - classification_loss: 0.6173 - regression_loss: 5.1695 - classification_acc: 0.8012 - regression_r2_keras: 0.9399INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 25 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 33s 163ms/step - loss: 9.1248 - classification_loss: 0.6173 - regression_loss: 5.1695 - classification_acc: 0.8012 - regression_r2_keras: 0.9399 - val_loss: 5.3056 - val_classification_loss: 0.1617 - val_regression_loss: 3.6219 - val_classification_acc: 0.9561 - val_regression_r2_keras: 0.9541\n",
            "Epoch 27/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 9.2649 - classification_loss: 0.5797 - regression_loss: 5.4928 - classification_acc: 0.8177 - regression_r2_keras: 0.9360\n",
            "Epoch : 26 -  Precision_Score : 1.00 - Recall_Score : 0.81 - F1_Score : 0.89\n",
            "\n",
            "200/200 [==============================] - 29s 145ms/step - loss: 9.2649 - classification_loss: 0.5797 - regression_loss: 5.4928 - classification_acc: 0.8177 - regression_r2_keras: 0.9360 - val_loss: 6.3182 - val_classification_loss: 0.1582 - val_regression_loss: 4.6504 - val_classification_acc: 0.9561 - val_regression_r2_keras: 0.9419\n",
            "Epoch 28/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 8.7382 - classification_loss: 0.5486 - regression_loss: 5.1154 - classification_acc: 0.8253 - regression_r2_keras: 0.9405\n",
            "Epoch : 27 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 143ms/step - loss: 8.7382 - classification_loss: 0.5486 - regression_loss: 5.1154 - classification_acc: 0.8253 - regression_r2_keras: 0.9405 - val_loss: 7.4804 - val_classification_loss: 0.1358 - val_regression_loss: 5.9198 - val_classification_acc: 0.9707 - val_regression_r2_keras: 0.9264\n",
            "Epoch 29/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 8.8099 - classification_loss: 0.5491 - regression_loss: 5.1777 - classification_acc: 0.8273 - regression_r2_keras: 0.9395INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 28 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 31s 157ms/step - loss: 8.8099 - classification_loss: 0.5491 - regression_loss: 5.1777 - classification_acc: 0.8273 - regression_r2_keras: 0.9395 - val_loss: 4.9897 - val_classification_loss: 0.1309 - val_regression_loss: 3.4436 - val_classification_acc: 0.9639 - val_regression_r2_keras: 0.9563\n",
            "Epoch 30/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 8.4798 - classification_loss: 0.5064 - regression_loss: 5.0582 - classification_acc: 0.8352 - regression_r2_keras: 0.9414\n",
            "Epoch : 29 -  Precision_Score : 1.00 - Recall_Score : 0.94 - F1_Score : 0.97\n",
            "\n",
            "200/200 [==============================] - 28s 142ms/step - loss: 8.4798 - classification_loss: 0.5064 - regression_loss: 5.0582 - classification_acc: 0.8352 - regression_r2_keras: 0.9414 - val_loss: 7.1389 - val_classification_loss: 0.1176 - val_regression_loss: 5.6591 - val_classification_acc: 0.9775 - val_regression_r2_keras: 0.9296\n",
            "Epoch 31/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 8.4630 - classification_loss: 0.4904 - regression_loss: 5.1170 - classification_acc: 0.8484 - regression_r2_keras: 0.9405\n",
            "Epoch : 30 -  Precision_Score : 1.00 - Recall_Score : 0.94 - F1_Score : 0.97\n",
            "\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 8.4630 - classification_loss: 0.4904 - regression_loss: 5.1170 - classification_acc: 0.8484 - regression_r2_keras: 0.9405 - val_loss: 5.3390 - val_classification_loss: 0.0710 - val_regression_loss: 4.0905 - val_classification_acc: 0.9873 - val_regression_r2_keras: 0.9486\n",
            "Epoch 32/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 8.3250 - classification_loss: 0.4877 - regression_loss: 4.9907 - classification_acc: 0.8473 - regression_r2_keras: 0.9421\n",
            "Epoch : 31 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 29s 146ms/step - loss: 8.3250 - classification_loss: 0.4877 - regression_loss: 4.9907 - classification_acc: 0.8473 - regression_r2_keras: 0.9421 - val_loss: 6.3052 - val_classification_loss: 0.0701 - val_regression_loss: 5.0590 - val_classification_acc: 0.9844 - val_regression_r2_keras: 0.9368\n",
            "Epoch 33/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 8.2921 - classification_loss: 0.4686 - regression_loss: 5.0507 - classification_acc: 0.8528 - regression_r2_keras: 0.9416\n",
            "Epoch : 32 -  Precision_Score : 1.00 - Recall_Score : 0.84 - F1_Score : 0.92\n",
            "\n",
            "200/200 [==============================] - 29s 144ms/step - loss: 8.2921 - classification_loss: 0.4686 - regression_loss: 5.0507 - classification_acc: 0.8528 - regression_r2_keras: 0.9416 - val_loss: 5.9546 - val_classification_loss: 0.0951 - val_regression_loss: 4.5791 - val_classification_acc: 0.9756 - val_regression_r2_keras: 0.9428\n",
            "Epoch 34/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 8.1093 - classification_loss: 0.4477 - regression_loss: 4.9681 - classification_acc: 0.8600 - regression_r2_keras: 0.9422\n",
            "Epoch : 33 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 28s 142ms/step - loss: 8.1093 - classification_loss: 0.4477 - regression_loss: 4.9681 - classification_acc: 0.8600 - regression_r2_keras: 0.9422 - val_loss: 8.5700 - val_classification_loss: 0.1014 - val_regression_loss: 7.1612 - val_classification_acc: 0.9775 - val_regression_r2_keras: 0.9115\n",
            "Epoch 35/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.9386 - classification_loss: 0.4188 - regression_loss: 4.9425 - classification_acc: 0.8680 - regression_r2_keras: 0.9426INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 34 -  Precision_Score : 1.00 - Recall_Score : 0.94 - F1_Score : 0.97\n",
            "\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 7.9386 - classification_loss: 0.4188 - regression_loss: 4.9425 - classification_acc: 0.8680 - regression_r2_keras: 0.9426 - val_loss: 4.7357 - val_classification_loss: 0.1172 - val_regression_loss: 3.2441 - val_classification_acc: 0.9727 - val_regression_r2_keras: 0.9587\n",
            "Epoch 36/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.7763 - classification_loss: 0.4028 - regression_loss: 4.8562 - classification_acc: 0.8747 - regression_r2_keras: 0.9434\n",
            "Epoch : 35 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 7.7763 - classification_loss: 0.4028 - regression_loss: 4.8562 - classification_acc: 0.8747 - regression_r2_keras: 0.9434 - val_loss: 5.3952 - val_classification_loss: 0.1029 - val_regression_loss: 3.9732 - val_classification_acc: 0.9805 - val_regression_r2_keras: 0.9501\n",
            "Epoch 37/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.8963 - classification_loss: 0.3970 - regression_loss: 5.0054 - classification_acc: 0.8752 - regression_r2_keras: 0.9416\n",
            "Epoch : 36 -  Precision_Score : 1.00 - Recall_Score : 0.84 - F1_Score : 0.92\n",
            "\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 7.8963 - classification_loss: 0.3970 - regression_loss: 5.0054 - classification_acc: 0.8752 - regression_r2_keras: 0.9416 - val_loss: 6.3832 - val_classification_loss: 0.1123 - val_regression_loss: 4.9162 - val_classification_acc: 0.9697 - val_regression_r2_keras: 0.9386\n",
            "Epoch 38/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.6916 - classification_loss: 0.3912 - regression_loss: 4.8277 - classification_acc: 0.8817 - regression_r2_keras: 0.9440\n",
            "Epoch : 37 -  Precision_Score : 1.00 - Recall_Score : 0.84 - F1_Score : 0.92\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 7.6916 - classification_loss: 0.3912 - regression_loss: 4.8277 - classification_acc: 0.8817 - regression_r2_keras: 0.9440 - val_loss: 6.7633 - val_classification_loss: 0.0735 - val_regression_loss: 5.4860 - val_classification_acc: 0.9834 - val_regression_r2_keras: 0.9321\n",
            "Epoch 39/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.7035 - classification_loss: 0.3817 - regression_loss: 4.8850 - classification_acc: 0.8792 - regression_r2_keras: 0.9431\n",
            "Epoch : 38 -  Precision_Score : 1.00 - Recall_Score : 0.94 - F1_Score : 0.97\n",
            "\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 7.7035 - classification_loss: 0.3817 - regression_loss: 4.8850 - classification_acc: 0.8792 - regression_r2_keras: 0.9431 - val_loss: 5.6834 - val_classification_loss: 0.0710 - val_regression_loss: 4.4169 - val_classification_acc: 0.9814 - val_regression_r2_keras: 0.9447\n",
            "Epoch 40/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.8588 - classification_loss: 0.3897 - regression_loss: 4.9944 - classification_acc: 0.8791 - regression_r2_keras: 0.9418\n",
            "Epoch : 39 -  Precision_Score : 1.00 - Recall_Score : 0.84 - F1_Score : 0.92\n",
            "\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 7.8588 - classification_loss: 0.3897 - regression_loss: 4.9944 - classification_acc: 0.8791 - regression_r2_keras: 0.9418 - val_loss: 5.1097 - val_classification_loss: 0.0981 - val_regression_loss: 3.7005 - val_classification_acc: 0.9775 - val_regression_r2_keras: 0.9533\n",
            "Epoch 41/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.4529 - classification_loss: 0.3508 - regression_loss: 4.7821 - classification_acc: 0.8902 - regression_r2_keras: 0.9444\n",
            "Epoch : 40 -  Precision_Score : 1.00 - Recall_Score : 0.75 - F1_Score : 0.86\n",
            "\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 7.4529 - classification_loss: 0.3508 - regression_loss: 4.7821 - classification_acc: 0.8902 - regression_r2_keras: 0.9444 - val_loss: 5.7298 - val_classification_loss: 0.0667 - val_regression_loss: 4.4802 - val_classification_acc: 0.9834 - val_regression_r2_keras: 0.9441\n",
            "Epoch 42/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.3958 - classification_loss: 0.3440 - regression_loss: 4.7583 - classification_acc: 0.8903 - regression_r2_keras: 0.9448\n",
            "Epoch : 41 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 7.3958 - classification_loss: 0.3440 - regression_loss: 4.7583 - classification_acc: 0.8903 - regression_r2_keras: 0.9448 - val_loss: 5.3705 - val_classification_loss: 0.0606 - val_regression_loss: 4.1511 - val_classification_acc: 0.9863 - val_regression_r2_keras: 0.9478\n",
            "Epoch 43/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.6250 - classification_loss: 0.3488 - regression_loss: 4.9652 - classification_acc: 0.8930 - regression_r2_keras: 0.9424\n",
            "Epoch : 42 -  Precision_Score : 1.00 - Recall_Score : 0.84 - F1_Score : 0.92\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 7.6250 - classification_loss: 0.3488 - regression_loss: 4.9652 - classification_acc: 0.8930 - regression_r2_keras: 0.9424 - val_loss: 5.7943 - val_classification_loss: 0.0787 - val_regression_loss: 4.4845 - val_classification_acc: 0.9814 - val_regression_r2_keras: 0.9440\n",
            "Epoch 44/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.4223 - classification_loss: 0.3526 - regression_loss: 4.7356 - classification_acc: 0.8905 - regression_r2_keras: 0.9447INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 43 -  Precision_Score : 1.00 - Recall_Score : 0.94 - F1_Score : 0.97\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 7.4223 - classification_loss: 0.3526 - regression_loss: 4.7356 - classification_acc: 0.8905 - regression_r2_keras: 0.9447 - val_loss: 4.4283 - val_classification_loss: 0.0653 - val_regression_loss: 3.1754 - val_classification_acc: 0.9863 - val_regression_r2_keras: 0.9596\n",
            "Epoch 45/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.1232 - classification_loss: 0.3190 - regression_loss: 4.6046 - classification_acc: 0.8984 - regression_r2_keras: 0.9465\n",
            "Epoch : 44 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 28s 139ms/step - loss: 7.1232 - classification_loss: 0.3190 - regression_loss: 4.6046 - classification_acc: 0.8984 - regression_r2_keras: 0.9465 - val_loss: 4.6533 - val_classification_loss: 0.0795 - val_regression_loss: 3.3351 - val_classification_acc: 0.9834 - val_regression_r2_keras: 0.9578\n",
            "Epoch 46/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.0282 - classification_loss: 0.3211 - regression_loss: 4.5026 - classification_acc: 0.8961 - regression_r2_keras: 0.9478INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 45 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 7.0282 - classification_loss: 0.3211 - regression_loss: 4.5026 - classification_acc: 0.8961 - regression_r2_keras: 0.9478 - val_loss: 4.2104 - val_classification_loss: 0.0559 - val_regression_loss: 3.0126 - val_classification_acc: 0.9883 - val_regression_r2_keras: 0.9616\n",
            "Epoch 47/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.1665 - classification_loss: 0.3029 - regression_loss: 4.7321 - classification_acc: 0.9081 - regression_r2_keras: 0.9448\n",
            "Epoch : 46 -  Precision_Score : 1.00 - Recall_Score : 0.88 - F1_Score : 0.93\n",
            "\n",
            "200/200 [==============================] - 28s 139ms/step - loss: 7.1665 - classification_loss: 0.3029 - regression_loss: 4.7321 - classification_acc: 0.9081 - regression_r2_keras: 0.9448 - val_loss: 4.8564 - val_classification_loss: 0.0529 - val_regression_loss: 3.6710 - val_classification_acc: 0.9893 - val_regression_r2_keras: 0.9538\n",
            "Epoch 48/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.0952 - classification_loss: 0.2907 - regression_loss: 4.7205 - classification_acc: 0.9112 - regression_r2_keras: 0.9450\n",
            "Epoch : 47 -  Precision_Score : 1.00 - Recall_Score : 0.88 - F1_Score : 0.93\n",
            "\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 7.0952 - classification_loss: 0.2907 - regression_loss: 4.7205 - classification_acc: 0.9112 - regression_r2_keras: 0.9450 - val_loss: 7.4734 - val_classification_loss: 0.0469 - val_regression_loss: 6.3210 - val_classification_acc: 0.9893 - val_regression_r2_keras: 0.9216\n",
            "Epoch 49/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 7.0485 - classification_loss: 0.3105 - regression_loss: 4.5755 - classification_acc: 0.9003 - regression_r2_keras: 0.9467\n",
            "Epoch : 48 -  Precision_Score : 1.00 - Recall_Score : 0.88 - F1_Score : 0.93\n",
            "\n",
            "200/200 [==============================] - 28s 139ms/step - loss: 7.0485 - classification_loss: 0.3105 - regression_loss: 4.5755 - classification_acc: 0.9003 - regression_r2_keras: 0.9467 - val_loss: 5.6299 - val_classification_loss: 0.0613 - val_regression_loss: 4.4048 - val_classification_acc: 0.9854 - val_regression_r2_keras: 0.9449\n",
            "Epoch 50/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.8518 - classification_loss: 0.2924 - regression_loss: 4.4718 - classification_acc: 0.9073 - regression_r2_keras: 0.9480\n",
            "Epoch : 49 -  Precision_Score : 1.00 - Recall_Score : 0.94 - F1_Score : 0.97\n",
            "\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 6.8518 - classification_loss: 0.2924 - regression_loss: 4.4718 - classification_acc: 0.9073 - regression_r2_keras: 0.9480 - val_loss: 5.0485 - val_classification_loss: 0.0366 - val_regression_loss: 3.9480 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9504\n",
            "Epoch 51/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.9836 - classification_loss: 0.2864 - regression_loss: 4.6336 - classification_acc: 0.9117 - regression_r2_keras: 0.9462\n",
            "Epoch : 50 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 6.9836 - classification_loss: 0.2864 - regression_loss: 4.6336 - classification_acc: 0.9117 - regression_r2_keras: 0.9462 - val_loss: 4.4257 - val_classification_loss: 0.0512 - val_regression_loss: 3.2508 - val_classification_acc: 0.9902 - val_regression_r2_keras: 0.9587\n",
            "Epoch 52/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.6554 - classification_loss: 0.2652 - regression_loss: 4.4128 - classification_acc: 0.9142 - regression_r2_keras: 0.9487INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 51 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 32s 159ms/step - loss: 6.6554 - classification_loss: 0.2652 - regression_loss: 4.4128 - classification_acc: 0.9142 - regression_r2_keras: 0.9487 - val_loss: 3.9950 - val_classification_loss: 0.0378 - val_regression_loss: 2.8897 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9632\n",
            "Epoch 53/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.7334 - classification_loss: 0.2618 - regression_loss: 4.5131 - classification_acc: 0.9155 - regression_r2_keras: 0.9474\n",
            "Epoch : 52 -  Precision_Score : 1.00 - Recall_Score : 0.88 - F1_Score : 0.93\n",
            "\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 6.7334 - classification_loss: 0.2618 - regression_loss: 4.5131 - classification_acc: 0.9155 - regression_r2_keras: 0.9474 - val_loss: 5.5275 - val_classification_loss: 0.0616 - val_regression_loss: 4.3085 - val_classification_acc: 0.9814 - val_regression_r2_keras: 0.9461\n",
            "Epoch 54/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.6252 - classification_loss: 0.2790 - regression_loss: 4.3201 - classification_acc: 0.9112 - regression_r2_keras: 0.9499\n",
            "Epoch : 53 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 152ms/step - loss: 6.6252 - classification_loss: 0.2790 - regression_loss: 4.3201 - classification_acc: 0.9112 - regression_r2_keras: 0.9499 - val_loss: 5.5808 - val_classification_loss: 0.0577 - val_regression_loss: 4.3835 - val_classification_acc: 0.9844 - val_regression_r2_keras: 0.9450\n",
            "Epoch 55/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.8202 - classification_loss: 0.2653 - regression_loss: 4.5822 - classification_acc: 0.9141 - regression_r2_keras: 0.9467INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 54 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 6.8202 - classification_loss: 0.2653 - regression_loss: 4.5822 - classification_acc: 0.9141 - regression_r2_keras: 0.9467 - val_loss: 3.9843 - val_classification_loss: 0.0361 - val_regression_loss: 2.8888 - val_classification_acc: 0.9922 - val_regression_r2_keras: 0.9631\n",
            "Epoch 56/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.6488 - classification_loss: 0.2522 - regression_loss: 4.4786 - classification_acc: 0.9192 - regression_r2_keras: 0.9479\n",
            "Epoch : 55 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 146ms/step - loss: 6.6488 - classification_loss: 0.2522 - regression_loss: 4.4786 - classification_acc: 0.9192 - regression_r2_keras: 0.9479 - val_loss: 5.4870 - val_classification_loss: 0.0289 - val_regression_loss: 4.4333 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9447\n",
            "Epoch 57/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.3765 - classification_loss: 0.2461 - regression_loss: 4.2363 - classification_acc: 0.9253 - regression_r2_keras: 0.9510\n",
            "Epoch : 56 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 31s 153ms/step - loss: 6.3765 - classification_loss: 0.2461 - regression_loss: 4.2363 - classification_acc: 0.9253 - regression_r2_keras: 0.9510 - val_loss: 5.5413 - val_classification_loss: 0.0419 - val_regression_loss: 4.4268 - val_classification_acc: 0.9902 - val_regression_r2_keras: 0.9449\n",
            "Epoch 58/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.5670 - classification_loss: 0.2485 - regression_loss: 4.4176 - classification_acc: 0.9203 - regression_r2_keras: 0.9485\n",
            "Epoch : 57 -  Precision_Score : 1.00 - Recall_Score : 0.94 - F1_Score : 0.97\n",
            "\n",
            "200/200 [==============================] - 29s 146ms/step - loss: 6.5670 - classification_loss: 0.2485 - regression_loss: 4.4176 - classification_acc: 0.9203 - regression_r2_keras: 0.9485 - val_loss: 5.5626 - val_classification_loss: 0.0768 - val_regression_loss: 4.2704 - val_classification_acc: 0.9834 - val_regression_r2_keras: 0.9465\n",
            "Epoch 59/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.4024 - classification_loss: 0.2366 - regression_loss: 4.3103 - classification_acc: 0.9247 - regression_r2_keras: 0.9498\n",
            "Epoch : 58 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 6.4024 - classification_loss: 0.2366 - regression_loss: 4.3103 - classification_acc: 0.9247 - regression_r2_keras: 0.9498 - val_loss: 4.1610 - val_classification_loss: 0.0477 - val_regression_loss: 3.0138 - val_classification_acc: 0.9883 - val_regression_r2_keras: 0.9615\n",
            "Epoch 60/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.2263 - classification_loss: 0.2264 - regression_loss: 4.1847 - classification_acc: 0.9258 - regression_r2_keras: 0.9514\n",
            "Epoch : 59 -  Precision_Score : 1.00 - Recall_Score : 0.88 - F1_Score : 0.93\n",
            "\n",
            "200/200 [==============================] - 30s 152ms/step - loss: 6.2263 - classification_loss: 0.2264 - regression_loss: 4.1847 - classification_acc: 0.9258 - regression_r2_keras: 0.9514 - val_loss: 4.9588 - val_classification_loss: 0.0346 - val_regression_loss: 3.8808 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9511\n",
            "Epoch 61/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.4163 - classification_loss: 0.2327 - regression_loss: 4.3480 - classification_acc: 0.9242 - regression_r2_keras: 0.9493\n",
            "Epoch : 60 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 29s 145ms/step - loss: 6.4163 - classification_loss: 0.2327 - regression_loss: 4.3480 - classification_acc: 0.9242 - regression_r2_keras: 0.9493 - val_loss: 4.7614 - val_classification_loss: 0.0421 - val_regression_loss: 3.6452 - val_classification_acc: 0.9912 - val_regression_r2_keras: 0.9541\n",
            "Epoch 62/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.3701 - classification_loss: 0.2354 - regression_loss: 4.2898 - classification_acc: 0.9270 - regression_r2_keras: 0.9499\n",
            "Epoch : 61 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 6.3701 - classification_loss: 0.2354 - regression_loss: 4.2898 - classification_acc: 0.9270 - regression_r2_keras: 0.9499 - val_loss: 4.3420 - val_classification_loss: 0.0306 - val_regression_loss: 3.2861 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9585\n",
            "Epoch 63/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.1421 - classification_loss: 0.2246 - regression_loss: 4.1169 - classification_acc: 0.9294 - regression_r2_keras: 0.9522\n",
            "Epoch : 62 -  Precision_Score : 1.00 - Recall_Score : 0.88 - F1_Score : 0.93\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 6.1421 - classification_loss: 0.2246 - regression_loss: 4.1169 - classification_acc: 0.9294 - regression_r2_keras: 0.9522 - val_loss: 4.7578 - val_classification_loss: 0.0354 - val_regression_loss: 3.6813 - val_classification_acc: 0.9922 - val_regression_r2_keras: 0.9537\n",
            "Epoch 64/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.0831 - classification_loss: 0.2210 - regression_loss: 4.0775 - classification_acc: 0.9309 - regression_r2_keras: 0.9527\n",
            "Epoch : 63 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 6.0831 - classification_loss: 0.2210 - regression_loss: 4.0775 - classification_acc: 0.9309 - regression_r2_keras: 0.9527 - val_loss: 5.4640 - val_classification_loss: 0.0346 - val_regression_loss: 4.3907 - val_classification_acc: 0.9912 - val_regression_r2_keras: 0.9448\n",
            "Epoch 65/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.2533 - classification_loss: 0.2166 - regression_loss: 4.2707 - classification_acc: 0.9323 - regression_r2_keras: 0.9503\n",
            "Epoch : 64 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 29s 144ms/step - loss: 6.2533 - classification_loss: 0.2166 - regression_loss: 4.2707 - classification_acc: 0.9323 - regression_r2_keras: 0.9503 - val_loss: 4.9578 - val_classification_loss: 0.0324 - val_regression_loss: 3.8993 - val_classification_acc: 0.9902 - val_regression_r2_keras: 0.9509\n",
            "Epoch 66/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.2446 - classification_loss: 0.2037 - regression_loss: 4.3311 - classification_acc: 0.9347 - regression_r2_keras: 0.9492\n",
            "Epoch : 65 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 29s 145ms/step - loss: 6.2446 - classification_loss: 0.2037 - regression_loss: 4.3311 - classification_acc: 0.9347 - regression_r2_keras: 0.9492 - val_loss: 4.0024 - val_classification_loss: 0.0416 - val_regression_loss: 2.8992 - val_classification_acc: 0.9883 - val_regression_r2_keras: 0.9631\n",
            "Epoch 67/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.0470 - classification_loss: 0.2064 - regression_loss: 4.1224 - classification_acc: 0.9344 - regression_r2_keras: 0.9520\n",
            "Epoch : 66 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 6.0470 - classification_loss: 0.2064 - regression_loss: 4.1224 - classification_acc: 0.9344 - regression_r2_keras: 0.9520 - val_loss: 4.9822 - val_classification_loss: 0.0337 - val_regression_loss: 3.9217 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9506\n",
            "Epoch 68/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.9697 - classification_loss: 0.1974 - regression_loss: 4.0928 - classification_acc: 0.9358 - regression_r2_keras: 0.9524\n",
            "Epoch : 67 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 5.9697 - classification_loss: 0.1974 - regression_loss: 4.0928 - classification_acc: 0.9358 - regression_r2_keras: 0.9524 - val_loss: 4.4514 - val_classification_loss: 0.0335 - val_regression_loss: 3.3965 - val_classification_acc: 0.9912 - val_regression_r2_keras: 0.9571\n",
            "Epoch 69/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.8686 - classification_loss: 0.1936 - regression_loss: 4.0148 - classification_acc: 0.9358 - regression_r2_keras: 0.9534\n",
            "Epoch : 68 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 5.8686 - classification_loss: 0.1936 - regression_loss: 4.0148 - classification_acc: 0.9358 - regression_r2_keras: 0.9534 - val_loss: 4.2836 - val_classification_loss: 0.0294 - val_regression_loss: 3.2489 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9588\n",
            "Epoch 70/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.0461 - classification_loss: 0.1926 - regression_loss: 4.1986 - classification_acc: 0.9367 - regression_r2_keras: 0.9511\n",
            "Epoch : 69 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 146ms/step - loss: 6.0461 - classification_loss: 0.1926 - regression_loss: 4.1986 - classification_acc: 0.9367 - regression_r2_keras: 0.9511 - val_loss: 4.9451 - val_classification_loss: 0.0272 - val_regression_loss: 3.9257 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9508\n",
            "Epoch 71/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.9450 - classification_loss: 0.1997 - regression_loss: 4.0623 - classification_acc: 0.9337 - regression_r2_keras: 0.9528\n",
            "Epoch : 70 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 148ms/step - loss: 5.9450 - classification_loss: 0.1997 - regression_loss: 4.0623 - classification_acc: 0.9337 - regression_r2_keras: 0.9528 - val_loss: 4.0185 - val_classification_loss: 0.0217 - val_regression_loss: 3.0238 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9615\n",
            "Epoch 72/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.8584 - classification_loss: 0.1998 - regression_loss: 3.9721 - classification_acc: 0.9383 - regression_r2_keras: 0.9538\n",
            "Epoch : 71 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 5.8584 - classification_loss: 0.1998 - regression_loss: 3.9721 - classification_acc: 0.9383 - regression_r2_keras: 0.9538 - val_loss: 6.2417 - val_classification_loss: 0.0384 - val_regression_loss: 5.1656 - val_classification_acc: 0.9922 - val_regression_r2_keras: 0.9355\n",
            "Epoch 73/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.7384 - classification_loss: 0.1835 - regression_loss: 3.9339 - classification_acc: 0.9434 - regression_r2_keras: 0.9542\n",
            "Epoch : 72 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 145ms/step - loss: 5.7384 - classification_loss: 0.1835 - regression_loss: 3.9339 - classification_acc: 0.9434 - regression_r2_keras: 0.9542 - val_loss: 4.4821 - val_classification_loss: 0.0267 - val_regression_loss: 3.4637 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9564\n",
            "Epoch 74/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.8062 - classification_loss: 0.1954 - regression_loss: 3.9462 - classification_acc: 0.9367 - regression_r2_keras: 0.9542\n",
            "Epoch : 73 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 155ms/step - loss: 5.8062 - classification_loss: 0.1954 - regression_loss: 3.9462 - classification_acc: 0.9367 - regression_r2_keras: 0.9542 - val_loss: 4.3632 - val_classification_loss: 0.0243 - val_regression_loss: 3.3573 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9575\n",
            "Epoch 75/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.8678 - classification_loss: 0.1787 - regression_loss: 4.0897 - classification_acc: 0.9430 - regression_r2_keras: 0.9523\n",
            "Epoch : 74 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 5.8678 - classification_loss: 0.1787 - regression_loss: 4.0897 - classification_acc: 0.9430 - regression_r2_keras: 0.9523 - val_loss: 4.7599 - val_classification_loss: 0.0295 - val_regression_loss: 3.7270 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9531\n",
            "Epoch 76/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.9089 - classification_loss: 0.2002 - regression_loss: 4.0255 - classification_acc: 0.9373 - regression_r2_keras: 0.9532\n",
            "Epoch : 75 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 5.9089 - classification_loss: 0.2002 - regression_loss: 4.0255 - classification_acc: 0.9373 - regression_r2_keras: 0.9532 - val_loss: 4.0526 - val_classification_loss: 0.0305 - val_regression_loss: 3.0129 - val_classification_acc: 0.9912 - val_regression_r2_keras: 0.9617\n",
            "Epoch 77/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.7479 - classification_loss: 0.1870 - regression_loss: 3.9294 - classification_acc: 0.9406 - regression_r2_keras: 0.9543\n",
            "Epoch : 76 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 5.7479 - classification_loss: 0.1870 - regression_loss: 3.9294 - classification_acc: 0.9406 - regression_r2_keras: 0.9543 - val_loss: 5.6672 - val_classification_loss: 0.0284 - val_regression_loss: 4.6476 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9418\n",
            "Epoch 78/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.6894 - classification_loss: 0.1811 - regression_loss: 3.9048 - classification_acc: 0.9453 - regression_r2_keras: 0.9545\n",
            "Epoch : 77 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 146ms/step - loss: 5.6894 - classification_loss: 0.1811 - regression_loss: 3.9048 - classification_acc: 0.9453 - regression_r2_keras: 0.9545 - val_loss: 5.2519 - val_classification_loss: 0.0206 - val_regression_loss: 4.2736 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9466\n",
            "Epoch 79/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.5052 - classification_loss: 0.1540 - regression_loss: 3.8602 - classification_acc: 0.9502 - regression_r2_keras: 0.9550\n",
            "Epoch : 78 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 5.5052 - classification_loss: 0.1540 - regression_loss: 3.8602 - classification_acc: 0.9502 - regression_r2_keras: 0.9550 - val_loss: 4.0031 - val_classification_loss: 0.0237 - val_regression_loss: 3.0114 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9616\n",
            "Epoch 80/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.7771 - classification_loss: 0.1740 - regression_loss: 4.0360 - classification_acc: 0.9441 - regression_r2_keras: 0.9528\n",
            "Epoch : 79 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 153ms/step - loss: 5.7771 - classification_loss: 0.1740 - regression_loss: 4.0360 - classification_acc: 0.9441 - regression_r2_keras: 0.9528 - val_loss: 5.1946 - val_classification_loss: 0.0410 - val_regression_loss: 4.1211 - val_classification_acc: 0.9902 - val_regression_r2_keras: 0.9484\n",
            "Epoch 81/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.5365 - classification_loss: 0.1715 - regression_loss: 3.8117 - classification_acc: 0.9480 - regression_r2_keras: 0.9557\n",
            "Epoch : 80 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 157ms/step - loss: 5.5365 - classification_loss: 0.1715 - regression_loss: 3.8117 - classification_acc: 0.9480 - regression_r2_keras: 0.9557 - val_loss: 5.0627 - val_classification_loss: 0.0312 - val_regression_loss: 4.0385 - val_classification_acc: 0.9941 - val_regression_r2_keras: 0.9494\n",
            "Epoch 82/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.6726 - classification_loss: 0.1947 - regression_loss: 3.8271 - classification_acc: 0.9391 - regression_r2_keras: 0.9556\n",
            "Epoch : 81 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 5.6726 - classification_loss: 0.1947 - regression_loss: 3.8271 - classification_acc: 0.9391 - regression_r2_keras: 0.9556 - val_loss: 5.5916 - val_classification_loss: 0.0270 - val_regression_loss: 4.5879 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9428\n",
            "Epoch 83/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.6438 - classification_loss: 0.1754 - regression_loss: 3.8948 - classification_acc: 0.9447 - regression_r2_keras: 0.9545INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 82 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 32s 160ms/step - loss: 5.6438 - classification_loss: 0.1754 - regression_loss: 3.8948 - classification_acc: 0.9447 - regression_r2_keras: 0.9545 - val_loss: 3.9528 - val_classification_loss: 0.0222 - val_regression_loss: 2.9689 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9622\n",
            "Epoch 84/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.3743 - classification_loss: 0.1567 - regression_loss: 3.7227 - classification_acc: 0.9506 - regression_r2_keras: 0.9568\n",
            "Epoch : 83 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 5.3743 - classification_loss: 0.1567 - regression_loss: 3.7227 - classification_acc: 0.9506 - regression_r2_keras: 0.9568 - val_loss: 4.8027 - val_classification_loss: 0.0430 - val_regression_loss: 3.7234 - val_classification_acc: 0.9863 - val_regression_r2_keras: 0.9532\n",
            "Epoch 85/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.4250 - classification_loss: 0.1607 - regression_loss: 3.7597 - classification_acc: 0.9494 - regression_r2_keras: 0.9561\n",
            "Epoch : 84 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 5.4250 - classification_loss: 0.1607 - regression_loss: 3.7597 - classification_acc: 0.9494 - regression_r2_keras: 0.9561 - val_loss: 4.2680 - val_classification_loss: 0.0196 - val_regression_loss: 3.3103 - val_classification_acc: 0.9941 - val_regression_r2_keras: 0.9582\n",
            "Epoch 86/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.5730 - classification_loss: 0.1576 - regression_loss: 3.9247 - classification_acc: 0.9502 - regression_r2_keras: 0.9540\n",
            "Epoch : 85 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 5.5730 - classification_loss: 0.1576 - regression_loss: 3.9247 - classification_acc: 0.9502 - regression_r2_keras: 0.9540 - val_loss: 5.2028 - val_classification_loss: 0.0165 - val_regression_loss: 4.2593 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9467\n",
            "Epoch 87/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.4063 - classification_loss: 0.1708 - regression_loss: 3.6934 - classification_acc: 0.9480 - regression_r2_keras: 0.9572\n",
            "Epoch : 86 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 5.4063 - classification_loss: 0.1708 - regression_loss: 3.6934 - classification_acc: 0.9480 - regression_r2_keras: 0.9572 - val_loss: 4.5478 - val_classification_loss: 0.0235 - val_regression_loss: 3.5722 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9550\n",
            "Epoch 88/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.2365 - classification_loss: 0.1434 - regression_loss: 3.6644 - classification_acc: 0.9544 - regression_r2_keras: 0.9572INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 87 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 33s 163ms/step - loss: 5.2365 - classification_loss: 0.1434 - regression_loss: 3.6644 - classification_acc: 0.9544 - regression_r2_keras: 0.9572 - val_loss: 3.6544 - val_classification_loss: 0.0165 - val_regression_loss: 2.7181 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9654\n",
            "Epoch 89/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.5994 - classification_loss: 0.1595 - regression_loss: 3.9502 - classification_acc: 0.9491 - regression_r2_keras: 0.9539\n",
            "Epoch : 88 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 157ms/step - loss: 5.5994 - classification_loss: 0.1595 - regression_loss: 3.9502 - classification_acc: 0.9491 - regression_r2_keras: 0.9539 - val_loss: 3.9042 - val_classification_loss: 0.0288 - val_regression_loss: 2.9053 - val_classification_acc: 0.9941 - val_regression_r2_keras: 0.9632\n",
            "Epoch 90/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.2900 - classification_loss: 0.1702 - regression_loss: 3.5848 - classification_acc: 0.9488 - regression_r2_keras: 0.9586\n",
            "Epoch : 89 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 32s 158ms/step - loss: 5.2900 - classification_loss: 0.1702 - regression_loss: 3.5848 - classification_acc: 0.9488 - regression_r2_keras: 0.9586 - val_loss: 4.4093 - val_classification_loss: 0.0144 - val_regression_loss: 3.4853 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9561\n",
            "Epoch 91/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.2324 - classification_loss: 0.1484 - regression_loss: 3.6367 - classification_acc: 0.9534 - regression_r2_keras: 0.9575\n",
            "Epoch : 90 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 30s 152ms/step - loss: 5.2324 - classification_loss: 0.1484 - regression_loss: 3.6367 - classification_acc: 0.9534 - regression_r2_keras: 0.9575 - val_loss: 4.0102 - val_classification_loss: 0.0223 - val_regression_loss: 3.0481 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9614\n",
            "Epoch 92/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.0967 - classification_loss: 0.1505 - regression_loss: 3.4953 - classification_acc: 0.9523 - regression_r2_keras: 0.9594\n",
            "Epoch : 91 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 152ms/step - loss: 5.0967 - classification_loss: 0.1505 - regression_loss: 3.4953 - classification_acc: 0.9523 - regression_r2_keras: 0.9594 - val_loss: 4.1294 - val_classification_loss: 0.0199 - val_regression_loss: 3.1830 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9598\n",
            "Epoch 93/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.1892 - classification_loss: 0.1377 - regression_loss: 3.6542 - classification_acc: 0.9553 - regression_r2_keras: 0.9574\n",
            "Epoch : 92 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 5.1892 - classification_loss: 0.1377 - regression_loss: 3.6542 - classification_acc: 0.9553 - regression_r2_keras: 0.9574 - val_loss: 5.2034 - val_classification_loss: 0.0152 - val_regression_loss: 4.2820 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9465\n",
            "Epoch 94/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.1789 - classification_loss: 0.1481 - regression_loss: 3.5930 - classification_acc: 0.9541 - regression_r2_keras: 0.9582\n",
            "Epoch : 93 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 153ms/step - loss: 5.1789 - classification_loss: 0.1481 - regression_loss: 3.5930 - classification_acc: 0.9541 - regression_r2_keras: 0.9582 - val_loss: 3.8467 - val_classification_loss: 0.0178 - val_regression_loss: 2.9128 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9631\n",
            "Epoch 95/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.2231 - classification_loss: 0.1533 - regression_loss: 3.6121 - classification_acc: 0.9506 - regression_r2_keras: 0.9579\n",
            "Epoch : 94 -  Precision_Score : 1.00 - Recall_Score : 0.91 - F1_Score : 0.95\n",
            "\n",
            "200/200 [==============================] - 31s 155ms/step - loss: 5.2231 - classification_loss: 0.1533 - regression_loss: 3.6121 - classification_acc: 0.9506 - regression_r2_keras: 0.9579 - val_loss: 4.8455 - val_classification_loss: 0.0204 - val_regression_loss: 3.8980 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9512\n",
            "Epoch 96/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.9514 - classification_loss: 0.1408 - regression_loss: 3.4020 - classification_acc: 0.9550 - regression_r2_keras: 0.9606\n",
            "Epoch : 95 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 155ms/step - loss: 4.9514 - classification_loss: 0.1408 - regression_loss: 3.4020 - classification_acc: 0.9550 - regression_r2_keras: 0.9606 - val_loss: 3.9185 - val_classification_loss: 0.0132 - val_regression_loss: 3.0105 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9620\n",
            "Epoch 97/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.2072 - classification_loss: 0.1438 - regression_loss: 3.6490 - classification_acc: 0.9544 - regression_r2_keras: 0.9573\n",
            "Epoch : 96 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 5.2072 - classification_loss: 0.1438 - regression_loss: 3.6490 - classification_acc: 0.9544 - regression_r2_keras: 0.9573 - val_loss: 4.7095 - val_classification_loss: 0.0192 - val_regression_loss: 3.7748 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9526\n",
            "Epoch 98/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.8652 - classification_loss: 0.1318 - regression_loss: 3.3698 - classification_acc: 0.9584 - regression_r2_keras: 0.9609\n",
            "Epoch : 97 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 4.8652 - classification_loss: 0.1318 - regression_loss: 3.3698 - classification_acc: 0.9584 - regression_r2_keras: 0.9609 - val_loss: 4.2845 - val_classification_loss: 0.0223 - val_regression_loss: 3.3378 - val_classification_acc: 0.9941 - val_regression_r2_keras: 0.9581\n",
            "Epoch 99/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.1546 - classification_loss: 0.1422 - regression_loss: 3.6052 - classification_acc: 0.9541 - regression_r2_keras: 0.9580\n",
            "Epoch : 98 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 153ms/step - loss: 5.1546 - classification_loss: 0.1422 - regression_loss: 3.6052 - classification_acc: 0.9541 - regression_r2_keras: 0.9580 - val_loss: 4.3036 - val_classification_loss: 0.0143 - val_regression_loss: 3.3931 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9573\n",
            "Epoch 100/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.1406 - classification_loss: 0.1498 - regression_loss: 3.5522 - classification_acc: 0.9519 - regression_r2_keras: 0.9586\n",
            "Epoch : 99 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 153ms/step - loss: 5.1406 - classification_loss: 0.1498 - regression_loss: 3.5522 - classification_acc: 0.9519 - regression_r2_keras: 0.9586 - val_loss: 4.4445 - val_classification_loss: 0.0296 - val_regression_loss: 3.4555 - val_classification_acc: 0.9941 - val_regression_r2_keras: 0.9564\n",
            "Epoch 101/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.9844 - classification_loss: 0.1470 - regression_loss: 3.4075 - classification_acc: 0.9516 - regression_r2_keras: 0.9604\n",
            "Epoch : 100 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 4.9844 - classification_loss: 0.1470 - regression_loss: 3.4075 - classification_acc: 0.9516 - regression_r2_keras: 0.9604 - val_loss: 4.7319 - val_classification_loss: 0.0208 - val_regression_loss: 3.7812 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9526\n",
            "Epoch 102/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.8285 - classification_loss: 0.1268 - regression_loss: 3.3533 - classification_acc: 0.9605 - regression_r2_keras: 0.9610\n",
            "Epoch : 101 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 4.8285 - classification_loss: 0.1268 - regression_loss: 3.3533 - classification_acc: 0.9605 - regression_r2_keras: 0.9610 - val_loss: 4.6591 - val_classification_loss: 0.0247 - val_regression_loss: 3.6977 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9537\n",
            "Epoch 103/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.9658 - classification_loss: 0.1333 - regression_loss: 3.4620 - classification_acc: 0.9553 - regression_r2_keras: 0.9599\n",
            "Epoch : 102 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 4.9658 - classification_loss: 0.1333 - regression_loss: 3.4620 - classification_acc: 0.9553 - regression_r2_keras: 0.9599 - val_loss: 4.0789 - val_classification_loss: 0.0201 - val_regression_loss: 3.1393 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9603\n",
            "Epoch 104/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.9024 - classification_loss: 0.1380 - regression_loss: 3.3740 - classification_acc: 0.9558 - regression_r2_keras: 0.9605INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 103 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 33s 163ms/step - loss: 4.9024 - classification_loss: 0.1380 - regression_loss: 3.3740 - classification_acc: 0.9558 - regression_r2_keras: 0.9605 - val_loss: 3.6148 - val_classification_loss: 0.0133 - val_regression_loss: 2.7097 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9656\n",
            "Epoch 105/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.8991 - classification_loss: 0.1279 - regression_loss: 3.4245 - classification_acc: 0.9589 - regression_r2_keras: 0.9601\n",
            "Epoch : 104 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 4.8991 - classification_loss: 0.1279 - regression_loss: 3.4245 - classification_acc: 0.9589 - regression_r2_keras: 0.9601 - val_loss: 5.1012 - val_classification_loss: 0.0178 - val_regression_loss: 4.1821 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9480\n",
            "Epoch 106/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.9532 - classification_loss: 0.1263 - regression_loss: 3.4872 - classification_acc: 0.9581 - regression_r2_keras: 0.9593\n",
            "Epoch : 105 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 155ms/step - loss: 4.9532 - classification_loss: 0.1263 - regression_loss: 3.4872 - classification_acc: 0.9581 - regression_r2_keras: 0.9593 - val_loss: 3.6324 - val_classification_loss: 0.0184 - val_regression_loss: 2.7070 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9656\n",
            "Epoch 107/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.6642 - classification_loss: 0.1161 - regression_loss: 3.2545 - classification_acc: 0.9638 - regression_r2_keras: 0.9621\n",
            "Epoch : 106 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 4.6642 - classification_loss: 0.1161 - regression_loss: 3.2545 - classification_acc: 0.9638 - regression_r2_keras: 0.9621 - val_loss: 3.7803 - val_classification_loss: 0.0170 - val_regression_loss: 2.8632 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9636\n",
            "Epoch 108/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.8028 - classification_loss: 0.1216 - regression_loss: 3.3670 - classification_acc: 0.9639 - regression_r2_keras: 0.9608\n",
            "Epoch : 107 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 4.8028 - classification_loss: 0.1216 - regression_loss: 3.3670 - classification_acc: 0.9639 - regression_r2_keras: 0.9608 - val_loss: 4.5979 - val_classification_loss: 0.0131 - val_regression_loss: 3.7066 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9535\n",
            "Epoch 109/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.7640 - classification_loss: 0.1302 - regression_loss: 3.2832 - classification_acc: 0.9597 - regression_r2_keras: 0.9618\n",
            "Epoch : 108 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 4.7640 - classification_loss: 0.1302 - regression_loss: 3.2832 - classification_acc: 0.9597 - regression_r2_keras: 0.9618 - val_loss: 3.8999 - val_classification_loss: 0.0152 - val_regression_loss: 2.9952 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9620\n",
            "Epoch 110/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.7883 - classification_loss: 0.1261 - regression_loss: 3.3298 - classification_acc: 0.9584 - regression_r2_keras: 0.9613\n",
            "Epoch : 109 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 4.7883 - classification_loss: 0.1261 - regression_loss: 3.3298 - classification_acc: 0.9584 - regression_r2_keras: 0.9613 - val_loss: 4.5017 - val_classification_loss: 0.0228 - val_regression_loss: 3.5614 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9552\n",
            "Epoch 111/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.7941 - classification_loss: 0.1315 - regression_loss: 3.3089 - classification_acc: 0.9588 - regression_r2_keras: 0.9616\n",
            "Epoch : 110 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 155ms/step - loss: 4.7941 - classification_loss: 0.1315 - regression_loss: 3.3089 - classification_acc: 0.9588 - regression_r2_keras: 0.9616 - val_loss: 4.5830 - val_classification_loss: 0.0228 - val_regression_loss: 3.6420 - val_classification_acc: 0.9932 - val_regression_r2_keras: 0.9544\n",
            "Epoch 112/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.6516 - classification_loss: 0.1214 - regression_loss: 3.2173 - classification_acc: 0.9597 - regression_r2_keras: 0.9626\n",
            "Epoch : 111 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 4.6516 - classification_loss: 0.1214 - regression_loss: 3.2173 - classification_acc: 0.9597 - regression_r2_keras: 0.9626 - val_loss: 3.7725 - val_classification_loss: 0.0158 - val_regression_loss: 2.8678 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9637\n",
            "Epoch 113/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.5967 - classification_loss: 0.1239 - regression_loss: 3.1519 - classification_acc: 0.9592 - regression_r2_keras: 0.9632\n",
            "Epoch : 112 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 155ms/step - loss: 4.5967 - classification_loss: 0.1239 - regression_loss: 3.1519 - classification_acc: 0.9592 - regression_r2_keras: 0.9632 - val_loss: 3.6578 - val_classification_loss: 0.0176 - val_regression_loss: 2.7465 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9652\n",
            "Epoch 114/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.5281 - classification_loss: 0.1015 - regression_loss: 3.2031 - classification_acc: 0.9692 - regression_r2_keras: 0.9626INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 113 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 32s 161ms/step - loss: 4.5281 - classification_loss: 0.1015 - regression_loss: 3.2031 - classification_acc: 0.9692 - regression_r2_keras: 0.9626 - val_loss: 3.5459 - val_classification_loss: 0.0168 - val_regression_loss: 2.6480 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9662\n",
            "Epoch 115/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.7711 - classification_loss: 0.1222 - regression_loss: 3.3445 - classification_acc: 0.9605 - regression_r2_keras: 0.9610\n",
            "Epoch : 114 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 4.7711 - classification_loss: 0.1222 - regression_loss: 3.3445 - classification_acc: 0.9605 - regression_r2_keras: 0.9610 - val_loss: 4.3212 - val_classification_loss: 0.0166 - val_regression_loss: 3.4239 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9570\n",
            "Epoch 116/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.5278 - classification_loss: 0.1193 - regression_loss: 3.1145 - classification_acc: 0.9616 - regression_r2_keras: 0.9637\n",
            "Epoch : 115 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 4.5278 - classification_loss: 0.1193 - regression_loss: 3.1145 - classification_acc: 0.9616 - regression_r2_keras: 0.9637 - val_loss: 3.7839 - val_classification_loss: 0.0096 - val_regression_loss: 2.9218 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9631\n",
            "Epoch 117/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.6450 - classification_loss: 0.1187 - regression_loss: 3.2375 - classification_acc: 0.9648 - regression_r2_keras: 0.9622\n",
            "Epoch : 116 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 31s 155ms/step - loss: 4.6450 - classification_loss: 0.1187 - regression_loss: 3.2375 - classification_acc: 0.9648 - regression_r2_keras: 0.9622 - val_loss: 3.9629 - val_classification_loss: 0.0171 - val_regression_loss: 3.0628 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9613\n",
            "Epoch 118/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.5574 - classification_loss: 0.1091 - regression_loss: 3.1975 - classification_acc: 0.9659 - regression_r2_keras: 0.9627INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 117 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 31s 157ms/step - loss: 4.5574 - classification_loss: 0.1091 - regression_loss: 3.1975 - classification_acc: 0.9659 - regression_r2_keras: 0.9627 - val_loss: 3.4782 - val_classification_loss: 0.0152 - val_regression_loss: 2.5889 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9670\n",
            "Epoch 119/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.5173 - classification_loss: 0.1148 - regression_loss: 3.1328 - classification_acc: 0.9648 - regression_r2_keras: 0.9636INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 118 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 33s 165ms/step - loss: 4.5173 - classification_loss: 0.1148 - regression_loss: 3.1328 - classification_acc: 0.9648 - regression_r2_keras: 0.9636 - val_loss: 3.3696 - val_classification_loss: 0.0122 - val_regression_loss: 2.4968 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9681\n",
            "Epoch 120/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.5633 - classification_loss: 0.1062 - regression_loss: 3.2227 - classification_acc: 0.9659 - regression_r2_keras: 0.9624\n",
            "Epoch : 119 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 4.5633 - classification_loss: 0.1062 - regression_loss: 3.2227 - classification_acc: 0.9659 - regression_r2_keras: 0.9624 - val_loss: 3.8762 - val_classification_loss: 0.0168 - val_regression_loss: 2.9813 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9624\n",
            "Epoch 121/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.5003 - classification_loss: 0.1161 - regression_loss: 3.1091 - classification_acc: 0.9609 - regression_r2_keras: 0.9637\n",
            "Epoch : 120 -  Precision_Score : 1.00 - Recall_Score : 0.94 - F1_Score : 0.97\n",
            "\n",
            "200/200 [==============================] - 31s 155ms/step - loss: 4.5003 - classification_loss: 0.1161 - regression_loss: 3.1091 - classification_acc: 0.9609 - regression_r2_keras: 0.9637 - val_loss: 3.9320 - val_classification_loss: 0.0187 - val_regression_loss: 3.0278 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9618\n",
            "Epoch 122/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.3824 - classification_loss: 0.1099 - regression_loss: 3.0253 - classification_acc: 0.9642 - regression_r2_keras: 0.9648\n",
            "Epoch : 121 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 4.3824 - classification_loss: 0.1099 - regression_loss: 3.0253 - classification_acc: 0.9642 - regression_r2_keras: 0.9648 - val_loss: 3.5822 - val_classification_loss: 0.0201 - val_regression_loss: 2.6732 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9660\n",
            "Epoch 123/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.6015 - classification_loss: 0.1270 - regression_loss: 3.1546 - classification_acc: 0.9623 - regression_r2_keras: 0.9633\n",
            "Epoch : 122 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 4.6015 - classification_loss: 0.1270 - regression_loss: 3.1546 - classification_acc: 0.9623 - regression_r2_keras: 0.9633 - val_loss: 3.9340 - val_classification_loss: 0.0130 - val_regression_loss: 3.0568 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9615\n",
            "Epoch 124/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.4072 - classification_loss: 0.0987 - regression_loss: 3.1051 - classification_acc: 0.9683 - regression_r2_keras: 0.9640\n",
            "Epoch : 123 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 153ms/step - loss: 4.4072 - classification_loss: 0.0987 - regression_loss: 3.1051 - classification_acc: 0.9683 - regression_r2_keras: 0.9640 - val_loss: 3.8209 - val_classification_loss: 0.0086 - val_regression_loss: 2.9757 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9625\n",
            "Epoch 125/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.2905 - classification_loss: 0.1010 - regression_loss: 2.9862 - classification_acc: 0.9661 - regression_r2_keras: 0.9653\n",
            "Epoch : 124 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 4.2905 - classification_loss: 0.1010 - regression_loss: 2.9862 - classification_acc: 0.9661 - regression_r2_keras: 0.9653 - val_loss: 3.8819 - val_classification_loss: 0.0153 - val_regression_loss: 3.0066 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9620\n",
            "Epoch 126/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.2985 - classification_loss: 0.0943 - regression_loss: 3.0308 - classification_acc: 0.9689 - regression_r2_keras: 0.9647\n",
            "Epoch : 125 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 4.2985 - classification_loss: 0.0943 - regression_loss: 3.0308 - classification_acc: 0.9689 - regression_r2_keras: 0.9647 - val_loss: 4.3639 - val_classification_loss: 0.0183 - val_regression_loss: 3.4810 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9564\n",
            "Epoch 127/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.3685 - classification_loss: 0.1142 - regression_loss: 3.0009 - classification_acc: 0.9631 - regression_r2_keras: 0.9650\n",
            "Epoch : 126 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 4.3685 - classification_loss: 0.1142 - regression_loss: 3.0009 - classification_acc: 0.9631 - regression_r2_keras: 0.9650 - val_loss: 3.9494 - val_classification_loss: 0.0103 - val_regression_loss: 3.1035 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9608\n",
            "Epoch 128/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.3529 - classification_loss: 0.1098 - regression_loss: 3.0103 - classification_acc: 0.9648 - regression_r2_keras: 0.9650\n",
            "Epoch : 127 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 4.3529 - classification_loss: 0.1098 - regression_loss: 3.0103 - classification_acc: 0.9648 - regression_r2_keras: 0.9650 - val_loss: 3.8216 - val_classification_loss: 0.0154 - val_regression_loss: 2.9490 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9628\n",
            "Epoch 129/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.2765 - classification_loss: 0.1097 - regression_loss: 2.9321 - classification_acc: 0.9630 - regression_r2_keras: 0.9658\n",
            "Epoch : 128 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 4.2765 - classification_loss: 0.1097 - regression_loss: 2.9321 - classification_acc: 0.9630 - regression_r2_keras: 0.9658 - val_loss: 3.6074 - val_classification_loss: 0.0144 - val_regression_loss: 2.7377 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9654\n",
            "Epoch 130/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.3904 - classification_loss: 0.0976 - regression_loss: 3.1055 - classification_acc: 0.9691 - regression_r2_keras: 0.9636\n",
            "Epoch : 129 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 4.3904 - classification_loss: 0.0976 - regression_loss: 3.1055 - classification_acc: 0.9691 - regression_r2_keras: 0.9636 - val_loss: 4.6812 - val_classification_loss: 0.0218 - val_regression_loss: 3.7791 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9528\n",
            "Epoch 131/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.2233 - classification_loss: 0.1080 - regression_loss: 2.8903 - classification_acc: 0.9667 - regression_r2_keras: 0.9664\n",
            "Epoch : 130 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 4.2233 - classification_loss: 0.1080 - regression_loss: 2.8903 - classification_acc: 0.9667 - regression_r2_keras: 0.9664 - val_loss: 3.8598 - val_classification_loss: 0.0150 - val_regression_loss: 2.9956 - val_classification_acc: 0.9951 - val_regression_r2_keras: 0.9622\n",
            "Epoch 132/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.2316 - classification_loss: 0.1016 - regression_loss: 2.9323 - classification_acc: 0.9694 - regression_r2_keras: 0.9658\n",
            "Epoch : 131 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 4.2316 - classification_loss: 0.1016 - regression_loss: 2.9323 - classification_acc: 0.9694 - regression_r2_keras: 0.9658 - val_loss: 3.6788 - val_classification_loss: 0.0121 - val_regression_loss: 2.8298 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9643\n",
            "Epoch 133/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.2101 - classification_loss: 0.1051 - regression_loss: 2.8965 - classification_acc: 0.9684 - regression_r2_keras: 0.9663\n",
            "Epoch : 132 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 4.2101 - classification_loss: 0.1051 - regression_loss: 2.8965 - classification_acc: 0.9684 - regression_r2_keras: 0.9663 - val_loss: 4.0520 - val_classification_loss: 0.0168 - val_regression_loss: 3.1801 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9601\n",
            "Epoch 134/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.0631 - classification_loss: 0.0979 - regression_loss: 2.7877 - classification_acc: 0.9686 - regression_r2_keras: 0.9676\n",
            "Epoch : 133 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 4.0631 - classification_loss: 0.0979 - regression_loss: 2.7877 - classification_acc: 0.9686 - regression_r2_keras: 0.9676 - val_loss: 4.1500 - val_classification_loss: 0.0112 - val_regression_loss: 3.3120 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9584\n",
            "Epoch 135/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.1121 - classification_loss: 0.1020 - regression_loss: 2.8199 - classification_acc: 0.9686 - regression_r2_keras: 0.9670\n",
            "Epoch : 134 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 4.1121 - classification_loss: 0.1020 - regression_loss: 2.8199 - classification_acc: 0.9686 - regression_r2_keras: 0.9670 - val_loss: 3.5173 - val_classification_loss: 0.0146 - val_regression_loss: 2.6619 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9663\n",
            "Epoch 136/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.1905 - classification_loss: 0.0998 - regression_loss: 2.9090 - classification_acc: 0.9672 - regression_r2_keras: 0.9661INFO:tensorflow:Assets written to: /content/drive/My Drive/CaseStudy2/best_models/TrafficSignRecog-first-cut-1656489931/assets\n",
            "\n",
            "Epoch : 135 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 32s 159ms/step - loss: 4.1905 - classification_loss: 0.0998 - regression_loss: 2.9090 - classification_acc: 0.9672 - regression_r2_keras: 0.9661 - val_loss: 3.2877 - val_classification_loss: 0.0100 - val_regression_loss: 2.4533 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9688\n",
            "Epoch 137/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.9697 - classification_loss: 0.0882 - regression_loss: 2.7500 - classification_acc: 0.9692 - regression_r2_keras: 0.9679\n",
            "Epoch : 136 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 3.9697 - classification_loss: 0.0882 - regression_loss: 2.7500 - classification_acc: 0.9692 - regression_r2_keras: 0.9679 - val_loss: 3.5019 - val_classification_loss: 0.0149 - val_regression_loss: 2.6503 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9664\n",
            "Epoch 138/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.0891 - classification_loss: 0.0873 - regression_loss: 2.8787 - classification_acc: 0.9709 - regression_r2_keras: 0.9665\n",
            "Epoch : 137 -  Precision_Score : 1.00 - Recall_Score : 0.97 - F1_Score : 0.98\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 4.0891 - classification_loss: 0.0873 - regression_loss: 2.8787 - classification_acc: 0.9709 - regression_r2_keras: 0.9665 - val_loss: 3.3804 - val_classification_loss: 0.0081 - val_regression_loss: 2.5670 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9674\n",
            "Epoch 139/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.1149 - classification_loss: 0.0891 - regression_loss: 2.9003 - classification_acc: 0.9698 - regression_r2_keras: 0.9662\n",
            "Epoch : 138 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 4.1149 - classification_loss: 0.0891 - regression_loss: 2.9003 - classification_acc: 0.9698 - regression_r2_keras: 0.9662 - val_loss: 3.5305 - val_classification_loss: 0.0126 - val_regression_loss: 2.6998 - val_classification_acc: 0.9971 - val_regression_r2_keras: 0.9658\n",
            "Epoch 140/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.1214 - classification_loss: 0.0951 - regression_loss: 2.8772 - classification_acc: 0.9689 - regression_r2_keras: 0.9666\n",
            "Epoch : 139 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 4.1214 - classification_loss: 0.0951 - regression_loss: 2.8772 - classification_acc: 0.9689 - regression_r2_keras: 0.9666 - val_loss: 3.5991 - val_classification_loss: 0.0165 - val_regression_loss: 2.7439 - val_classification_acc: 0.9941 - val_regression_r2_keras: 0.9653\n",
            "Epoch 141/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.1117 - classification_loss: 0.0997 - regression_loss: 2.8432 - classification_acc: 0.9688 - regression_r2_keras: 0.9667\n",
            "Epoch : 140 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 4.1117 - classification_loss: 0.0997 - regression_loss: 2.8432 - classification_acc: 0.9688 - regression_r2_keras: 0.9667 - val_loss: 3.4805 - val_classification_loss: 0.0067 - val_regression_loss: 2.6746 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9661\n",
            "Epoch 142/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.8631 - classification_loss: 0.0820 - regression_loss: 2.6838 - classification_acc: 0.9739 - regression_r2_keras: 0.9688\n",
            "Epoch : 141 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 3.8631 - classification_loss: 0.0820 - regression_loss: 2.6838 - classification_acc: 0.9739 - regression_r2_keras: 0.9688 - val_loss: 3.4865 - val_classification_loss: 0.0080 - val_regression_loss: 2.6815 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9660\n",
            "Epoch 143/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.8036 - classification_loss: 0.0919 - regression_loss: 2.5807 - classification_acc: 0.9697 - regression_r2_keras: 0.9701\n",
            "Epoch : 142 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 32s 158ms/step - loss: 3.8036 - classification_loss: 0.0919 - regression_loss: 2.5807 - classification_acc: 0.9697 - regression_r2_keras: 0.9701 - val_loss: 3.2920 - val_classification_loss: 0.0048 - val_regression_loss: 2.5059 - val_classification_acc: 0.9990 - val_regression_r2_keras: 0.9681\n",
            "Epoch 144/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.9996 - classification_loss: 0.0848 - regression_loss: 2.8153 - classification_acc: 0.9698 - regression_r2_keras: 0.9670\n",
            "Epoch : 143 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 155ms/step - loss: 3.9996 - classification_loss: 0.0848 - regression_loss: 2.8153 - classification_acc: 0.9698 - regression_r2_keras: 0.9670 - val_loss: 3.4271 - val_classification_loss: 0.0060 - val_regression_loss: 2.6391 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9665\n",
            "Epoch 145/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.9158 - classification_loss: 0.0778 - regression_loss: 2.7708 - classification_acc: 0.9775 - regression_r2_keras: 0.9676\n",
            "Epoch : 144 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 3.9158 - classification_loss: 0.0778 - regression_loss: 2.7708 - classification_acc: 0.9775 - regression_r2_keras: 0.9676 - val_loss: 3.4864 - val_classification_loss: 0.0127 - val_regression_loss: 2.6678 - val_classification_acc: 0.9961 - val_regression_r2_keras: 0.9663\n",
            "Epoch 146/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.0519 - classification_loss: 0.1036 - regression_loss: 2.7751 - classification_acc: 0.9695 - regression_r2_keras: 0.9677\n",
            "Epoch : 145 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 4.0519 - classification_loss: 0.1036 - regression_loss: 2.7751 - classification_acc: 0.9695 - regression_r2_keras: 0.9677 - val_loss: 3.6290 - val_classification_loss: 0.0067 - val_regression_loss: 2.8385 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9642\n",
            "Epoch 147/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.8961 - classification_loss: 0.0873 - regression_loss: 2.7010 - classification_acc: 0.9723 - regression_r2_keras: 0.9685\n",
            "Epoch : 146 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 31s 157ms/step - loss: 3.8961 - classification_loss: 0.0873 - regression_loss: 2.7010 - classification_acc: 0.9723 - regression_r2_keras: 0.9685 - val_loss: 3.8837 - val_classification_loss: 0.0093 - val_regression_loss: 3.0821 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9613\n",
            "Epoch 148/200\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.8765 - classification_loss: 0.0784 - regression_loss: 2.7300 - classification_acc: 0.9778 - regression_r2_keras: 0.9681\n",
            "Epoch : 147 -  Precision_Score : 1.00 - Recall_Score : 1.00 - F1_Score : 1.00\n",
            "\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 3.8765 - classification_loss: 0.0784 - regression_loss: 2.7300 - classification_acc: 0.9778 - regression_r2_keras: 0.9681 - val_loss: 3.3012 - val_classification_loss: 0.0121 - val_regression_loss: 2.4876 - val_classification_acc: 0.9980 - val_regression_r2_keras: 0.9683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test_images(path, model) :\n",
        "  \"\"\"\n",
        "  Function to make predictions for the test set images\n",
        "  \"\"\"\n",
        "  labels = []\n",
        "  bbox = []\n",
        "  all_imgs = os.listdir(path)\n",
        "  all_imgs.sort()\n",
        "  for img in tqdm(all_imgs) :\n",
        "    if '.png' in img :\n",
        "      image_string = tf.io.read_file(path + '/' + img)\n",
        "      #Loading and decoding image\n",
        "      image = tf.image.decode_png(image_string, channels=N_CHANNELS)\n",
        "      #Converting image data type to float\n",
        "      image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "      #Adjusting image brightness and contrast\n",
        "      if tf.math.reduce_mean(image) < 0.3 :\n",
        "        image = tf.image.adjust_contrast(image, 5)\n",
        "        image = tf.image.adjust_brightness(image, 0.2)\n",
        "      #Resizing image\n",
        "      image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=\"nearest\", preserve_aspect_ratio=False)\n",
        "      image = image/255.0\n",
        "      image = np.expand_dims(image, axis=0)\n",
        "      #Predicting output\n",
        "      pred = model.predict(image)\n",
        "      labels.append(np.argmax(pred[0][0]))\n",
        "      bbox.append(pred[1][0])\n",
        "  return labels, bbox"
      ],
      "metadata": {
        "id": "rJtWlv8odJB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_test_images('/content/Data/test', model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18hECwPCw8Ne",
        "outputId": "110e8af0-fa04-499f-9f85-6cf165b202f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12631/12631 [13:37<00:00, 15.45it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([16,\n",
              "  1,\n",
              "  38,\n",
              "  33,\n",
              "  11,\n",
              "  38,\n",
              "  18,\n",
              "  12,\n",
              "  25,\n",
              "  35,\n",
              "  12,\n",
              "  7,\n",
              "  23,\n",
              "  5,\n",
              "  4,\n",
              "  9,\n",
              "  21,\n",
              "  20,\n",
              "  27,\n",
              "  38,\n",
              "  4,\n",
              "  33,\n",
              "  9,\n",
              "  3,\n",
              "  1,\n",
              "  11,\n",
              "  13,\n",
              "  10,\n",
              "  9,\n",
              "  11,\n",
              "  5,\n",
              "  17,\n",
              "  34,\n",
              "  23,\n",
              "  2,\n",
              "  17,\n",
              "  3,\n",
              "  12,\n",
              "  16,\n",
              "  8,\n",
              "  7,\n",
              "  30,\n",
              "  18,\n",
              "  12,\n",
              "  24,\n",
              "  25,\n",
              "  3,\n",
              "  10,\n",
              "  18,\n",
              "  8,\n",
              "  18,\n",
              "  13,\n",
              "  15,\n",
              "  9,\n",
              "  13,\n",
              "  35,\n",
              "  5,\n",
              "  26,\n",
              "  9,\n",
              "  16,\n",
              "  38,\n",
              "  10,\n",
              "  4,\n",
              "  9,\n",
              "  15,\n",
              "  9,\n",
              "  26,\n",
              "  2,\n",
              "  5,\n",
              "  28,\n",
              "  11,\n",
              "  25,\n",
              "  11,\n",
              "  34,\n",
              "  5,\n",
              "  12,\n",
              "  1,\n",
              "  10,\n",
              "  25,\n",
              "  25,\n",
              "  21,\n",
              "  33,\n",
              "  25,\n",
              "  5,\n",
              "  10,\n",
              "  35,\n",
              "  3,\n",
              "  7,\n",
              "  22,\n",
              "  13,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  14,\n",
              "  12,\n",
              "  32,\n",
              "  3,\n",
              "  38,\n",
              "  9,\n",
              "  33,\n",
              "  1,\n",
              "  10,\n",
              "  5,\n",
              "  11,\n",
              "  33,\n",
              "  4,\n",
              "  35,\n",
              "  25,\n",
              "  33,\n",
              "  4,\n",
              "  1,\n",
              "  14,\n",
              "  16,\n",
              "  10,\n",
              "  30,\n",
              "  3,\n",
              "  27,\n",
              "  29,\n",
              "  1,\n",
              "  17,\n",
              "  13,\n",
              "  7,\n",
              "  1,\n",
              "  8,\n",
              "  2,\n",
              "  10,\n",
              "  10,\n",
              "  11,\n",
              "  1,\n",
              "  6,\n",
              "  36,\n",
              "  3,\n",
              "  14,\n",
              "  13,\n",
              "  11,\n",
              "  10,\n",
              "  18,\n",
              "  7,\n",
              "  2,\n",
              "  38,\n",
              "  41,\n",
              "  4,\n",
              "  6,\n",
              "  18,\n",
              "  17,\n",
              "  25,\n",
              "  2,\n",
              "  9,\n",
              "  11,\n",
              "  21,\n",
              "  5,\n",
              "  24,\n",
              "  11,\n",
              "  25,\n",
              "  17,\n",
              "  3,\n",
              "  6,\n",
              "  9,\n",
              "  7,\n",
              "  4,\n",
              "  13,\n",
              "  16,\n",
              "  4,\n",
              "  25,\n",
              "  18,\n",
              "  9,\n",
              "  13,\n",
              "  14,\n",
              "  29,\n",
              "  17,\n",
              "  13,\n",
              "  38,\n",
              "  26,\n",
              "  25,\n",
              "  33,\n",
              "  1,\n",
              "  5,\n",
              "  40,\n",
              "  13,\n",
              "  2,\n",
              "  8,\n",
              "  4,\n",
              "  36,\n",
              "  25,\n",
              "  20,\n",
              "  25,\n",
              "  18,\n",
              "  1,\n",
              "  10,\n",
              "  8,\n",
              "  10,\n",
              "  29,\n",
              "  12,\n",
              "  38,\n",
              "  31,\n",
              "  2,\n",
              "  8,\n",
              "  38,\n",
              "  1,\n",
              "  28,\n",
              "  17,\n",
              "  9,\n",
              "  4,\n",
              "  1,\n",
              "  17,\n",
              "  9,\n",
              "  2,\n",
              "  31,\n",
              "  13,\n",
              "  15,\n",
              "  15,\n",
              "  38,\n",
              "  25,\n",
              "  5,\n",
              "  25,\n",
              "  13,\n",
              "  10,\n",
              "  5,\n",
              "  4,\n",
              "  10,\n",
              "  2,\n",
              "  4,\n",
              "  5,\n",
              "  1,\n",
              "  14,\n",
              "  12,\n",
              "  12,\n",
              "  5,\n",
              "  8,\n",
              "  36,\n",
              "  25,\n",
              "  13,\n",
              "  33,\n",
              "  18,\n",
              "  33,\n",
              "  19,\n",
              "  12,\n",
              "  30,\n",
              "  4,\n",
              "  18,\n",
              "  12,\n",
              "  13,\n",
              "  20,\n",
              "  0,\n",
              "  10,\n",
              "  40,\n",
              "  5,\n",
              "  5,\n",
              "  12,\n",
              "  38,\n",
              "  20,\n",
              "  14,\n",
              "  0,\n",
              "  36,\n",
              "  34,\n",
              "  28,\n",
              "  35,\n",
              "  13,\n",
              "  25,\n",
              "  15,\n",
              "  35,\n",
              "  14,\n",
              "  18,\n",
              "  25,\n",
              "  1,\n",
              "  12,\n",
              "  5,\n",
              "  25,\n",
              "  2,\n",
              "  18,\n",
              "  18,\n",
              "  18,\n",
              "  34,\n",
              "  9,\n",
              "  25,\n",
              "  18,\n",
              "  34,\n",
              "  39,\n",
              "  31,\n",
              "  1,\n",
              "  9,\n",
              "  35,\n",
              "  31,\n",
              "  26,\n",
              "  1,\n",
              "  1,\n",
              "  33,\n",
              "  30,\n",
              "  17,\n",
              "  13,\n",
              "  1,\n",
              "  31,\n",
              "  13,\n",
              "  35,\n",
              "  5,\n",
              "  1,\n",
              "  33,\n",
              "  28,\n",
              "  35,\n",
              "  26,\n",
              "  12,\n",
              "  5,\n",
              "  2,\n",
              "  14,\n",
              "  4,\n",
              "  3,\n",
              "  32,\n",
              "  1,\n",
              "  7,\n",
              "  38,\n",
              "  19,\n",
              "  11,\n",
              "  38,\n",
              "  38,\n",
              "  1,\n",
              "  42,\n",
              "  2,\n",
              "  40,\n",
              "  17,\n",
              "  4,\n",
              "  8,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  31,\n",
              "  35,\n",
              "  9,\n",
              "  38,\n",
              "  8,\n",
              "  2,\n",
              "  4,\n",
              "  18,\n",
              "  3,\n",
              "  25,\n",
              "  10,\n",
              "  32,\n",
              "  7,\n",
              "  34,\n",
              "  4,\n",
              "  22,\n",
              "  10,\n",
              "  29,\n",
              "  9,\n",
              "  2,\n",
              "  38,\n",
              "  38,\n",
              "  18,\n",
              "  8,\n",
              "  13,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  16,\n",
              "  14,\n",
              "  12,\n",
              "  7,\n",
              "  35,\n",
              "  3,\n",
              "  38,\n",
              "  10,\n",
              "  9,\n",
              "  38,\n",
              "  13,\n",
              "  39,\n",
              "  3,\n",
              "  11,\n",
              "  7,\n",
              "  38,\n",
              "  19,\n",
              "  13,\n",
              "  10,\n",
              "  18,\n",
              "  3,\n",
              "  5,\n",
              "  25,\n",
              "  1,\n",
              "  41,\n",
              "  13,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  13,\n",
              "  38,\n",
              "  4,\n",
              "  35,\n",
              "  25,\n",
              "  34,\n",
              "  12,\n",
              "  17,\n",
              "  9,\n",
              "  4,\n",
              "  33,\n",
              "  28,\n",
              "  2,\n",
              "  1,\n",
              "  5,\n",
              "  4,\n",
              "  38,\n",
              "  4,\n",
              "  12,\n",
              "  38,\n",
              "  36,\n",
              "  10,\n",
              "  0,\n",
              "  38,\n",
              "  36,\n",
              "  8,\n",
              "  25,\n",
              "  5,\n",
              "  2,\n",
              "  25,\n",
              "  14,\n",
              "  2,\n",
              "  26,\n",
              "  29,\n",
              "  10,\n",
              "  10,\n",
              "  14,\n",
              "  9,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  19,\n",
              "  9,\n",
              "  10,\n",
              "  13,\n",
              "  13,\n",
              "  20,\n",
              "  38,\n",
              "  34,\n",
              "  11,\n",
              "  13,\n",
              "  34,\n",
              "  34,\n",
              "  12,\n",
              "  6,\n",
              "  10,\n",
              "  10,\n",
              "  8,\n",
              "  3,\n",
              "  22,\n",
              "  17,\n",
              "  7,\n",
              "  30,\n",
              "  25,\n",
              "  1,\n",
              "  31,\n",
              "  38,\n",
              "  38,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  2,\n",
              "  40,\n",
              "  1,\n",
              "  34,\n",
              "  14,\n",
              "  8,\n",
              "  39,\n",
              "  6,\n",
              "  35,\n",
              "  25,\n",
              "  25,\n",
              "  17,\n",
              "  2,\n",
              "  38,\n",
              "  7,\n",
              "  13,\n",
              "  14,\n",
              "  7,\n",
              "  8,\n",
              "  35,\n",
              "  3,\n",
              "  1,\n",
              "  35,\n",
              "  12,\n",
              "  35,\n",
              "  36,\n",
              "  24,\n",
              "  13,\n",
              "  33,\n",
              "  2,\n",
              "  35,\n",
              "  6,\n",
              "  2,\n",
              "  10,\n",
              "  12,\n",
              "  31,\n",
              "  9,\n",
              "  14,\n",
              "  17,\n",
              "  26,\n",
              "  2,\n",
              "  3,\n",
              "  10,\n",
              "  5,\n",
              "  30,\n",
              "  9,\n",
              "  31,\n",
              "  12,\n",
              "  22,\n",
              "  23,\n",
              "  9,\n",
              "  7,\n",
              "  23,\n",
              "  4,\n",
              "  32,\n",
              "  42,\n",
              "  1,\n",
              "  3,\n",
              "  8,\n",
              "  2,\n",
              "  25,\n",
              "  22,\n",
              "  38,\n",
              "  33,\n",
              "  3,\n",
              "  1,\n",
              "  8,\n",
              "  4,\n",
              "  18,\n",
              "  26,\n",
              "  31,\n",
              "  14,\n",
              "  11,\n",
              "  13,\n",
              "  3,\n",
              "  5,\n",
              "  18,\n",
              "  4,\n",
              "  13,\n",
              "  15,\n",
              "  23,\n",
              "  1,\n",
              "  12,\n",
              "  31,\n",
              "  38,\n",
              "  32,\n",
              "  10,\n",
              "  35,\n",
              "  8,\n",
              "  6,\n",
              "  5,\n",
              "  12,\n",
              "  4,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  12,\n",
              "  12,\n",
              "  5,\n",
              "  5,\n",
              "  9,\n",
              "  13,\n",
              "  38,\n",
              "  4,\n",
              "  13,\n",
              "  8,\n",
              "  13,\n",
              "  24,\n",
              "  17,\n",
              "  10,\n",
              "  10,\n",
              "  18,\n",
              "  12,\n",
              "  23,\n",
              "  10,\n",
              "  10,\n",
              "  1,\n",
              "  23,\n",
              "  3,\n",
              "  8,\n",
              "  41,\n",
              "  6,\n",
              "  13,\n",
              "  33,\n",
              "  3,\n",
              "  2,\n",
              "  13,\n",
              "  0,\n",
              "  17,\n",
              "  10,\n",
              "  7,\n",
              "  1,\n",
              "  35,\n",
              "  10,\n",
              "  2,\n",
              "  30,\n",
              "  5,\n",
              "  5,\n",
              "  35,\n",
              "  13,\n",
              "  16,\n",
              "  17,\n",
              "  11,\n",
              "  3,\n",
              "  4,\n",
              "  29,\n",
              "  2,\n",
              "  26,\n",
              "  2,\n",
              "  11,\n",
              "  4,\n",
              "  19,\n",
              "  3,\n",
              "  9,\n",
              "  5,\n",
              "  38,\n",
              "  28,\n",
              "  9,\n",
              "  27,\n",
              "  41,\n",
              "  1,\n",
              "  29,\n",
              "  11,\n",
              "  10,\n",
              "  25,\n",
              "  1,\n",
              "  10,\n",
              "  38,\n",
              "  30,\n",
              "  14,\n",
              "  1,\n",
              "  12,\n",
              "  8,\n",
              "  13,\n",
              "  28,\n",
              "  8,\n",
              "  2,\n",
              "  17,\n",
              "  5,\n",
              "  35,\n",
              "  25,\n",
              "  8,\n",
              "  4,\n",
              "  7,\n",
              "  16,\n",
              "  29,\n",
              "  17,\n",
              "  9,\n",
              "  7,\n",
              "  8,\n",
              "  17,\n",
              "  11,\n",
              "  2,\n",
              "  13,\n",
              "  12,\n",
              "  7,\n",
              "  1,\n",
              "  2,\n",
              "  32,\n",
              "  17,\n",
              "  13,\n",
              "  5,\n",
              "  12,\n",
              "  11,\n",
              "  29,\n",
              "  13,\n",
              "  13,\n",
              "  10,\n",
              "  5,\n",
              "  13,\n",
              "  2,\n",
              "  7,\n",
              "  13,\n",
              "  10,\n",
              "  14,\n",
              "  13,\n",
              "  11,\n",
              "  4,\n",
              "  15,\n",
              "  10,\n",
              "  36,\n",
              "  35,\n",
              "  26,\n",
              "  0,\n",
              "  25,\n",
              "  18,\n",
              "  29,\n",
              "  8,\n",
              "  13,\n",
              "  14,\n",
              "  35,\n",
              "  12,\n",
              "  35,\n",
              "  35,\n",
              "  14,\n",
              "  25,\n",
              "  17,\n",
              "  34,\n",
              "  5,\n",
              "  4,\n",
              "  4,\n",
              "  13,\n",
              "  29,\n",
              "  4,\n",
              "  5,\n",
              "  8,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  39,\n",
              "  12,\n",
              "  7,\n",
              "  16,\n",
              "  12,\n",
              "  12,\n",
              "  26,\n",
              "  16,\n",
              "  2,\n",
              "  36,\n",
              "  11,\n",
              "  39,\n",
              "  4,\n",
              "  6,\n",
              "  2,\n",
              "  36,\n",
              "  1,\n",
              "  5,\n",
              "  10,\n",
              "  13,\n",
              "  5,\n",
              "  30,\n",
              "  38,\n",
              "  13,\n",
              "  14,\n",
              "  11,\n",
              "  11,\n",
              "  35,\n",
              "  25,\n",
              "  2,\n",
              "  14,\n",
              "  38,\n",
              "  15,\n",
              "  38,\n",
              "  39,\n",
              "  38,\n",
              "  4,\n",
              "  1,\n",
              "  3,\n",
              "  1,\n",
              "  35,\n",
              "  17,\n",
              "  4,\n",
              "  17,\n",
              "  4,\n",
              "  2,\n",
              "  5,\n",
              "  29,\n",
              "  10,\n",
              "  28,\n",
              "  9,\n",
              "  28,\n",
              "  22,\n",
              "  42,\n",
              "  2,\n",
              "  12,\n",
              "  3,\n",
              "  23,\n",
              "  5,\n",
              "  13,\n",
              "  10,\n",
              "  3,\n",
              "  12,\n",
              "  4,\n",
              "  1,\n",
              "  5,\n",
              "  3,\n",
              "  9,\n",
              "  10,\n",
              "  4,\n",
              "  13,\n",
              "  29,\n",
              "  3,\n",
              "  4,\n",
              "  15,\n",
              "  15,\n",
              "  0,\n",
              "  33,\n",
              "  2,\n",
              "  39,\n",
              "  12,\n",
              "  38,\n",
              "  7,\n",
              "  10,\n",
              "  2,\n",
              "  10,\n",
              "  2,\n",
              "  38,\n",
              "  2,\n",
              "  5,\n",
              "  1,\n",
              "  3,\n",
              "  1,\n",
              "  42,\n",
              "  15,\n",
              "  15,\n",
              "  4,\n",
              "  15,\n",
              "  38,\n",
              "  25,\n",
              "  5,\n",
              "  5,\n",
              "  12,\n",
              "  2,\n",
              "  26,\n",
              "  0,\n",
              "  17,\n",
              "  0,\n",
              "  26,\n",
              "  31,\n",
              "  4,\n",
              "  13,\n",
              "  17,\n",
              "  1,\n",
              "  11,\n",
              "  8,\n",
              "  1,\n",
              "  2,\n",
              "  4,\n",
              "  14,\n",
              "  3,\n",
              "  4,\n",
              "  25,\n",
              "  4,\n",
              "  15,\n",
              "  2,\n",
              "  38,\n",
              "  11,\n",
              "  37,\n",
              "  7,\n",
              "  1,\n",
              "  18,\n",
              "  28,\n",
              "  11,\n",
              "  10,\n",
              "  9,\n",
              "  15,\n",
              "  11,\n",
              "  12,\n",
              "  10,\n",
              "  13,\n",
              "  13,\n",
              "  25,\n",
              "  4,\n",
              "  1,\n",
              "  38,\n",
              "  12,\n",
              "  23,\n",
              "  10,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  24,\n",
              "  10,\n",
              "  1,\n",
              "  28,\n",
              "  5,\n",
              "  11,\n",
              "  5,\n",
              "  6,\n",
              "  9,\n",
              "  2,\n",
              "  1,\n",
              "  33,\n",
              "  3,\n",
              "  9,\n",
              "  25,\n",
              "  16,\n",
              "  42,\n",
              "  35,\n",
              "  10,\n",
              "  28,\n",
              "  4,\n",
              "  1,\n",
              "  7,\n",
              "  5,\n",
              "  3,\n",
              "  23,\n",
              "  1,\n",
              "  1,\n",
              "  10,\n",
              "  23,\n",
              "  35,\n",
              "  24,\n",
              "  33,\n",
              "  1,\n",
              "  12,\n",
              "  2,\n",
              "  13,\n",
              "  13,\n",
              "  33,\n",
              "  17,\n",
              "  35,\n",
              "  5,\n",
              "  15,\n",
              "  31,\n",
              "  33,\n",
              "  42,\n",
              "  11,\n",
              "  24,\n",
              "  38,\n",
              "  4,\n",
              "  25,\n",
              "  7,\n",
              "  13,\n",
              "  21,\n",
              "  38,\n",
              "  38,\n",
              "  1,\n",
              "  13,\n",
              "  23,\n",
              "  13,\n",
              "  18,\n",
              "  13,\n",
              "  13,\n",
              "  38,\n",
              "  35,\n",
              "  5,\n",
              "  12,\n",
              "  25,\n",
              "  4,\n",
              "  1,\n",
              "  19,\n",
              "  3,\n",
              "  9,\n",
              "  2,\n",
              "  3,\n",
              "  17,\n",
              "  38,\n",
              "  5,\n",
              "  5,\n",
              "  38,\n",
              "  1,\n",
              "  11,\n",
              "  31,\n",
              "  2,\n",
              "  42,\n",
              "  12,\n",
              "  35,\n",
              "  29,\n",
              "  38,\n",
              "  0,\n",
              "  38,\n",
              "  10,\n",
              "  13,\n",
              "  1,\n",
              "  34,\n",
              "  22,\n",
              "  12,\n",
              "  31,\n",
              "  15,\n",
              "  13,\n",
              "  31,\n",
              "  1,\n",
              "  42,\n",
              "  36,\n",
              "  7,\n",
              "  20,\n",
              "  27,\n",
              "  15,\n",
              "  12,\n",
              "  14,\n",
              "  10,\n",
              "  5,\n",
              "  32,\n",
              "  3,\n",
              "  7,\n",
              "  13,\n",
              "  12,\n",
              "  7,\n",
              "  13,\n",
              "  4,\n",
              "  10,\n",
              "  8,\n",
              "  23,\n",
              "  10,\n",
              "  39,\n",
              "  2,\n",
              "  13,\n",
              "  7,\n",
              "  1,\n",
              "  5,\n",
              "  31,\n",
              "  10,\n",
              "  5,\n",
              "  31,\n",
              "  7,\n",
              "  39,\n",
              "  0,\n",
              "  23,\n",
              "  7,\n",
              "  38,\n",
              "  35,\n",
              "  38,\n",
              "  25,\n",
              "  38,\n",
              "  9,\n",
              "  16,\n",
              "  ...],\n",
              " [array([ 5.693913,  5.725306, 24.46571 , 24.511951], dtype=float32),\n",
              "  array([ 5.6984706,  5.730566 , 23.803932 , 23.884869 ], dtype=float32),\n",
              "  array([ 5.3989577,  5.4353228, 24.939854 , 25.003588 ], dtype=float32),\n",
              "  array([ 5.522105,  5.512214, 22.802689, 22.85009 ], dtype=float32),\n",
              "  array([ 6.9256363,  6.665922 , 23.014133 , 23.310986 ], dtype=float32),\n",
              "  array([ 5.442824,  5.480901, 23.993107, 24.040646], dtype=float32),\n",
              "  array([ 6.4328566,  6.24399  , 22.704178 , 22.99087  ], dtype=float32),\n",
              "  array([ 5.6265345,  5.605998 , 23.946497 , 23.990416 ], dtype=float32),\n",
              "  array([ 7.020373,  6.816496, 22.637661, 22.935463], dtype=float32),\n",
              "  array([ 6.0481014,  5.975634 , 22.094913 , 22.225729 ], dtype=float32),\n",
              "  array([ 5.5047565,  5.432125 , 24.31849  , 24.352024 ], dtype=float32),\n",
              "  array([ 5.3573055,  5.394038 , 23.885769 , 23.900723 ], dtype=float32),\n",
              "  array([ 5.53722  ,  5.3731117, 23.618301 , 23.782316 ], dtype=float32),\n",
              "  array([ 5.2724032,  5.271886 , 24.260891 , 24.277979 ], dtype=float32),\n",
              "  array([ 5.4192553,  5.4695387, 23.963442 , 24.00787  ], dtype=float32),\n",
              "  array([ 5.0115223,  5.0694914, 23.97592  , 23.98061  ], dtype=float32),\n",
              "  array([ 5.3729525,  5.244478 , 23.595627 , 23.694403 ], dtype=float32),\n",
              "  array([ 5.401683,  5.394857, 24.888123, 24.994879], dtype=float32),\n",
              "  array([ 5.5663943,  5.4193316, 24.463345 , 24.652634 ], dtype=float32),\n",
              "  array([ 5.248024 ,  5.3492546, 24.681181 , 24.737785 ], dtype=float32),\n",
              "  array([ 5.285821 ,  5.2452655, 24.663513 , 24.742252 ], dtype=float32),\n",
              "  array([ 5.670246 ,  5.6164455, 23.273643 , 23.336395 ], dtype=float32),\n",
              "  array([ 5.422079 ,  5.4700155, 23.91384  , 23.943703 ], dtype=float32),\n",
              "  array([ 5.425419 ,  5.3577065, 25.279358 , 25.32188  ], dtype=float32),\n",
              "  array([ 6.424297,  6.405594, 22.717812, 22.854881], dtype=float32),\n",
              "  array([ 5.5559373,  5.5145445, 23.841602 , 23.94017  ], dtype=float32),\n",
              "  array([ 5.8271976,  5.7377677, 23.06503  , 23.160717 ], dtype=float32),\n",
              "  array([ 5.101491,  5.109813, 24.960384, 24.953995], dtype=float32),\n",
              "  array([ 5.132649,  5.141796, 24.234612, 24.24205 ], dtype=float32),\n",
              "  array([ 5.4075193,  5.345781 , 24.53181  , 24.641832 ], dtype=float32),\n",
              "  array([ 5.3485646,  5.313955 , 23.996044 , 24.026375 ], dtype=float32),\n",
              "  array([ 5.1477313,  5.2237763, 23.799381 , 23.806955 ], dtype=float32),\n",
              "  array([ 5.4033203,  5.4128304, 24.099476 , 24.162418 ], dtype=float32),\n",
              "  array([ 5.445152,  5.2407  , 23.994678, 24.158014], dtype=float32),\n",
              "  array([ 5.5220523,  5.5193663, 24.138363 , 24.186775 ], dtype=float32),\n",
              "  array([ 5.111799 ,  5.2210274, 24.488844 , 24.474705 ], dtype=float32),\n",
              "  array([ 5.432006,  5.392811, 23.513247, 23.54742 ], dtype=float32),\n",
              "  array([ 7.379282,  7.200411, 20.83153 , 21.031788], dtype=float32),\n",
              "  array([ 5.179371 ,  5.2045536, 24.07374  , 24.102114 ], dtype=float32),\n",
              "  array([ 5.3492327,  5.3085904, 24.1613   , 24.253933 ], dtype=float32),\n",
              "  array([ 5.3553867,  5.3867354, 23.896336 , 23.910225 ], dtype=float32),\n",
              "  array([ 5.268912 ,  5.1729116, 24.146255 , 24.263874 ], dtype=float32),\n",
              "  array([ 6.6461577,  6.450658 , 22.789597 , 23.07645  ], dtype=float32),\n",
              "  array([ 5.380248,  5.346428, 24.75171 , 24.765392], dtype=float32),\n",
              "  array([ 5.8281546,  5.616895 , 23.113358 , 23.338581 ], dtype=float32),\n",
              "  array([ 5.489066,  5.422858, 22.730242, 22.848541], dtype=float32),\n",
              "  array([ 5.4838524,  5.437021 , 24.350178 , 24.389744 ], dtype=float32),\n",
              "  array([ 5.1401744,  5.1845307, 24.782558 , 24.780651 ], dtype=float32),\n",
              "  array([ 5.3987064,  5.295979 , 23.265842 , 23.397648 ], dtype=float32),\n",
              "  array([ 5.4748707,  5.4521284, 24.009718 , 24.093552 ], dtype=float32),\n",
              "  array([ 5.396626,  5.333925, 24.169909, 24.273958], dtype=float32),\n",
              "  array([ 6.624714,  6.469344, 22.445099, 22.640995], dtype=float32),\n",
              "  array([ 5.3463235,  5.3591537, 24.951942 , 24.96002  ], dtype=float32),\n",
              "  array([ 5.2606063,  5.2986007, 24.349884 , 24.373236 ], dtype=float32),\n",
              "  array([ 6.57718  ,  6.4242578, 22.608343 , 22.784039 ], dtype=float32),\n",
              "  array([ 5.8505425,  5.848452 , 23.083937 , 23.146517 ], dtype=float32),\n",
              "  array([ 5.271427 ,  5.2663736, 24.163364 , 24.164768 ], dtype=float32),\n",
              "  array([ 5.79649 ,  5.650302, 24.099522, 24.369633], dtype=float32),\n",
              "  array([ 5.0614653,  5.1193876, 23.700863 , 23.707188 ], dtype=float32),\n",
              "  array([ 5.097584 ,  5.1415644, 24.438824 , 24.424873 ], dtype=float32),\n",
              "  array([ 6.2179294,  6.1575804, 23.74339  , 23.863842 ], dtype=float32),\n",
              "  array([ 5.107419 ,  5.1793885, 24.836414 , 24.8088   ], dtype=float32),\n",
              "  array([ 5.5078053,  5.474026 , 23.899025 , 23.976557 ], dtype=float32),\n",
              "  array([ 5.0721993,  5.1089826, 25.640614 , 25.663715 ], dtype=float32),\n",
              "  array([ 5.429747 ,  5.4511347, 24.443918 , 24.462341 ], dtype=float32),\n",
              "  array([ 5.5617604,  5.613901 , 24.691212 , 24.720509 ], dtype=float32),\n",
              "  array([ 5.567758 ,  5.4490557, 23.542553 , 23.703213 ], dtype=float32),\n",
              "  array([ 5.442323 ,  5.4051223, 24.682089 , 24.729366 ], dtype=float32),\n",
              "  array([ 5.2595253,  5.2370906, 24.57124  , 24.576916 ], dtype=float32),\n",
              "  array([ 5.8978443,  5.73889  , 23.52211  , 23.705894 ], dtype=float32),\n",
              "  array([ 6.7384195,  6.512224 , 22.282024 , 22.573292 ], dtype=float32),\n",
              "  array([ 7.1353025,  6.9269385, 22.681108 , 22.995766 ], dtype=float32),\n",
              "  array([ 5.399399,  5.257827, 24.308907, 24.46098 ], dtype=float32),\n",
              "  array([ 5.1748667,  5.179681 , 23.553661 , 23.593987 ], dtype=float32),\n",
              "  array([ 5.4420314,  5.4195714, 23.978361 , 24.008507 ], dtype=float32),\n",
              "  array([ 6.3097744,  6.199568 , 23.348328 , 23.455132 ], dtype=float32),\n",
              "  array([ 5.3355246,  5.3742924, 23.993534 , 24.024555 ], dtype=float32),\n",
              "  array([ 5.1770787,  5.1910315, 24.757303 , 24.756838 ], dtype=float32),\n",
              "  array([ 5.515835 ,  5.4204884, 22.913242 , 23.026539 ], dtype=float32),\n",
              "  array([ 5.4784336,  5.343564 , 23.973951 , 24.110256 ], dtype=float32),\n",
              "  array([ 5.48386 ,  5.290659, 24.572603, 24.696035], dtype=float32),\n",
              "  array([ 5.632925 ,  5.6061797, 23.755182 , 23.819496 ], dtype=float32),\n",
              "  array([ 5.774336 ,  5.6638174, 24.486858 , 24.670498 ], dtype=float32),\n",
              "  array([ 5.240563 ,  5.2577176, 23.955212 , 23.958694 ], dtype=float32),\n",
              "  array([ 5.442507 ,  5.4847364, 24.760265 , 24.765339 ], dtype=float32),\n",
              "  array([ 5.640824,  5.554701, 23.364365, 23.480854], dtype=float32),\n",
              "  array([ 6.2076616,  6.1100664, 22.517878 , 22.633987 ], dtype=float32),\n",
              "  array([ 5.3214455,  5.3283772, 23.315403 , 23.361794 ], dtype=float32),\n",
              "  array([ 5.743767 ,  5.5955615, 23.248524 , 23.456966 ], dtype=float32),\n",
              "  array([ 5.5380445,  5.4795737, 24.859535 , 24.917889 ], dtype=float32),\n",
              "  array([ 5.3313932,  5.274917 , 24.491596 , 24.524544 ], dtype=float32),\n",
              "  array([ 5.486746,  5.517036, 24.893456, 24.94228 ], dtype=float32),\n",
              "  array([ 5.5676746,  5.5308695, 24.28599  , 24.346256 ], dtype=float32),\n",
              "  array([ 6.9602494,  6.8564353, 22.38559  , 22.543545 ], dtype=float32),\n",
              "  array([ 6.0873322,  6.0289445, 23.74979  , 23.8051   ], dtype=float32),\n",
              "  array([ 5.4103127,  5.4325495, 24.059917 , 24.07405  ], dtype=float32),\n",
              "  array([ 5.394734,  5.378147, 24.977568, 24.995644], dtype=float32),\n",
              "  array([ 5.310491,  5.401119, 24.819614, 24.847443], dtype=float32),\n",
              "  array([ 5.2379446,  5.271242 , 24.041065 , 24.054783 ], dtype=float32),\n",
              "  array([ 5.6116734,  5.5749216, 24.429993 , 24.493427 ], dtype=float32),\n",
              "  array([ 5.3895693,  5.4230337, 24.623474 , 24.65107  ], dtype=float32),\n",
              "  array([ 5.204343 ,  5.1973906, 24.387104 , 24.40703  ], dtype=float32),\n",
              "  array([ 5.20898  ,  5.1620903, 24.844692 , 24.859482 ], dtype=float32),\n",
              "  array([ 5.4290123,  5.3504677, 24.728975 , 24.83599  ], dtype=float32),\n",
              "  array([ 5.544192 ,  5.5359893, 23.681705 , 23.718681 ], dtype=float32),\n",
              "  array([ 5.41264 ,  5.411878, 24.889515, 24.9584  ], dtype=float32),\n",
              "  array([ 5.3283033,  5.3213105, 23.986704 , 24.05141  ], dtype=float32),\n",
              "  array([ 7.861416,  7.579877, 21.336348, 21.709915], dtype=float32),\n",
              "  array([ 5.881758,  5.812902, 23.337078, 23.411114], dtype=float32),\n",
              "  array([ 5.240337,  5.227848, 25.133171, 25.186174], dtype=float32),\n",
              "  array([ 5.3307543,  5.3687577, 23.954834 , 23.972748 ], dtype=float32),\n",
              "  array([ 6.506843,  6.45494 , 22.20594 , 22.330402], dtype=float32),\n",
              "  array([ 5.243627,  5.274442, 23.550827, 23.58031 ], dtype=float32),\n",
              "  array([ 5.3114753,  5.340486 , 24.631058 , 24.633858 ], dtype=float32),\n",
              "  array([ 5.2120175,  5.1450915, 24.328382 , 24.424927 ], dtype=float32),\n",
              "  array([ 6.261217 ,  6.1692333, 22.917591 , 23.020714 ], dtype=float32),\n",
              "  array([ 5.494723 ,  5.3630466, 24.461155 , 24.600231 ], dtype=float32),\n",
              "  array([ 5.1534686,  5.0028853, 23.744946 , 23.847923 ], dtype=float32),\n",
              "  array([ 5.348352 ,  5.3965273, 24.583435 , 24.591923 ], dtype=float32),\n",
              "  array([ 5.288765 ,  5.3547015, 24.15194  , 24.20166  ], dtype=float32),\n",
              "  array([ 5.62228 ,  5.523499, 24.28424 , 24.374966], dtype=float32),\n",
              "  array([ 6.118251,  6.10842 , 22.954014, 23.029064], dtype=float32),\n",
              "  array([ 5.3925376,  5.418244 , 24.252373 , 24.29486  ], dtype=float32),\n",
              "  array([ 5.4451337,  5.4572983, 23.657536 , 23.729694 ], dtype=float32),\n",
              "  array([ 7.0078163,  6.875715 , 21.847357 , 22.031776 ], dtype=float32),\n",
              "  array([ 5.3254943,  5.3482842, 23.837822 , 23.844744 ], dtype=float32),\n",
              "  array([ 5.183723,  5.189708, 24.80651 , 24.811836], dtype=float32),\n",
              "  array([ 5.3555636,  5.2519026, 24.513054 , 24.644754 ], dtype=float32),\n",
              "  array([ 5.5037146,  5.549826 , 23.081833 , 23.14475  ], dtype=float32),\n",
              "  array([ 5.2635965,  5.3027043, 24.955957 , 24.96759  ], dtype=float32),\n",
              "  array([ 5.501704 ,  5.5547986, 23.820858 , 23.89513  ], dtype=float32),\n",
              "  array([ 5.1717896,  5.162284 , 23.9716   , 23.978321 ], dtype=float32),\n",
              "  array([ 5.2439013,  5.275073 , 23.674921 , 23.687786 ], dtype=float32),\n",
              "  array([ 5.750602,  5.674103, 24.470383, 24.570217], dtype=float32),\n",
              "  array([ 5.4825788,  5.3677073, 24.878407 , 25.025888 ], dtype=float32),\n",
              "  array([ 5.0719237,  5.117698 , 24.156643 , 24.147194 ], dtype=float32),\n",
              "  array([ 5.906251 ,  5.8082347, 23.400846 , 23.601439 ], dtype=float32),\n",
              "  array([ 5.2807245,  5.3573146, 23.763008 , 23.736317 ], dtype=float32),\n",
              "  array([ 5.5073624,  5.4637794, 23.697197 , 23.749422 ], dtype=float32),\n",
              "  array([ 5.2406583,  5.283154 , 24.952988 , 24.995594 ], dtype=float32),\n",
              "  array([ 5.5976114,  5.66556  , 24.515062 , 24.530025 ], dtype=float32),\n",
              "  array([ 5.2402086,  5.2385964, 24.196335 , 24.243624 ], dtype=float32),\n",
              "  array([ 5.301376 ,  5.3262644, 24.539507 , 24.569115 ], dtype=float32),\n",
              "  array([ 5.5707555,  5.477849 , 23.607693 , 23.782166 ], dtype=float32),\n",
              "  array([ 5.22836 ,  5.292425, 24.280132, 24.284199], dtype=float32),\n",
              "  array([ 5.4278164,  5.3331223, 24.229618 , 24.368774 ], dtype=float32),\n",
              "  array([ 5.5047364,  5.50304  , 24.276583 , 24.301945 ], dtype=float32),\n",
              "  array([ 5.1119666,  5.172159 , 24.969795 , 24.966784 ], dtype=float32),\n",
              "  array([ 6.837809 ,  6.6219506, 22.638653 , 22.926802 ], dtype=float32),\n",
              "  array([ 5.530673 ,  5.3148003, 24.913065 , 25.04181  ], dtype=float32),\n",
              "  array([ 5.3798623,  5.405661 , 24.509453 , 24.51774  ], dtype=float32),\n",
              "  array([ 6.611599 ,  6.3858867, 22.740814 , 22.9691   ], dtype=float32),\n",
              "  array([ 5.3410788,  5.288556 , 25.015497 , 25.084858 ], dtype=float32),\n",
              "  array([ 7.46941  ,  7.2715015, 21.533894 , 21.860611 ], dtype=float32),\n",
              "  array([ 5.191551,  5.279602, 24.530884, 24.520195], dtype=float32),\n",
              "  array([ 5.3950295,  5.356539 , 24.466797 , 24.503468 ], dtype=float32),\n",
              "  array([ 5.2690034,  5.2973285, 24.767094 , 24.778072 ], dtype=float32),\n",
              "  array([ 5.2518716,  5.2730827, 23.744602 , 23.767899 ], dtype=float32),\n",
              "  array([ 5.2839622,  5.310929 , 23.862093 , 23.870892 ], dtype=float32),\n",
              "  array([ 5.343252,  5.322023, 25.051567, 25.112167], dtype=float32),\n",
              "  array([ 5.8226633,  5.7239146, 24.80288  , 24.906303 ], dtype=float32),\n",
              "  array([ 5.0570154,  5.0769253, 24.95418  , 24.958202 ], dtype=float32),\n",
              "  array([ 5.501873,  5.478346, 23.772675, 23.866802], dtype=float32),\n",
              "  array([ 5.476243 ,  5.4183087, 23.764393 , 23.87067  ], dtype=float32),\n",
              "  array([ 5.6020246,  5.458295 , 24.19505  , 24.382967 ], dtype=float32),\n",
              "  array([ 6.0905485,  6.0706716, 22.366207 , 22.466068 ], dtype=float32),\n",
              "  array([ 6.6180034,  6.4386754, 22.804455 , 23.00476  ], dtype=float32),\n",
              "  array([ 5.5447226,  5.5909944, 23.217136 , 23.250568 ], dtype=float32),\n",
              "  array([ 5.8485885,  5.6148596, 23.510983 , 23.74882  ], dtype=float32),\n",
              "  array([ 5.186907,  5.280491, 23.787128, 23.80099 ], dtype=float32),\n",
              "  array([ 6.503044,  6.351909, 23.224247, 23.417175], dtype=float32),\n",
              "  array([ 5.5308237,  5.5021896, 23.59172  , 23.636147 ], dtype=float32),\n",
              "  array([ 5.703558 ,  5.5790634, 23.887348 , 24.142471 ], dtype=float32),\n",
              "  array([ 5.3397126,  5.231993 , 24.02726  , 24.149055 ], dtype=float32),\n",
              "  array([ 6.1488414,  6.077704 , 23.286282 , 23.38587  ], dtype=float32),\n",
              "  array([ 5.384696,  5.409299, 23.806408, 23.85543 ], dtype=float32),\n",
              "  array([ 5.2511883,  5.228839 , 23.808167 , 23.816504 ], dtype=float32),\n",
              "  array([ 6.0726504,  6.084343 , 23.333893 , 23.375607 ], dtype=float32),\n",
              "  array([ 5.875211,  5.798786, 24.121655, 24.213821], dtype=float32),\n",
              "  array([ 5.462281 ,  5.4353447, 24.859045 , 24.915424 ], dtype=float32),\n",
              "  array([ 5.1367955,  5.186488 , 24.20063  , 24.23079  ], dtype=float32),\n",
              "  array([ 5.212919,  5.251761, 23.878082, 23.922619], dtype=float32),\n",
              "  array([ 5.2615304,  5.326807 , 24.306713 , 24.3676   ], dtype=float32),\n",
              "  array([ 5.374743,  5.257423, 25.047173, 25.170492], dtype=float32),\n",
              "  array([ 5.433495,  5.383489, 24.58022 , 24.69478 ], dtype=float32),\n",
              "  array([ 5.434999 ,  5.3413863, 24.584568 , 24.728271 ], dtype=float32),\n",
              "  array([ 5.3526645,  5.2426624, 23.928051 , 24.061028 ], dtype=float32),\n",
              "  array([ 5.373273 ,  5.3805285, 24.108614 , 24.145845 ], dtype=float32),\n",
              "  array([ 5.150791,  5.20235 , 24.541107, 24.546467], dtype=float32),\n",
              "  array([ 5.1394444,  5.181966 , 24.718536 , 24.757275 ], dtype=float32),\n",
              "  array([ 5.064208 ,  5.0151386, 25.037682 , 25.076939 ], dtype=float32),\n",
              "  array([ 6.487355 ,  6.2539744, 22.905327 , 23.160503 ], dtype=float32),\n",
              "  array([ 6.829195,  6.726783, 23.241724, 23.340614], dtype=float32),\n",
              "  array([ 5.4687505,  5.484975 , 23.532448 , 23.579472 ], dtype=float32),\n",
              "  array([ 5.533898 ,  5.3598433, 24.37365  , 24.51609  ], dtype=float32),\n",
              "  array([ 5.6710563,  5.644935 , 24.016394 , 24.076235 ], dtype=float32),\n",
              "  array([ 5.201063,  5.186071, 24.692154, 24.727482], dtype=float32),\n",
              "  array([ 5.267363 ,  5.2713337, 23.96006  , 24.005634 ], dtype=float32),\n",
              "  array([ 5.594219,  5.466738, 23.445305, 23.562252], dtype=float32),\n",
              "  array([ 5.474303 ,  5.4203553, 24.182228 , 24.275936 ], dtype=float32),\n",
              "  array([ 5.132007,  5.252837, 24.439955, 24.42091 ], dtype=float32),\n",
              "  array([ 5.0400314,  5.075883 , 23.990013 , 23.994799 ], dtype=float32),\n",
              "  array([ 5.2058554,  5.215044 , 24.361423 , 24.421713 ], dtype=float32),\n",
              "  array([ 5.359857 ,  5.3731217, 24.050123 , 24.084095 ], dtype=float32),\n",
              "  array([ 5.258094,  5.318064, 23.865551, 23.886795], dtype=float32),\n",
              "  array([ 5.174055,  5.180668, 24.408699, 24.432995], dtype=float32),\n",
              "  array([ 5.297777 ,  5.2577877, 24.18425  , 24.204487 ], dtype=float32),\n",
              "  array([ 5.275188,  5.104022, 25.358871, 25.466341], dtype=float32),\n",
              "  array([ 5.645255 ,  5.5480976, 24.929108 , 25.023596 ], dtype=float32),\n",
              "  array([ 6.4510407,  6.386755 , 22.249992 , 22.36092  ], dtype=float32),\n",
              "  array([ 6.6296473,  6.5615225, 22.872684 , 22.989176 ], dtype=float32),\n",
              "  array([ 5.5553417,  5.5690055, 24.301647 , 24.36514  ], dtype=float32),\n",
              "  array([ 6.641472 ,  6.4497247, 22.518902 , 22.803402 ], dtype=float32),\n",
              "  array([ 5.341397,  5.316662, 24.13139 , 24.148102], dtype=float32),\n",
              "  array([ 5.834697,  5.705569, 24.30291 , 24.505013], dtype=float32),\n",
              "  array([ 5.9214535,  5.856428 , 24.22681  , 24.325325 ], dtype=float32),\n",
              "  array([ 5.2846255,  5.2739053, 24.171146 , 24.204308 ], dtype=float32),\n",
              "  array([ 5.3973026,  5.411209 , 23.70124  , 23.71896  ], dtype=float32),\n",
              "  array([ 5.668095,  5.589196, 24.048832, 24.1636  ], dtype=float32),\n",
              "  array([ 6.1121764,  6.105325 , 23.567513 , 23.6428   ], dtype=float32),\n",
              "  array([ 5.82302  ,  5.8140893, 23.92235  , 23.992332 ], dtype=float32),\n",
              "  array([ 5.3655314,  5.386201 , 24.491583 , 24.55267  ], dtype=float32),\n",
              "  array([ 5.3739777,  5.3614354, 24.044445 , 24.07161  ], dtype=float32),\n",
              "  array([ 5.3579707,  5.4256253, 24.457447 , 24.478107 ], dtype=float32),\n",
              "  array([ 7.083789 ,  6.9791827, 21.855196 , 22.03675  ], dtype=float32),\n",
              "  array([ 5.541875,  5.513805, 24.072712, 24.100124], dtype=float32),\n",
              "  array([ 5.4006333,  5.3994913, 24.713165 , 24.694616 ], dtype=float32),\n",
              "  array([ 5.4529114,  5.4165382, 23.582912 , 23.628006 ], dtype=float32),\n",
              "  array([ 5.2028465,  5.2366457, 23.59889  , 23.63838  ], dtype=float32),\n",
              "  array([ 5.164844,  5.257412, 23.623478, 23.686712], dtype=float32),\n",
              "  array([ 8.246892 ,  7.9760675, 21.158548 , 21.580238 ], dtype=float32),\n",
              "  array([ 5.693883 ,  5.6307826, 24.230534 , 24.336533 ], dtype=float32),\n",
              "  array([ 5.45528  ,  5.4506583, 23.434166 , 23.487938 ], dtype=float32),\n",
              "  array([ 5.3863883,  5.2891493, 23.81688  , 23.98919  ], dtype=float32),\n",
              "  array([ 6.0129056,  5.944228 , 23.352879 , 23.444878 ], dtype=float32),\n",
              "  array([ 5.3981524,  5.1648717, 23.985886 , 24.17355  ], dtype=float32),\n",
              "  array([ 6.3885427,  6.295251 , 21.419277 , 21.523193 ], dtype=float32),\n",
              "  array([ 5.2312374,  5.1088543, 24.710144 , 24.824524 ], dtype=float32),\n",
              "  array([ 6.7002034,  6.607269 , 23.279251 , 23.444103 ], dtype=float32),\n",
              "  array([ 5.4648547,  5.368309 , 24.90575  , 25.066837 ], dtype=float32),\n",
              "  array([ 5.630853,  5.571102, 24.669308, 24.69926 ], dtype=float32),\n",
              "  array([ 7.400789 ,  7.1981487, 22.20514  , 22.447296 ], dtype=float32),\n",
              "  array([ 5.3697276,  5.366535 , 24.8625   , 24.945873 ], dtype=float32),\n",
              "  array([ 5.563983 ,  5.5447464, 23.945993 , 24.059998 ], dtype=float32),\n",
              "  array([ 5.11232  ,  5.0386534, 24.698093 , 24.75114  ], dtype=float32),\n",
              "  array([ 5.958515,  5.899452, 22.717634, 22.808815], dtype=float32),\n",
              "  array([ 5.2462173,  5.211211 , 23.908257 , 23.936975 ], dtype=float32),\n",
              "  array([ 5.1569204,  5.2146072, 24.439304 , 24.42519  ], dtype=float32),\n",
              "  array([ 5.346891 ,  5.3064003, 24.31479  , 24.35672  ], dtype=float32),\n",
              "  array([ 5.3113284,  5.3976097, 23.994356 , 24.015965 ], dtype=float32),\n",
              "  array([ 5.6991844,  5.6125474, 23.828213 , 23.990307 ], dtype=float32),\n",
              "  array([ 7.500993 ,  7.3541985, 21.349495 , 21.575562 ], dtype=float32),\n",
              "  array([ 5.4591193,  5.475639 , 23.788631 , 23.880291 ], dtype=float32),\n",
              "  array([ 5.3332086,  5.386859 , 24.541407 , 24.59924  ], dtype=float32),\n",
              "  array([ 5.357834,  5.362308, 23.689785, 23.775223], dtype=float32),\n",
              "  array([ 7.304635,  7.09486 , 22.020142, 22.359333], dtype=float32),\n",
              "  array([ 5.719863 ,  5.7457066, 23.422916 , 23.476957 ], dtype=float32),\n",
              "  array([ 5.840557 ,  5.7384467, 23.186848 , 23.298122 ], dtype=float32),\n",
              "  array([ 5.5497694,  5.484983 , 25.757233 , 25.88028  ], dtype=float32),\n",
              "  array([ 5.3323417,  5.3341217, 24.170113 , 24.192175 ], dtype=float32),\n",
              "  array([ 5.334067 ,  5.3355055, 24.044472 , 24.105064 ], dtype=float32),\n",
              "  array([ 7.0784807,  6.9817915, 21.918133 , 22.087017 ], dtype=float32),\n",
              "  array([ 5.4169292,  5.3358135, 24.558517 , 24.70642  ], dtype=float32),\n",
              "  array([ 5.946348,  5.762515, 23.071957, 23.278278], dtype=float32),\n",
              "  array([ 5.4223576,  5.4334607, 24.625698 , 24.655846 ], dtype=float32),\n",
              "  array([ 5.3429937,  5.296789 , 23.690762 , 23.75102  ], dtype=float32),\n",
              "  array([ 5.227569 ,  5.1873403, 24.39031  , 24.426739 ], dtype=float32),\n",
              "  array([ 7.879693,  7.620678, 20.77062 , 21.16586 ], dtype=float32),\n",
              "  array([ 5.4861093,  5.471142 , 24.717785 , 24.777168 ], dtype=float32),\n",
              "  array([ 5.5979643,  5.4822097, 25.016819 , 25.193079 ], dtype=float32),\n",
              "  array([ 5.9736266,  5.8229747, 22.89149  , 23.113115 ], dtype=float32),\n",
              "  array([ 5.385007,  5.311889, 23.924932, 24.062191], dtype=float32),\n",
              "  array([ 5.2357655,  5.250963 , 24.281551 , 24.344582 ], dtype=float32),\n",
              "  array([ 5.108422,  5.175213, 25.605995, 25.607534], dtype=float32),\n",
              "  array([ 5.5131884,  5.466863 , 24.567331 , 24.69117  ], dtype=float32),\n",
              "  array([ 5.36644  ,  5.3148603, 24.097355 , 24.210762 ], dtype=float32),\n",
              "  array([ 5.3186207,  5.357276 , 24.041002 , 24.090717 ], dtype=float32),\n",
              "  array([ 6.462036 ,  6.3347416, 22.77985  , 22.918934 ], dtype=float32),\n",
              "  array([ 5.533451,  5.389228, 23.760502, 23.897644], dtype=float32),\n",
              "  array([ 5.385951,  5.458912, 23.43689 , 23.471714], dtype=float32),\n",
              "  array([ 5.328661,  5.314787, 24.658472, 24.681318], dtype=float32),\n",
              "  array([ 5.3594575,  5.3004084, 23.921192 , 23.985123 ], dtype=float32),\n",
              "  array([ 5.2117596,  5.062756 , 25.354565 , 25.454674 ], dtype=float32),\n",
              "  array([ 5.5918264,  5.4594545, 24.231697 , 24.39309  ], dtype=float32),\n",
              "  array([ 6.4365487,  6.4176455, 22.845509 , 22.993607 ], dtype=float32),\n",
              "  array([ 5.3481984,  5.339725 , 24.057209 , 24.08807  ], dtype=float32),\n",
              "  array([ 5.556954 ,  5.5241427, 23.97604  , 24.028364 ], dtype=float32),\n",
              "  array([ 5.397292,  5.238075, 23.758266, 23.887218], dtype=float32),\n",
              "  array([ 5.2279763,  5.303016 , 24.222195 , 24.238682 ], dtype=float32),\n",
              "  array([ 5.4220023,  5.3615637, 24.336918 , 24.388214 ], dtype=float32),\n",
              "  array([ 6.9305773,  6.855993 , 22.687    , 22.87603  ], dtype=float32),\n",
              "  array([ 5.443783 ,  5.2775326, 25.212399 , 25.340641 ], dtype=float32),\n",
              "  array([ 6.370747 ,  6.2175846, 22.69522  , 22.861137 ], dtype=float32),\n",
              "  array([ 5.911703 ,  5.8610644, 23.585815 , 23.712948 ], dtype=float32),\n",
              "  array([ 5.1404796,  5.1011543, 25.08796  , 25.088495 ], dtype=float32),\n",
              "  array([ 6.4008164,  6.368798 , 23.222523 , 23.371357 ], dtype=float32),\n",
              "  array([ 5.624773,  5.587961, 24.066814, 24.117146], dtype=float32),\n",
              "  array([ 6.1152515,  5.949915 , 23.766918 , 23.972153 ], dtype=float32),\n",
              "  array([ 5.3554325,  5.3503036, 24.466747 , 24.541365 ], dtype=float32),\n",
              "  array([ 5.569738 ,  5.4569397, 24.31701  , 24.521595 ], dtype=float32),\n",
              "  array([ 6.6243706,  6.495672 , 22.141373 , 22.283894 ], dtype=float32),\n",
              "  array([ 5.392008,  5.356988, 23.86354 , 23.902649], dtype=float32),\n",
              "  array([ 5.4574885,  5.4235997, 24.683956 , 24.727158 ], dtype=float32),\n",
              "  array([ 7.4040875,  7.281994 , 21.30394  , 21.512886 ], dtype=float32),\n",
              "  array([ 5.22597 ,  5.261633, 24.02976 , 24.050358], dtype=float32),\n",
              "  array([ 5.1555705,  5.1307383, 23.756771 , 23.769615 ], dtype=float32),\n",
              "  array([ 5.493516,  5.494993, 23.541157, 23.589241], dtype=float32),\n",
              "  array([ 5.4117284,  5.433068 , 24.043339 , 24.085255 ], dtype=float32),\n",
              "  array([ 5.3415766,  5.36454  , 24.315308 , 24.334665 ], dtype=float32),\n",
              "  array([ 5.460887 ,  5.4400845, 23.772062 , 23.877821 ], dtype=float32),\n",
              "  array([ 6.094694,  5.823566, 23.576147, 23.831902], dtype=float32),\n",
              "  array([ 5.485797,  5.333931, 23.823807, 23.953054], dtype=float32),\n",
              "  array([ 5.2922726,  5.3520136, 24.502285 , 24.507343 ], dtype=float32),\n",
              "  array([ 5.4479527,  5.4722943, 23.647036 , 23.713665 ], dtype=float32),\n",
              "  array([ 5.3296247,  5.3606915, 23.659018 , 23.650518 ], dtype=float32),\n",
              "  array([ 5.148423,  5.216805, 24.509354, 24.491726], dtype=float32),\n",
              "  array([ 6.6497483,  6.5716124, 22.436901 , 22.588875 ], dtype=float32),\n",
              "  array([ 5.3700895,  5.4347324, 24.969181 , 24.99078  ], dtype=float32),\n",
              "  array([ 5.172496 ,  5.2832537, 24.603588 , 24.61657  ], dtype=float32),\n",
              "  array([ 5.5949864,  5.575618 , 23.735657 , 23.804081 ], dtype=float32),\n",
              "  array([ 5.1870623,  5.2128196, 23.771503 , 23.815285 ], dtype=float32),\n",
              "  array([ 5.33264  ,  5.3456497, 24.967373 , 25.024117 ], dtype=float32),\n",
              "  array([ 5.269399,  5.227091, 24.814632, 24.826138], dtype=float32),\n",
              "  array([ 5.2445817,  5.2820845, 25.008188 , 25.019363 ], dtype=float32),\n",
              "  array([ 5.5471997,  5.409461 , 24.190405 , 24.325808 ], dtype=float32),\n",
              "  array([ 6.056666 ,  5.9626927, 22.604904 , 22.75746  ], dtype=float32),\n",
              "  array([ 5.1515446,  5.1739764, 24.77484  , 24.803604 ], dtype=float32),\n",
              "  array([ 5.3986864,  5.4340887, 25.075659 , 25.137772 ], dtype=float32),\n",
              "  array([ 5.4948826,  5.548356 , 23.556534 , 23.62154  ], dtype=float32),\n",
              "  array([ 5.4486074,  5.4181433, 24.147942 , 24.18892  ], dtype=float32),\n",
              "  array([ 5.287878,  5.26871 , 24.741123, 24.798359], dtype=float32),\n",
              "  array([ 5.6237097,  5.506164 , 23.539536 , 23.733963 ], dtype=float32),\n",
              "  array([ 5.2489476,  5.232865 , 24.022942 , 24.021402 ], dtype=float32),\n",
              "  array([ 5.6838517,  5.5995975, 23.931341 , 24.080347 ], dtype=float32),\n",
              "  array([ 5.105363 ,  5.1341205, 24.003616 , 24.013493 ], dtype=float32),\n",
              "  array([ 5.2399344,  5.216404 , 25.26556  , 25.293694 ], dtype=float32),\n",
              "  array([ 5.237919 ,  5.2258945, 24.23441  , 24.254505 ], dtype=float32),\n",
              "  array([ 5.3472743,  5.3627076, 23.937561 , 23.99255  ], dtype=float32),\n",
              "  array([ 5.3123345,  5.293639 , 24.013329 , 24.054743 ], dtype=float32),\n",
              "  array([ 5.5511637,  5.4716854, 24.285913 , 24.44711  ], dtype=float32),\n",
              "  array([ 5.0870037,  5.1301923, 24.601814 , 24.595896 ], dtype=float32),\n",
              "  array([ 5.7698274,  5.580584 , 23.299496 , 23.5003   ], dtype=float32),\n",
              "  array([ 5.166772,  5.224309, 24.306196, 24.301495], dtype=float32),\n",
              "  array([ 5.4971676,  5.4748526, 24.183258 , 24.23217  ], dtype=float32),\n",
              "  array([ 5.4235826,  5.477946 , 24.309555 , 24.353645 ], dtype=float32),\n",
              "  array([ 5.293918,  5.319076, 24.543999, 24.6056  ], dtype=float32),\n",
              "  array([ 7.192361,  6.949299, 21.960869, 22.311016], dtype=float32),\n",
              "  array([ 5.271148,  5.290706, 23.513357, 23.540989], dtype=float32),\n",
              "  array([ 5.6995587,  5.60821  , 23.678186 , 23.78021  ], dtype=float32),\n",
              "  array([ 5.6089964,  5.506729 , 24.128891 , 24.270588 ], dtype=float32),\n",
              "  array([ 5.254454 ,  5.3029504, 23.896696 , 23.908615 ], dtype=float32),\n",
              "  array([ 6.1224623,  6.080554 , 23.2518   , 23.354626 ], dtype=float32),\n",
              "  array([ 6.4059544,  6.3974357, 23.235088 , 23.338024 ], dtype=float32),\n",
              "  array([ 5.7552776,  5.760946 , 23.57776  , 23.616276 ], dtype=float32),\n",
              "  array([ 5.341122,  5.324244, 24.967442, 24.966042], dtype=float32),\n",
              "  array([ 5.214546 ,  5.2612615, 23.73315  , 23.719608 ], dtype=float32),\n",
              "  array([ 5.5500083,  5.4739165, 23.461315 , 23.556704 ], dtype=float32),\n",
              "  array([ 5.4585576,  5.403704 , 24.209545 , 24.263748 ], dtype=float32),\n",
              "  array([ 5.8042684,  5.8545427, 21.957617 , 22.057901 ], dtype=float32),\n",
              "  array([ 5.227767,  5.267915, 24.729248, 24.701736], dtype=float32),\n",
              "  array([ 5.243065 ,  5.2988415, 24.518135 , 24.5481   ], dtype=float32),\n",
              "  array([ 5.4418755,  5.444641 , 23.763111 , 23.820156 ], dtype=float32),\n",
              "  array([ 5.742432 ,  5.6825185, 23.641935 , 23.720272 ], dtype=float32),\n",
              "  array([ 5.412339,  5.365427, 23.886837, 23.913967], dtype=float32),\n",
              "  array([ 5.365107,  5.338196, 23.965216, 23.985134], dtype=float32),\n",
              "  array([ 7.2023153,  6.9510202, 21.75409  , 22.07609  ], dtype=float32),\n",
              "  array([ 5.480456,  5.52009 , 23.42913 , 23.446407], dtype=float32),\n",
              "  array([ 5.367799 ,  5.3855305, 24.489014 , 24.53284  ], dtype=float32),\n",
              "  array([ 5.323775,  5.106667, 24.32108 , 24.482718], dtype=float32),\n",
              "  array([ 6.583228 ,  6.4496956, 23.062866 , 23.228012 ], dtype=float32),\n",
              "  array([ 5.004461,  5.012848, 24.932629, 24.93953 ], dtype=float32),\n",
              "  array([ 5.6209655,  5.546228 , 23.906384 , 24.057728 ], dtype=float32),\n",
              "  array([ 5.422949 ,  5.3457994, 24.909657 , 24.977459 ], dtype=float32),\n",
              "  array([ 5.3929367,  5.3934755, 23.175701 , 23.207752 ], dtype=float32),\n",
              "  array([ 6.460129 ,  6.3061395, 22.44915  , 22.68592  ], dtype=float32),\n",
              "  array([ 5.3550115,  5.3685718, 24.366386 , 24.41603  ], dtype=float32),\n",
              "  array([ 5.3334413,  5.419529 , 24.204063 , 24.201317 ], dtype=float32),\n",
              "  array([ 8.002251 ,  7.7514105, 21.3937   , 21.726181 ], dtype=float32),\n",
              "  array([ 5.401084,  5.452133, 24.433182, 24.467464], dtype=float32),\n",
              "  array([ 5.650919 ,  5.5461864, 23.928226 , 24.117752 ], dtype=float32),\n",
              "  array([ 5.637876 ,  5.3841815, 24.164192 , 24.374527 ], dtype=float32),\n",
              "  array([ 6.2433167,  6.126013 , 23.031162 , 23.18589  ], dtype=float32),\n",
              "  array([ 5.4321084,  5.464681 , 24.761112 , 24.82061  ], dtype=float32),\n",
              "  array([ 5.447488,  5.431032, 24.417053, 24.48404 ], dtype=float32),\n",
              "  array([ 5.606803 ,  5.5380197, 23.828056 , 23.929487 ], dtype=float32),\n",
              "  array([ 6.175291 ,  6.0555587, 23.674583 , 23.881977 ], dtype=float32),\n",
              "  array([ 5.359108,  5.371409, 24.290743, 24.339008], dtype=float32),\n",
              "  array([ 5.318281,  5.284516, 24.370872, 24.392532], dtype=float32),\n",
              "  array([ 5.217763,  5.285174, 24.531513, 24.539177], dtype=float32),\n",
              "  array([ 5.1318536,  5.1773767, 24.47697  , 24.47482  ], dtype=float32),\n",
              "  array([ 5.608025 ,  5.5836926, 23.498108 , 23.580456 ], dtype=float32),\n",
              "  array([ 5.800914,  5.717391, 24.121346, 24.187656], dtype=float32),\n",
              "  array([ 5.497572,  5.412839, 24.510708, 24.612106], dtype=float32),\n",
              "  array([ 5.319559,  5.268231, 23.985428, 24.036083], dtype=float32),\n",
              "  array([ 5.412327 ,  5.4513144, 23.750696 , 23.766262 ], dtype=float32),\n",
              "  array([ 5.1233025,  5.0972104, 24.870275 , 24.86179  ], dtype=float32),\n",
              "  array([ 5.2420387,  5.21814  , 23.89692  , 23.962397 ], dtype=float32),\n",
              "  array([ 5.3351703,  5.4005346, 24.274403 , 24.297102 ], dtype=float32),\n",
              "  array([ 5.518938,  5.493397, 24.495615, 24.574085], dtype=float32),\n",
              "  array([ 5.6304765,  5.5650954, 23.70098  , 23.736717 ], dtype=float32),\n",
              "  array([ 5.3477106,  5.404463 , 25.127703 , 25.164997 ], dtype=float32),\n",
              "  array([ 5.4290566,  5.491986 , 23.919588 , 23.991077 ], dtype=float32),\n",
              "  array([ 5.0258217,  5.0659547, 24.591087 , 24.573612 ], dtype=float32),\n",
              "  array([ 5.5028567,  5.5123763, 23.97891  , 24.076838 ], dtype=float32),\n",
              "  array([ 5.253517,  5.342493, 24.71519 , 24.77613 ], dtype=float32),\n",
              "  array([ 5.2233977,  5.276773 , 24.546677 , 24.609165 ], dtype=float32),\n",
              "  array([ 5.302095 ,  5.3221416, 23.590519 , 23.644344 ], dtype=float32),\n",
              "  array([ 6.3048153,  6.1892056, 22.13593  , 22.356737 ], dtype=float32),\n",
              "  array([ 5.3206754,  5.2937374, 24.224548 , 24.231228 ], dtype=float32),\n",
              "  array([ 6.2914124,  6.250355 , 22.6787   , 22.789913 ], dtype=float32),\n",
              "  array([ 7.102482 ,  6.8747525, 21.910978 , 22.230667 ], dtype=float32),\n",
              "  array([ 6.7001486,  6.61748  , 22.620773 , 22.771847 ], dtype=float32),\n",
              "  array([ 5.4488463,  5.4083786, 24.529055 , 24.57648  ], dtype=float32),\n",
              "  array([ 5.5305824,  5.433955 , 23.769306 , 23.969336 ], dtype=float32),\n",
              "  array([ 5.622232,  5.470168, 23.784912, 23.952526], dtype=float32),\n",
              "  array([ 5.1462855,  5.1798735, 24.778358 , 24.76797  ], dtype=float32),\n",
              "  array([ 5.0192556,  4.992318 , 25.166138 , 25.191093 ], dtype=float32),\n",
              "  array([ 5.5497217,  5.5978894, 24.001558 , 24.008188 ], dtype=float32),\n",
              "  array([ 5.021787,  5.068895, 25.616205, 25.625446], dtype=float32),\n",
              "  array([ 5.279287 ,  5.2390227, 23.840328 , 23.866219 ], dtype=float32),\n",
              "  array([ 5.701139,  5.652182, 23.492384, 23.553707], dtype=float32),\n",
              "  array([ 5.357704,  5.275901, 23.519428, 23.573029], dtype=float32),\n",
              "  array([ 5.4365735,  5.2719264, 23.806015 , 23.95039  ], dtype=float32),\n",
              "  array([ 7.2219815,  7.1505632, 23.594719 , 23.765224 ], dtype=float32),\n",
              "  array([ 6.2584596,  6.2215705, 24.108648 , 24.185335 ], dtype=float32),\n",
              "  array([ 5.636159,  5.561056, 24.515945, 24.592325], dtype=float32),\n",
              "  array([ 6.329067 ,  6.1952295, 23.29375  , 23.447039 ], dtype=float32),\n",
              "  array([ 5.550463,  5.445706, 23.210842, 23.359043], dtype=float32),\n",
              "  array([ 5.3701916,  5.404328 , 23.962683 , 24.01125  ], dtype=float32),\n",
              "  array([ 5.399351 ,  5.3709617, 24.419044 , 24.511768 ], dtype=float32),\n",
              "  array([ 6.053913,  5.88391 , 23.028145, 23.28051 ], dtype=float32),\n",
              "  array([ 5.6731477,  5.5987544, 23.816086 , 23.909843 ], dtype=float32),\n",
              "  array([ 5.3112707,  5.3243704, 24.109562 , 24.17635  ], dtype=float32),\n",
              "  array([ 5.984268 ,  5.9561663, 23.08371  , 23.199894 ], dtype=float32),\n",
              "  array([ 5.4010487,  5.367669 , 24.224337 , 24.258764 ], dtype=float32),\n",
              "  array([ 5.741953,  5.741594, 23.361456, 23.440834], dtype=float32),\n",
              "  array([ 6.0249662,  6.016592 , 24.370975 , 24.42588  ], dtype=float32),\n",
              "  array([ 5.102677 ,  5.1405663, 24.17617  , 24.18092  ], dtype=float32),\n",
              "  array([ 5.4190083,  5.473487 , 24.634888 , 24.698076 ], dtype=float32),\n",
              "  array([ 5.3475475,  5.3118777, 24.995419 , 25.012589 ], dtype=float32),\n",
              "  array([ 5.43507  ,  5.2890368, 24.121899 , 24.293335 ], dtype=float32),\n",
              "  array([ 5.3253508,  5.3884616, 23.69331  , 23.719437 ], dtype=float32),\n",
              "  array([ 5.4050884,  5.453511 , 24.128473 , 24.141094 ], dtype=float32),\n",
              "  array([ 8.139337 ,  7.7654066, 20.175018 , 20.640167 ], dtype=float32),\n",
              "  array([ 8.153607 ,  7.8973055, 20.459911 , 20.876778 ], dtype=float32),\n",
              "  array([ 6.3285437,  6.285059 , 23.039268 , 23.176394 ], dtype=float32),\n",
              "  array([ 5.350668,  5.192781, 23.743864, 23.881413], dtype=float32),\n",
              "  array([ 5.243301,  5.354878, 24.034576, 24.032457], dtype=float32),\n",
              "  array([ 5.4850316,  5.5327234, 24.624584 , 24.672115 ], dtype=float32),\n",
              "  array([ 5.2121654,  5.2561626, 23.825531 , 23.861465 ], dtype=float32),\n",
              "  array([ 5.5587373,  5.572403 , 23.385832 , 23.424091 ], dtype=float32),\n",
              "  array([ 5.062645 ,  5.0133944, 25.08385  , 25.124065 ], dtype=float32),\n",
              "  array([ 5.4183407,  5.406747 , 24.07671  , 24.123001 ], dtype=float32),\n",
              "  array([ 5.789729 ,  5.7387605, 22.792675 , 22.874638 ], dtype=float32),\n",
              "  array([ 5.4209666,  5.4561305, 24.95406  , 25.01215  ], dtype=float32),\n",
              "  array([ 5.5097537,  5.466634 , 23.221657 , 23.343727 ], dtype=float32),\n",
              "  array([ 6.497102,  6.451641, 22.399647, 22.515831], dtype=float32),\n",
              "  array([ 5.8824267,  5.9037085, 23.469604 , 23.575302 ], dtype=float32),\n",
              "  array([ 6.1944323,  6.0739746, 23.505573 , 23.611122 ], dtype=float32),\n",
              "  array([ 5.2972984,  5.294623 , 24.762981 , 24.779783 ], dtype=float32),\n",
              "  array([ 5.4161134,  5.408312 , 23.814587 , 23.896652 ], dtype=float32),\n",
              "  array([ 5.862256,  5.742939, 23.423164, 23.619213], dtype=float32),\n",
              "  array([ 5.336803 ,  5.2281337, 23.744026 , 23.852486 ], dtype=float32),\n",
              "  array([ 5.1298904,  5.246315 , 23.720951 , 23.721115 ], dtype=float32),\n",
              "  array([ 5.4816265,  5.4952574, 23.478737 , 23.525963 ], dtype=float32),\n",
              "  array([ 5.2494307,  5.3504333, 25.0769   , 25.114597 ], dtype=float32),\n",
              "  array([ 5.359436,  5.372736, 24.398857, 24.41103 ], dtype=float32),\n",
              "  array([ 5.871528,  5.76229 , 23.473186, 23.590168], dtype=float32),\n",
              "  array([ 6.4731994,  6.417749 , 22.211447 , 22.340382 ], dtype=float32),\n",
              "  array([ 5.8880844,  5.867494 , 22.95123  , 23.016006 ], dtype=float32),\n",
              "  array([ 5.366026,  5.365675, 24.29497 , 24.363514], dtype=float32),\n",
              "  array([ 5.3081098,  5.296791 , 23.386066 , 23.438236 ], dtype=float32),\n",
              "  array([ 5.433955,  5.42945 , 24.109291, 24.136864], dtype=float32),\n",
              "  array([ 5.437976,  5.493085, 24.866096, 24.895638], dtype=float32),\n",
              "  array([ 5.4880924,  5.44841  , 23.526005 , 23.616934 ], dtype=float32),\n",
              "  array([ 6.0906763,  6.024358 , 23.303223 , 23.394676 ], dtype=float32),\n",
              "  array([ 5.327836,  5.307955, 24.677883, 24.756916], dtype=float32),\n",
              "  array([ 5.2130055,  5.270758 , 23.391212 , 23.473228 ], dtype=float32),\n",
              "  array([ 6.6656995,  6.447565 , 22.422024 , 22.67778  ], dtype=float32),\n",
              "  array([ 6.5024548,  6.348198 , 23.302813 , 23.483627 ], dtype=float32),\n",
              "  array([ 5.6418133,  5.5902925, 23.94739  , 24.003088 ], dtype=float32),\n",
              "  array([ 5.373571,  5.353639, 24.524805, 24.56372 ], dtype=float32),\n",
              "  array([ 5.619741 ,  5.6180534, 23.49974  , 23.579088 ], dtype=float32),\n",
              "  array([ 5.4190955,  5.4411073, 24.544632 , 24.573986 ], dtype=float32),\n",
              "  array([ 5.9042473,  5.853861 , 22.69611  , 22.799685 ], dtype=float32),\n",
              "  array([ 4.990125,  5.002596, 25.393436, 25.391598], dtype=float32),\n",
              "  array([ 5.999327 ,  5.8901005, 23.451906 , 23.5499   ], dtype=float32),\n",
              "  array([ 5.570874 ,  5.4301095, 24.242485 , 24.388447 ], dtype=float32),\n",
              "  array([ 5.243163,  5.283112, 24.60167 , 24.616734], dtype=float32),\n",
              "  array([ 5.81708  ,  5.8338537, 23.228745 , 23.276552 ], dtype=float32),\n",
              "  array([ 5.125548 ,  5.2447157, 24.367483 , 24.363089 ], dtype=float32),\n",
              "  array([ 5.445896,  5.35206 , 23.810741, 23.955687], dtype=float32),\n",
              "  array([ 5.3010616,  5.248435 , 23.286839 , 23.30492  ], dtype=float32),\n",
              "  array([ 5.2925234,  5.284285 , 24.538334 , 24.553566 ], dtype=float32),\n",
              "  array([ 5.1001163,  5.0089054, 24.751617 , 24.814734 ], dtype=float32),\n",
              "  array([ 5.2503414,  5.192288 , 24.446606 , 24.466866 ], dtype=float32),\n",
              "  array([ 5.324184 ,  5.2163973, 23.880268 , 23.986904 ], dtype=float32),\n",
              "  array([ 5.4958177,  5.5364904, 22.7277   , 22.75642  ], dtype=float32),\n",
              "  array([ 5.433071,  5.261137, 24.863417, 24.98877 ], dtype=float32),\n",
              "  array([ 5.310433 ,  5.3057356, 23.319275 , 23.341484 ], dtype=float32),\n",
              "  array([ 5.6120133,  5.4706078, 23.758595 , 23.962326 ], dtype=float32),\n",
              "  array([ 7.5123396,  7.1434765, 21.000067 , 21.421612 ], dtype=float32),\n",
              "  array([ 5.2661657,  5.261995 , 24.038622 , 24.07683  ], dtype=float32),\n",
              "  array([ 5.3086953,  5.3289003, 23.50766  , 23.527416 ], dtype=float32),\n",
              "  array([ 7.5238004,  7.153968 , 21.236382 , 21.626442 ], dtype=float32),\n",
              "  array([ 5.1984076,  5.1860094, 24.267841 , 24.316305 ], dtype=float32),\n",
              "  array([ 5.440545 ,  5.4500713, 23.772852 , 23.795326 ], dtype=float32),\n",
              "  array([ 5.221976 ,  5.3097444, 24.975952 , 24.94535  ], dtype=float32),\n",
              "  array([ 5.6826696,  5.7371855, 23.050934 , 23.148859 ], dtype=float32),\n",
              "  array([ 5.35062  ,  5.3322096, 24.554771 , 24.578682 ], dtype=float32),\n",
              "  array([ 5.29572  ,  5.3215475, 24.151558 , 24.184006 ], dtype=float32),\n",
              "  array([ 5.437748 ,  5.4097314, 23.78215  , 23.848122 ], dtype=float32),\n",
              "  array([ 6.358553,  6.169696, 22.513916, 22.801268], dtype=float32),\n",
              "  array([ 5.6133156,  5.5227637, 22.956238 , 23.115448 ], dtype=float32),\n",
              "  array([ 5.2813587,  5.393902 , 24.81306  , 24.814606 ], dtype=float32),\n",
              "  array([ 5.4607267,  5.455927 , 23.943281 , 23.981169 ], dtype=float32),\n",
              "  array([ 6.1861606,  6.1209707, 22.643215 , 22.728088 ], dtype=float32),\n",
              "  array([ 5.3549666,  5.356497 , 24.244144 , 24.280575 ], dtype=float32),\n",
              "  array([ 5.307895,  5.355227, 24.642849, 24.685005], dtype=float32),\n",
              "  array([ 5.642027,  5.630515, 23.949057, 24.041267], dtype=float32),\n",
              "  array([ 5.4753437,  5.4130235, 24.996622 , 25.121922 ], dtype=float32),\n",
              "  array([ 5.542507,  5.440797, 24.258415, 24.44767 ], dtype=float32),\n",
              "  array([ 6.0736103,  5.9036446, 23.129715 , 23.335709 ], dtype=float32),\n",
              "  array([ 5.388934,  5.45052 , 23.830074, 23.821346], dtype=float32),\n",
              "  array([ 5.693356,  5.57323 , 23.740726, 23.921513], dtype=float32),\n",
              "  array([ 5.388614,  5.374058, 24.503742, 24.531895], dtype=float32),\n",
              "  array([ 5.4595346,  5.4249454, 24.28798  , 24.338936 ], dtype=float32),\n",
              "  array([ 5.3197737,  5.2976027, 23.992977 , 24.006306 ], dtype=float32),\n",
              "  array([ 5.498335,  5.414571, 24.423538, 24.5774  ], dtype=float32),\n",
              "  array([ 5.220977 ,  5.2422976, 24.793564 , 24.841076 ], dtype=float32),\n",
              "  array([ 7.063607,  6.872319, 22.092422, 22.327251], dtype=float32),\n",
              "  array([ 6.2937336,  6.2509766, 23.702156 , 23.7887   ], dtype=float32),\n",
              "  array([ 6.6068363,  6.3546762, 22.417706 , 22.705265 ], dtype=float32),\n",
              "  array([ 6.768135 ,  6.7065115, 22.513315 , 22.692314 ], dtype=float32),\n",
              "  array([ 5.4884143,  5.4853935, 24.302668 , 24.330109 ], dtype=float32),\n",
              "  array([ 6.938825 ,  6.6486616, 23.838474 , 24.154205 ], dtype=float32),\n",
              "  array([ 5.2273035,  5.316184 , 24.029915 , 24.077614 ], dtype=float32),\n",
              "  array([ 5.3002224,  5.252965 , 25.074379 , 25.105116 ], dtype=float32),\n",
              "  array([ 5.117681 ,  5.0892377, 24.685734 , 24.691078 ], dtype=float32),\n",
              "  array([ 5.363751 ,  5.3359447, 23.803509 , 23.87048  ], dtype=float32),\n",
              "  array([ 5.362869 ,  5.3620334, 23.474983 , 23.538105 ], dtype=float32),\n",
              "  array([ 5.261085 ,  5.3239117, 24.528786 , 24.533081 ], dtype=float32),\n",
              "  array([ 6.3713126,  6.2872663, 23.095936 , 23.201345 ], dtype=float32),\n",
              "  array([ 5.9176483,  5.910243 , 23.5569   , 23.587788 ], dtype=float32),\n",
              "  array([ 5.495105,  5.476563, 24.5233  , 24.604704], dtype=float32),\n",
              "  array([ 5.364748,  5.414902, 23.960579, 23.981064], dtype=float32),\n",
              "  array([ 5.5446386,  5.5649924, 24.49283  , 24.535686 ], dtype=float32),\n",
              "  array([ 6.402859,  6.352474, 23.25113 , 23.401657], dtype=float32),\n",
              "  array([ 5.5445147,  5.541971 , 24.332592 , 24.332542 ], dtype=float32),\n",
              "  array([ 5.70878  ,  5.6177683, 24.283678 , 24.323128 ], dtype=float32),\n",
              "  array([ 5.4550414,  5.4666195, 22.999374 , 23.078075 ], dtype=float32),\n",
              "  array([ 5.3338265,  5.306086 , 24.942928 , 24.971739 ], dtype=float32),\n",
              "  array([ 5.106556 ,  5.1223803, 23.820421 , 23.827927 ], dtype=float32),\n",
              "  array([ 5.631299,  5.55119 , 23.955776, 24.032707], dtype=float32),\n",
              "  array([ 5.362503 ,  5.4189305, 23.660873 , 23.72084  ], dtype=float32),\n",
              "  array([ 5.3796387,  5.392217 , 25.4781   , 25.531815 ], dtype=float32),\n",
              "  array([ 5.5214415,  5.4567804, 25.091724 , 25.149529 ], dtype=float32),\n",
              "  array([ 5.204416,  5.2182  , 23.89266 , 23.938896], dtype=float32),\n",
              "  array([ 5.600178,  5.506729, 24.87825 , 24.957493], dtype=float32),\n",
              "  array([ 5.673979,  5.477825, 24.063568, 24.222847], dtype=float32),\n",
              "  array([ 5.23569 ,  5.296198, 23.8111  , 23.817986], dtype=float32),\n",
              "  array([ 5.211663,  5.213481, 24.363684, 24.375797], dtype=float32),\n",
              "  array([ 5.1496444,  5.1808066, 25.127447 , 25.122515 ], dtype=float32),\n",
              "  array([ 5.4099236,  5.330921 , 24.470253 , 24.623714 ], dtype=float32),\n",
              "  array([ 6.948264 ,  6.8008914, 21.53616  , 21.696056 ], dtype=float32),\n",
              "  array([ 5.2725024,  5.1412487, 24.800152 , 24.919498 ], dtype=float32),\n",
              "  array([ 5.59286  ,  5.5733266, 24.70757  , 24.750546 ], dtype=float32),\n",
              "  array([ 5.21073  ,  5.1383843, 24.539572 , 24.591883 ], dtype=float32),\n",
              "  array([ 5.4640856,  5.418931 , 23.854889 , 23.930492 ], dtype=float32),\n",
              "  array([ 7.7425222,  7.4491024, 20.434322 , 20.805046 ], dtype=float32),\n",
              "  array([ 5.4613705,  5.390407 , 24.744884 , 24.783386 ], dtype=float32),\n",
              "  array([ 5.267088,  5.309587, 23.300425, 23.35506 ], dtype=float32),\n",
              "  array([ 5.6668034,  5.724471 , 24.465265 , 24.487297 ], dtype=float32),\n",
              "  array([ 5.433319,  5.424908, 23.884037, 23.965855], dtype=float32),\n",
              "  array([ 6.003124 ,  5.8792424, 23.972622 , 24.104397 ], dtype=float32),\n",
              "  array([ 5.6186304,  5.5415616, 24.016571 , 24.068531 ], dtype=float32),\n",
              "  array([ 5.3387175,  5.3086343, 24.2342   , 24.260666 ], dtype=float32),\n",
              "  array([ 5.997787 ,  5.9655814, 23.936207 , 24.028606 ], dtype=float32),\n",
              "  array([ 5.8272486,  5.7206   , 23.834152 , 23.948925 ], dtype=float32),\n",
              "  array([ 5.3042793,  5.3600416, 23.82357  , 23.895355 ], dtype=float32),\n",
              "  array([ 5.1600013,  5.286196 , 24.151318 , 24.130642 ], dtype=float32),\n",
              "  array([ 5.0704494,  5.044268 , 25.017967 , 25.034595 ], dtype=float32),\n",
              "  array([ 5.293774,  5.298528, 23.560282, 23.59845 ], dtype=float32),\n",
              "  array([ 5.407609 ,  5.4532847, 24.873621 , 24.899872 ], dtype=float32),\n",
              "  array([ 6.42757  ,  6.3314934, 21.853653 , 22.021946 ], dtype=float32),\n",
              "  array([ 5.134493,  5.168986, 23.912489, 23.90923 ], dtype=float32),\n",
              "  array([ 5.375541 ,  5.3506346, 23.440659 , 23.474304 ], dtype=float32),\n",
              "  array([ 5.4021544,  5.277753 , 23.960976 , 24.119532 ], dtype=float32),\n",
              "  array([ 5.5114193,  5.49001  , 23.914162 , 23.954235 ], dtype=float32),\n",
              "  array([ 5.3474813,  5.35244  , 24.366299 , 24.385996 ], dtype=float32),\n",
              "  array([ 5.4308066,  5.401958 , 24.45624  , 24.547829 ], dtype=float32),\n",
              "  array([ 5.5928745,  5.492554 , 25.17554  , 25.24884  ], dtype=float32),\n",
              "  array([ 5.1668077,  5.220246 , 24.598696 , 24.605175 ], dtype=float32),\n",
              "  array([ 5.374923,  5.427215, 23.389793, 23.417763], dtype=float32),\n",
              "  array([ 5.3547316,  5.2316427, 24.583689 , 24.706764 ], dtype=float32),\n",
              "  array([ 5.369878 ,  5.3327127, 24.648804 , 24.661667 ], dtype=float32),\n",
              "  array([ 5.2288446,  5.194293 , 24.497564 , 24.531971 ], dtype=float32),\n",
              "  array([ 6.875522,  6.624436, 22.37712 , 22.664373], dtype=float32),\n",
              "  array([ 5.5438404,  5.505285 , 23.45644  , 23.525305 ], dtype=float32),\n",
              "  array([ 5.5989084,  5.474461 , 23.860584 , 24.022793 ], dtype=float32),\n",
              "  array([ 5.4936843,  5.4488583, 22.541145 , 22.607162 ], dtype=float32),\n",
              "  array([ 8.120237 ,  7.7893343, 20.434635 , 20.863735 ], dtype=float32),\n",
              "  array([ 5.3704944,  5.366373 , 24.333656 , 24.409676 ], dtype=float32),\n",
              "  array([ 5.5210547,  5.2826786, 24.322319 , 24.514004 ], dtype=float32),\n",
              "  array([ 5.2049665,  5.1890445, 24.56324  , 24.57367  ], dtype=float32),\n",
              "  array([ 5.3989105,  5.4344325, 23.712284 , 23.757809 ], dtype=float32),\n",
              "  array([ 5.2406354,  5.241638 , 24.861351 , 24.864456 ], dtype=float32),\n",
              "  array([ 5.212278,  5.297268, 24.186615, 24.215836], dtype=float32),\n",
              "  array([ 5.407297,  5.304238, 24.464214, 24.574286], dtype=float32),\n",
              "  array([ 5.058336 ,  5.1347666, 25.972881 , 25.975838 ], dtype=float32),\n",
              "  array([ 5.480346,  5.333209, 24.086676, 24.208744], dtype=float32),\n",
              "  array([ 5.2983675,  5.3781424, 24.141104 , 24.144695 ], dtype=float32),\n",
              "  array([ 5.384736,  5.422962, 24.379913, 24.41677 ], dtype=float32),\n",
              "  array([ 6.285958,  6.069544, 23.265244, 23.508438], dtype=float32),\n",
              "  array([ 5.5282507,  5.4039416, 23.964588 , 24.087013 ], dtype=float32),\n",
              "  array([ 5.474144 ,  5.4763527, 24.55214  , 24.579725 ], dtype=float32),\n",
              "  array([ 5.449037 ,  5.3732576, 23.618118 , 23.744251 ], dtype=float32),\n",
              "  array([ 5.5083227,  5.544625 , 23.776894 , 23.813944 ], dtype=float32),\n",
              "  array([ 5.0864096,  5.10448  , 25.047356 , 25.051971 ], dtype=float32),\n",
              "  array([ 5.2614703,  5.305384 , 24.613525 , 24.630295 ], dtype=float32),\n",
              "  array([ 5.4619503,  5.353104 , 24.697723 , 24.867863 ], dtype=float32),\n",
              "  array([ 5.395598,  5.465098, 23.73769 , 23.72754 ], dtype=float32),\n",
              "  array([ 5.3070254,  5.3733606, 24.382254 , 24.393723 ], dtype=float32),\n",
              "  array([ 5.3976383,  5.385056 , 24.575123 , 24.628597 ], dtype=float32),\n",
              "  array([ 5.3579173,  5.349632 , 24.241867 , 24.2737   ], dtype=float32),\n",
              "  array([ 5.3878193,  5.3290815, 24.942196 , 24.98751  ], dtype=float32),\n",
              "  array([ 5.578597,  5.486132, 24.220867, 24.370277], dtype=float32),\n",
              "  array([ 5.2759233,  5.3260355, 24.081034 , 24.127821 ], dtype=float32),\n",
              "  array([ 5.485018,  5.497874, 24.668987, 24.71304 ], dtype=float32),\n",
              "  array([ 5.1892776,  5.2615895, 23.979305 , 23.985918 ], dtype=float32),\n",
              "  array([ 5.287505,  5.261314, 24.262032, 24.269112], dtype=float32),\n",
              "  array([ 5.3527884,  5.336891 , 23.875328 , 23.94733  ], dtype=float32),\n",
              "  array([ 5.470002 ,  5.3839293, 25.064749 , 25.159426 ], dtype=float32),\n",
              "  array([ 5.2399077,  5.253282 , 24.424618 , 24.466745 ], dtype=float32),\n",
              "  array([ 5.3219676,  5.305567 , 24.47033  , 24.544765 ], dtype=float32),\n",
              "  array([ 5.364899 ,  5.3690352, 24.220045 , 24.224394 ], dtype=float32),\n",
              "  array([ 5.313505 ,  5.3504176, 23.958683 , 23.974133 ], dtype=float32),\n",
              "  array([ 5.1728764,  5.0415287, 23.998913 , 24.092892 ], dtype=float32),\n",
              "  array([ 5.1514153,  5.2491274, 23.89588  , 23.918505 ], dtype=float32),\n",
              "  array([ 5.1153507,  5.161951 , 24.190254 , 24.203762 ], dtype=float32),\n",
              "  array([ 5.959055 ,  5.9417877, 23.35767  , 23.421764 ], dtype=float32),\n",
              "  array([ 5.186005 ,  5.2205343, 24.563152 , 24.597881 ], dtype=float32),\n",
              "  array([ 5.1497364,  5.253225 , 24.276459 , 24.279268 ], dtype=float32),\n",
              "  array([ 6.2359805,  6.0647726, 22.886185 , 23.0933   ], dtype=float32),\n",
              "  array([ 5.3957195,  5.3668737, 24.814295 , 24.871658 ], dtype=float32),\n",
              "  array([ 6.1446285,  6.0278873, 23.31126  , 23.440458 ], dtype=float32),\n",
              "  array([ 6.095031 ,  6.0519257, 24.379086 , 24.411041 ], dtype=float32),\n",
              "  array([ 5.1925564,  5.2396207, 24.510975 , 24.505026 ], dtype=float32),\n",
              "  array([ 5.480998 ,  5.5135446, 24.929073 , 24.96833  ], dtype=float32),\n",
              "  array([ 5.3717422,  5.3434143, 24.90929  , 24.931604 ], dtype=float32),\n",
              "  array([ 5.378684 ,  5.4048343, 24.95034  , 24.97697  ], dtype=float32),\n",
              "  array([ 5.1518507,  5.2429423, 24.903688 , 24.89201  ], dtype=float32),\n",
              "  array([ 5.763804 ,  5.6679616, 23.974106 , 24.079472 ], dtype=float32),\n",
              "  array([ 5.362842,  5.307683, 24.324085, 24.351234], dtype=float32),\n",
              "  array([ 6.0424843,  5.974211 , 23.374546 , 23.46917  ], dtype=float32),\n",
              "  array([ 5.5508146,  5.448751 , 24.80638  , 24.962805 ], dtype=float32),\n",
              "  array([ 5.7106433,  5.515029 , 23.056759 , 23.268723 ], dtype=float32),\n",
              "  array([ 5.602631 ,  5.4987407, 23.798046 , 23.884298 ], dtype=float32),\n",
              "  array([ 6.437575,  6.292219, 23.327654, 23.512291], dtype=float32),\n",
              "  array([ 5.1826434,  5.190324 , 24.626482 , 24.624897 ], dtype=float32),\n",
              "  array([ 5.1935506,  5.126325 , 24.428596 , 24.460384 ], dtype=float32),\n",
              "  array([ 5.3617115,  5.3064137, 24.683632 , 24.72947  ], dtype=float32),\n",
              "  array([ 5.5156064,  5.4993205, 23.781902 , 23.847565 ], dtype=float32),\n",
              "  array([ 5.3026953,  5.304974 , 23.566166 , 23.5956   ], dtype=float32),\n",
              "  array([ 6.155244,  6.045173, 22.935158, 23.051725], dtype=float32),\n",
              "  array([ 5.124001 ,  5.1432757, 24.66894  , 24.68302  ], dtype=float32),\n",
              "  array([ 6.355049,  6.319273, 22.6282  , 22.732113], dtype=float32),\n",
              "  array([ 5.4753   ,  5.4370766, 22.534414 , 22.623344 ], dtype=float32),\n",
              "  array([ 5.3080945,  5.2115335, 24.057505 , 24.161644 ], dtype=float32),\n",
              "  array([ 5.4652123,  5.4249306, 24.391243 , 24.48196  ], dtype=float32),\n",
              "  array([ 5.4757643,  5.4753966, 24.31547  , 24.36117  ], dtype=float32),\n",
              "  array([ 5.255414 ,  5.2235913, 24.137241 , 24.168686 ], dtype=float32),\n",
              "  array([ 5.291211 ,  5.3436856, 23.183529 , 23.245434 ], dtype=float32),\n",
              "  array([ 5.9376116,  5.902276 , 22.366146 , 22.487457 ], dtype=float32),\n",
              "  array([ 5.9003243,  5.7446494, 23.815582 , 24.081074 ], dtype=float32),\n",
              "  array([ 5.3892627,  5.4092283, 24.056824 , 24.139912 ], dtype=float32),\n",
              "  array([ 5.3850255,  5.284399 , 25.50056  , 25.621529 ], dtype=float32),\n",
              "  array([ 5.5224576,  5.418094 , 23.6455   , 23.772247 ], dtype=float32),\n",
              "  array([ 5.4395814,  5.2966475, 23.763546 , 23.934422 ], dtype=float32),\n",
              "  array([ 5.304526 ,  5.3748927, 24.710247 , 24.743053 ], dtype=float32),\n",
              "  array([ 6.5976124,  6.4724927, 22.769604 , 22.935097 ], dtype=float32),\n",
              "  array([ 5.3433404,  5.4050007, 23.534508 , 23.537697 ], dtype=float32),\n",
              "  array([ 5.413348,  5.377647, 22.89658 , 22.979633], dtype=float32),\n",
              "  array([ 5.3546686,  5.355407 , 24.013733 , 24.036346 ], dtype=float32),\n",
              "  array([ 5.4096684,  5.3982153, 23.770905 , 23.847672 ], dtype=float32),\n",
              "  array([ 5.4144526,  5.3952646, 24.272095 , 24.341957 ], dtype=float32),\n",
              "  array([ 6.8508387,  6.747162 , 22.022522 , 22.176838 ], dtype=float32),\n",
              "  array([ 6.7441854,  6.5492024, 22.92347  , 23.199844 ], dtype=float32),\n",
              "  array([ 5.1505284,  5.2382317, 24.580929 , 24.556396 ], dtype=float32),\n",
              "  array([ 5.2782745,  5.2680373, 24.283741 , 24.371254 ], dtype=float32),\n",
              "  array([ 5.6782866,  5.6557612, 23.206676 , 23.262259 ], dtype=float32),\n",
              "  array([ 5.3617935,  5.3483806, 25.034187 , 25.092777 ], dtype=float32),\n",
              "  array([ 5.338971 ,  5.3053164, 23.007416 , 23.091988 ], dtype=float32),\n",
              "  array([ 7.3930154,  7.182061 , 22.096783 , 22.345577 ], dtype=float32),\n",
              "  array([ 6.8323793,  6.578581 , 22.527054 , 22.8095   ], dtype=float32),\n",
              "  array([ 6.910158 ,  6.8177314, 23.033749 , 23.222466 ], dtype=float32),\n",
              "  array([ 5.2408843,  5.192421 , 24.19517  , 24.215065 ], dtype=float32),\n",
              "  array([ 5.8838005,  5.8241477, 24.187035 , 24.268005 ], dtype=float32),\n",
              "  array([ 5.4272947,  5.45406  , 24.24527  , 24.29279  ], dtype=float32),\n",
              "  array([ 5.41549 ,  5.373859, 24.736397, 24.774303], dtype=float32),\n",
              "  array([ 7.2502165,  7.107277 , 22.523663 , 22.702166 ], dtype=float32),\n",
              "  array([ 5.583109 ,  5.5584726, 23.785866 , 23.874413 ], dtype=float32),\n",
              "  array([ 5.5379124,  5.4488444, 23.799637 , 23.862204 ], dtype=float32),\n",
              "  array([ 5.463201 ,  5.4474454, 24.463797 , 24.470577 ], dtype=float32),\n",
              "  array([ 5.4256964,  5.43745  , 23.601526 , 23.630535 ], dtype=float32),\n",
              "  array([ 5.7329884,  5.762389 , 23.520325 , 23.578083 ], dtype=float32),\n",
              "  array([ 5.347762,  5.337385, 24.659008, 24.654072], dtype=float32),\n",
              "  array([ 5.768148 ,  5.7141795, 23.825054 , 23.877832 ], dtype=float32),\n",
              "  array([ 6.526234,  6.288247, 22.857769, 23.153961], dtype=float32),\n",
              "  array([ 6.144385 ,  6.1134467, 23.151958 , 23.240292 ], dtype=float32),\n",
              "  array([ 5.436602,  5.448089, 23.864334, 23.9128  ], dtype=float32),\n",
              "  array([ 5.3934784,  5.459729 , 23.928839 , 23.997747 ], dtype=float32),\n",
              "  array([ 5.280295 ,  5.2382383, 24.135216 , 24.213049 ], dtype=float32),\n",
              "  array([ 6.87574  ,  6.7062635, 22.676233 , 22.845451 ], dtype=float32),\n",
              "  array([ 5.3404737,  5.3337474, 24.783623 , 24.853113 ], dtype=float32),\n",
              "  array([ 5.210714,  5.230887, 24.676182, 24.676136], dtype=float32),\n",
              "  array([ 5.497445,  5.479264, 25.172619, 25.230438], dtype=float32),\n",
              "  array([ 5.553492,  5.586628, 23.701672, 23.786577], dtype=float32),\n",
              "  array([ 5.9085455,  5.9356437, 23.851063 , 23.940798 ], dtype=float32),\n",
              "  array([ 5.37945  ,  5.3772945, 23.8691   , 23.897999 ], dtype=float32),\n",
              "  array([ 5.1508117,  5.1763225, 24.611893 , 24.610733 ], dtype=float32),\n",
              "  array([ 5.3306065,  5.2872105, 24.450342 , 24.498219 ], dtype=float32),\n",
              "  array([ 5.2042956,  5.1750264, 24.107315 , 24.114157 ], dtype=float32),\n",
              "  array([ 5.291494,  5.245066, 23.850754, 23.962921], dtype=float32),\n",
              "  array([ 5.4450583,  5.462883 , 24.286219 , 24.335608 ], dtype=float32),\n",
              "  array([ 6.523776,  6.359854, 23.112028, 23.29948 ], dtype=float32),\n",
              "  array([ 5.312713 ,  5.3750315, 24.09153  , 24.06834  ], dtype=float32),\n",
              "  array([ 7.177252 ,  6.9199076, 22.104908 , 22.464684 ], dtype=float32),\n",
              "  array([ 5.386261 ,  5.3367176, 25.733055 , 25.80568  ], dtype=float32),\n",
              "  array([ 5.316296 ,  5.2766857, 24.427252 , 24.504028 ], dtype=float32),\n",
              "  array([ 6.7157454,  6.56832  , 21.535305 , 21.79829  ], dtype=float32),\n",
              "  array([ 5.3230414,  5.2956753, 24.555946 , 24.594858 ], dtype=float32),\n",
              "  array([ 6.0344496,  6.026384 , 23.236492 , 23.30975  ], dtype=float32),\n",
              "  array([ 5.474549,  5.489705, 23.28682 , 23.34135 ], dtype=float32),\n",
              "  array([ 5.235792 ,  5.1995482, 24.353615 , 24.392658 ], dtype=float32),\n",
              "  array([ 5.2623315,  5.308569 , 25.151993 , 25.206131 ], dtype=float32),\n",
              "  array([ 6.637622,  6.508235, 22.80069 , 22.939812], dtype=float32),\n",
              "  array([ 5.136212,  5.257003, 24.329254, 24.364733], dtype=float32),\n",
              "  array([ 5.19943 ,  5.168614, 24.608452, 24.648281], dtype=float32),\n",
              "  array([ 6.1617727,  6.1230297, 23.13198  , 23.263042 ], dtype=float32),\n",
              "  array([ 5.352717 ,  5.3035603, 24.852814 , 24.883865 ], dtype=float32),\n",
              "  array([ 5.4793425,  5.5009665, 23.89485  , 23.951763 ], dtype=float32),\n",
              "  array([ 5.372968 ,  5.3306613, 23.519245 , 23.591064 ], dtype=float32),\n",
              "  array([ 5.211373 ,  5.2776575, 24.098288 , 24.114887 ], dtype=float32),\n",
              "  array([ 5.3571033,  5.3374   , 24.163845 , 24.236553 ], dtype=float32),\n",
              "  array([ 5.1840954,  5.202478 , 24.31931  , 24.346474 ], dtype=float32),\n",
              "  array([ 5.3930902,  5.3735194, 23.738955 , 23.80194  ], dtype=float32),\n",
              "  array([ 5.3737707,  5.317139 , 24.626823 , 24.685394 ], dtype=float32),\n",
              "  array([ 5.304573,  5.265382, 24.627525, 24.63937 ], dtype=float32),\n",
              "  array([ 7.3845615,  7.051782 , 21.072123 , 21.471487 ], dtype=float32),\n",
              "  array([ 5.1357946,  5.168702 , 24.630447 , 24.644398 ], dtype=float32),\n",
              "  array([ 5.9905844,  5.8528185, 22.979118 , 23.195705 ], dtype=float32),\n",
              "  array([ 5.1337633,  5.157278 , 23.7961   , 23.81903  ], dtype=float32),\n",
              "  array([ 6.44019 ,  6.257422, 23.639057, 23.902426], dtype=float32),\n",
              "  array([ 5.3168106,  5.201439 , 23.913565 , 24.051216 ], dtype=float32),\n",
              "  array([ 5.1838894,  5.2829766, 24.849487 , 24.807932 ], dtype=float32),\n",
              "  array([ 5.426924,  5.376279, 24.395185, 24.453217], dtype=float32),\n",
              "  array([ 5.4518604,  5.3949547, 24.47145  , 24.522476 ], dtype=float32),\n",
              "  array([ 5.4044533,  5.365038 , 24.12854  , 24.160019 ], dtype=float32),\n",
              "  array([ 5.529772,  5.372926, 24.346437, 24.48565 ], dtype=float32),\n",
              "  array([ 5.366643 ,  5.3376546, 23.751928 , 23.778044 ], dtype=float32),\n",
              "  array([ 7.630734,  7.440572, 22.0187  , 22.288193], dtype=float32),\n",
              "  array([ 5.1085625,  5.1276913, 24.742477 , 24.741114 ], dtype=float32),\n",
              "  array([ 5.285317 ,  5.2676034, 24.492031 , 24.49998  ], dtype=float32),\n",
              "  array([ 5.7593656,  5.685947 , 23.61507  , 23.679049 ], dtype=float32),\n",
              "  array([ 5.836008 ,  5.7833014, 24.354874 , 24.46431  ], dtype=float32),\n",
              "  array([ 5.53496  ,  5.5232234, 23.56977  , 23.607033 ], dtype=float32),\n",
              "  array([ 5.318555,  5.295328, 24.342346, 24.348183], dtype=float32),\n",
              "  array([ 5.3564243,  5.311573 , 23.856342 , 23.906864 ], dtype=float32),\n",
              "  array([ 6.1211095,  6.0611467, 24.261337 , 24.34929  ], dtype=float32),\n",
              "  array([ 5.09093  ,  5.1133494, 24.414217 , 24.413164 ], dtype=float32),\n",
              "  array([ 5.427028 ,  5.4088097, 23.924334 , 24.011505 ], dtype=float32),\n",
              "  array([ 5.5679636,  5.5038357, 24.845314 , 24.91772  ], dtype=float32),\n",
              "  array([ 5.458952 ,  5.2982845, 24.60073  , 24.738174 ], dtype=float32),\n",
              "  array([ 6.1622233,  6.0980363, 22.41077  , 22.511723 ], dtype=float32),\n",
              "  array([ 5.238036,  5.224802, 24.078934, 24.12714 ], dtype=float32),\n",
              "  array([ 6.0218177,  5.996562 , 22.914963 , 22.975971 ], dtype=float32),\n",
              "  array([ 5.394077,  5.407603, 24.656185, 24.67949 ], dtype=float32),\n",
              "  array([ 5.5093465,  5.4834533, 24.069416 , 24.172752 ], dtype=float32),\n",
              "  array([ 5.7473173,  5.677621 , 24.177895 , 24.245413 ], dtype=float32),\n",
              "  array([ 5.4071302,  5.3955164, 23.380268 , 23.419662 ], dtype=float32),\n",
              "  array([ 6.2259026,  6.0984516, 22.937521 , 23.073195 ], dtype=float32),\n",
              "  array([ 5.463103 ,  5.4635334, 24.52686  , 24.52496  ], dtype=float32),\n",
              "  array([ 5.2146893,  5.2155614, 24.780594 , 24.808544 ], dtype=float32),\n",
              "  array([ 5.389554 ,  5.4096045, 23.604977 , 23.622337 ], dtype=float32),\n",
              "  array([ 5.150527 ,  5.1555266, 24.432    , 24.453278 ], dtype=float32),\n",
              "  array([ 5.4423842,  5.41099  , 24.610386 , 24.662735 ], dtype=float32),\n",
              "  array([ 5.1313343,  5.1838255, 24.461676 , 24.436764 ], dtype=float32),\n",
              "  array([ 5.368379 ,  5.3439035, 24.167587 , 24.220047 ], dtype=float32),\n",
              "  array([ 5.6130266,  5.5893025, 23.251312 , 23.307571 ], dtype=float32),\n",
              "  array([ 5.5311513,  5.476319 , 24.333992 , 24.364132 ], dtype=float32),\n",
              "  array([ 5.2968144,  5.2835116, 24.384754 , 24.372852 ], dtype=float32),\n",
              "  array([ 5.293353,  5.365612, 23.93441 , 23.94931 ], dtype=float32),\n",
              "  array([ 5.3276925,  5.289034 , 24.394024 , 24.422443 ], dtype=float32),\n",
              "  array([ 5.592895,  5.555153, 23.908058, 23.992596], dtype=float32),\n",
              "  array([ 5.220528,  5.288873, 24.729988, 24.700922], dtype=float32),\n",
              "  array([ 5.419917 ,  5.4465847, 24.67062  , 24.693058 ], dtype=float32),\n",
              "  array([ 5.3218336,  5.2741456, 24.566925 , 24.60407  ], dtype=float32),\n",
              "  array([ 5.403818,  5.384124, 23.898338, 23.979956], dtype=float32),\n",
              "  array([ 6.8059254,  6.7332463, 22.733364 , 22.863785 ], dtype=float32),\n",
              "  array([ 5.2559915,  5.332199 , 23.626896 , 23.619177 ], dtype=float32),\n",
              "  array([ 7.400135,  7.166934, 22.779242, 23.11441 ], dtype=float32),\n",
              "  array([ 5.2628417,  5.247213 , 24.999155 , 25.009895 ], dtype=float32),\n",
              "  array([ 5.7246485,  5.7009044, 22.841974 , 22.909494 ], dtype=float32),\n",
              "  array([ 5.367485,  5.321275, 23.99065 , 24.042004], dtype=float32),\n",
              "  array([ 5.404084,  5.354944, 24.723495, 24.761591], dtype=float32),\n",
              "  array([ 5.606265 ,  5.5458097, 23.738937 , 23.891354 ], dtype=float32),\n",
              "  array([ 5.5126185,  5.5192976, 23.780348 , 23.880468 ], dtype=float32),\n",
              "  array([ 5.1100273,  5.1822066, 24.196953 , 24.200031 ], dtype=float32),\n",
              "  array([ 5.3550634,  5.371691 , 23.846626 , 23.943607 ], dtype=float32),\n",
              "  array([ 5.4430847,  5.342167 , 24.245796 , 24.410599 ], dtype=float32),\n",
              "  array([ 5.38321  ,  5.2302475, 24.786268 , 24.914536 ], dtype=float32),\n",
              "  array([ 5.6200914,  5.5877047, 23.33405  , 23.424953 ], dtype=float32),\n",
              "  array([ 5.3861837,  5.3480196, 24.219154 , 24.263704 ], dtype=float32),\n",
              "  array([ 5.1210246,  5.182085 , 24.197474 , 24.234089 ], dtype=float32),\n",
              "  array([ 5.3498836,  5.30388  , 23.981834 , 24.035313 ], dtype=float32),\n",
              "  array([ 6.152795,  6.001871, 23.26656 , 23.480282], dtype=float32),\n",
              "  array([ 5.2608194,  5.270527 , 23.671194 , 23.719425 ], dtype=float32),\n",
              "  array([ 7.181698 ,  7.0704784, 22.225845 , 22.433601 ], dtype=float32),\n",
              "  array([ 5.3920093,  5.3545938, 24.87077  , 24.90155  ], dtype=float32),\n",
              "  array([ 5.303978,  5.315834, 24.994041, 25.037361], dtype=float32),\n",
              "  array([ 5.2401066,  5.329897 , 23.728174 , 23.697765 ], dtype=float32),\n",
              "  array([ 5.4822307,  5.4491034, 24.738728 , 24.760818 ], dtype=float32),\n",
              "  array([ 5.497836,  5.471654, 24.839186, 24.909107], dtype=float32),\n",
              "  array([ 8.292651,  8.00801 , 21.0551  , 21.483135], dtype=float32),\n",
              "  array([ 5.310061,  5.293234, 24.497087, 24.54449 ], dtype=float32),\n",
              "  array([ 5.409291,  5.38933 , 24.824116, 24.851845], dtype=float32),\n",
              "  array([ 5.442443,  5.397056, 24.592518, 24.64366 ], dtype=float32),\n",
              "  array([ 5.7562466,  5.7596908, 24.16835  , 24.251673 ], dtype=float32),\n",
              "  array([ 5.726368,  5.645624, 22.02939 , 22.166233], dtype=float32),\n",
              "  array([ 5.370392 ,  5.3080797, 25.089722 , 25.15063  ], dtype=float32),\n",
              "  array([ 5.2866583,  5.323085 , 24.350084 , 24.356056 ], dtype=float32),\n",
              "  array([ 6.73628  ,  6.6773047, 22.281094 , 22.436855 ], dtype=float32),\n",
              "  array([ 5.425246,  5.339949, 24.694782, 24.829405], dtype=float32),\n",
              "  array([ 5.6794643,  5.627546 , 23.588207 , 23.751305 ], dtype=float32),\n",
              "  array([ 6.4064217,  6.3124847, 21.74554  , 21.975674 ], dtype=float32),\n",
              "  array([ 5.0045  ,  4.989139, 25.471134, 25.473553], dtype=float32),\n",
              "  array([ 5.203222 ,  5.2696023, 25.361591 , 25.358444 ], dtype=float32),\n",
              "  array([ 5.3778534,  5.4013844, 24.677494 , 24.685192 ], dtype=float32),\n",
              "  array([ 7.2491007,  6.9977818, 21.45801  , 21.764168 ], dtype=float32),\n",
              "  array([ 5.4725137,  5.475154 , 24.055687 , 24.054148 ], dtype=float32),\n",
              "  array([ 5.0190063,  5.020835 , 24.779041 , 24.784348 ], dtype=float32),\n",
              "  array([ 5.50358 ,  5.449276, 24.305737, 24.37711 ], dtype=float32),\n",
              "  array([ 7.1003513,  6.9330177, 22.002705 , 22.236305 ], dtype=float32),\n",
              "  array([ 7.627251,  7.399681, 21.508173, 21.86995 ], dtype=float32),\n",
              "  array([ 5.29906  ,  5.2891383, 23.844032 , 23.880133 ], dtype=float32),\n",
              "  array([ 5.651456,  5.686593, 23.791542, 23.86953 ], dtype=float32),\n",
              "  array([ 5.552836 ,  5.5933127, 24.755955 , 24.814558 ], dtype=float32),\n",
              "  array([ 5.5150213,  5.511361 , 24.52144  , 24.515274 ], dtype=float32),\n",
              "  array([ 7.8438253,  7.540494 , 20.08664  , 20.455322 ], dtype=float32),\n",
              "  array([ 5.1559696,  5.17711  , 24.210346 , 24.215267 ], dtype=float32),\n",
              "  array([ 5.4875364,  5.4607673, 24.069515 , 24.104626 ], dtype=float32),\n",
              "  array([ 6.61686  ,  6.5530443, 22.30789  , 22.46363  ], dtype=float32),\n",
              "  array([ 7.6918154,  7.3467073, 21.41257  , 21.784893 ], dtype=float32),\n",
              "  array([ 5.632472,  5.463879, 23.633251, 23.795017], dtype=float32),\n",
              "  array([ 5.126161,  5.182321, 24.315575, 24.315212], dtype=float32),\n",
              "  array([ 5.5850654,  5.6513524, 24.067677 , 24.12978  ], dtype=float32),\n",
              "  array([ 5.993425 ,  5.8377676, 22.501892 , 22.688934 ], dtype=float32),\n",
              "  array([ 5.32011 ,  5.305855, 23.590431, 23.601305], dtype=float32),\n",
              "  array([ 5.489098 ,  5.3818574, 23.818192 , 23.968426 ], dtype=float32),\n",
              "  array([ 5.2830944,  5.2242594, 24.557678 , 24.585354 ], dtype=float32),\n",
              "  array([ 5.32387  ,  5.3515778, 25.02023  , 25.02877  ], dtype=float32),\n",
              "  array([ 5.4333344,  5.466181 , 23.265694 , 23.282236 ], dtype=float32),\n",
              "  array([ 5.3986406,  5.3677483, 23.626081 , 23.672398 ], dtype=float32),\n",
              "  array([ 6.9311714,  6.817398 , 22.13882  , 22.327576 ], dtype=float32),\n",
              "  array([ 5.6974974,  5.6653023, 23.788347 , 23.866829 ], dtype=float32),\n",
              "  array([ 5.4232464,  5.3762574, 24.491358 , 24.530624 ], dtype=float32),\n",
              "  array([ 6.0320086,  6.0597715, 24.591928 , 24.664705 ], dtype=float32),\n",
              "  array([ 7.563078 ,  7.3259125, 21.376318 , 21.718576 ], dtype=float32),\n",
              "  array([ 6.4764357,  6.4121   , 22.70259  , 22.835867 ], dtype=float32),\n",
              "  array([ 5.139331,  5.188886, 24.737654, 24.71835 ], dtype=float32),\n",
              "  array([ 5.3569584,  5.3359265, 24.000362 , 24.0661   ], dtype=float32),\n",
              "  array([ 5.56316 ,  5.580324, 24.430077, 24.451458], dtype=float32),\n",
              "  array([ 7.322506,  7.088333, 22.04794 , 22.378826], dtype=float32),\n",
              "  array([ 5.3407974,  5.3323903, 24.352098 , 24.425993 ], dtype=float32),\n",
              "  array([ 5.4569125,  5.475346 , 23.939903 , 23.985434 ], dtype=float32),\n",
              "  array([ 5.331827,  5.338152, 24.172073, 24.213667], dtype=float32),\n",
              "  array([ 5.2894783,  5.258746 , 24.058157 , 24.077133 ], dtype=float32),\n",
              "  array([ 5.286763 ,  5.2604065, 24.036524 , 24.05296  ], dtype=float32),\n",
              "  array([ 6.0851107,  5.856234 , 23.084557 , 23.32928  ], dtype=float32),\n",
              "  array([ 5.7434826,  5.7715945, 23.922165 , 23.994469 ], dtype=float32),\n",
              "  array([ 5.389632,  5.404712, 24.896873, 24.964317], dtype=float32),\n",
              "  array([ 5.0475388,  4.9531336, 24.492943 , 24.556572 ], dtype=float32),\n",
              "  array([ 8.162384,  7.792182, 20.146196, 20.61075 ], dtype=float32),\n",
              "  array([ 6.009752,  5.963155, 22.33425 , 22.459225], dtype=float32),\n",
              "  array([ 5.854955 ,  5.6850834, 23.483051 , 23.656761 ], dtype=float32),\n",
              "  array([ 5.5189433,  5.486504 , 24.525303 , 24.569504 ], dtype=float32),\n",
              "  array([ 6.4846573,  6.4460297, 23.305779 , 23.455074 ], dtype=float32),\n",
              "  array([ 5.609306,  5.568202, 24.174353, 24.220451], dtype=float32),\n",
              "  array([ 5.377059,  5.351726, 24.363304, 24.394482], dtype=float32),\n",
              "  array([ 5.549492 ,  5.4663706, 23.833927 , 23.918419 ], dtype=float32),\n",
              "  array([ 5.559368,  5.474263, 23.76846 , 23.867779], dtype=float32),\n",
              "  array([ 5.728815 ,  5.6871295, 23.362526 , 23.415081 ], dtype=float32),\n",
              "  array([ 5.0835896,  5.233514 , 23.389496 , 23.358252 ], dtype=float32),\n",
              "  array([ 5.7234154,  5.6358633, 23.789532 , 23.927086 ], dtype=float32),\n",
              "  array([ 5.270608 ,  5.2438154, 24.173933 , 24.176052 ], dtype=float32),\n",
              "  array([ 5.2610445,  5.2506466, 24.622425 , 24.636658 ], dtype=float32),\n",
              "  array([ 5.1837177,  5.060903 , 25.324524 , 25.419813 ], dtype=float32),\n",
              "  array([ 5.543224,  5.52986 , 23.009354, 23.063602], dtype=float32),\n",
              "  array([ 5.434624,  5.443925, 23.94043 , 23.964096], dtype=float32),\n",
              "  array([ 5.529789 ,  5.4945235, 23.268848 , 23.396969 ], dtype=float32),\n",
              "  array([ 5.7395744,  5.557883 , 23.036942 , 23.206383 ], dtype=float32),\n",
              "  array([ 5.24492  ,  5.3353963, 24.373756 , 24.371183 ], dtype=float32),\n",
              "  array([ 5.2628093,  5.262044 , 24.242668 , 24.29803  ], dtype=float32),\n",
              "  array([ 6.0828676,  5.95222  , 21.25662  , 21.426952 ], dtype=float32),\n",
              "  array([ 5.312644 ,  5.3497725, 23.923634 , 23.926113 ], dtype=float32),\n",
              "  array([ 5.4316654,  5.3646936, 24.625349 , 24.690315 ], dtype=float32),\n",
              "  array([ 5.570539 ,  5.3578463, 23.681866 , 23.838736 ], dtype=float32),\n",
              "  array([ 5.400391,  5.386005, 23.803131, 23.882706], dtype=float32),\n",
              "  array([ 5.2310543,  5.3493204, 24.440525 , 24.462042 ], dtype=float32),\n",
              "  array([ 6.5639176,  6.5262027, 22.484875 , 22.635431 ], dtype=float32),\n",
              "  array([ 5.4219923,  5.385418 , 25.238495 , 25.261232 ], dtype=float32),\n",
              "  array([ 6.6832376,  6.456045 , 21.600698 , 21.864433 ], dtype=float32),\n",
              "  array([ 5.392876,  5.371754, 23.394451, 23.43715 ], dtype=float32),\n",
              "  array([ 5.4898705,  5.388586 , 24.047575 , 24.159286 ], dtype=float32),\n",
              "  array([ 5.9851675,  5.887602 , 23.878963 , 24.000011 ], dtype=float32),\n",
              "  array([ 5.5656137,  5.501961 , 24.205612 , 24.277485 ], dtype=float32),\n",
              "  array([ 5.248728 ,  5.3330193, 24.785076 , 24.800758 ], dtype=float32),\n",
              "  array([ 5.375718 ,  5.3304033, 24.021624 , 24.118515 ], dtype=float32),\n",
              "  array([ 5.325872,  5.292794, 24.966352, 25.00053 ], dtype=float32),\n",
              "  array([ 5.807338,  5.795714, 23.957561, 23.974289], dtype=float32),\n",
              "  array([ 5.5543733,  5.436428 , 24.785772 , 24.935772 ], dtype=float32),\n",
              "  array([ 5.390123,  5.376562, 24.305107, 24.391544], dtype=float32),\n",
              "  array([ 5.345811,  5.400646, 23.65755 , 23.678062], dtype=float32),\n",
              "  array([ 5.8818645,  5.620118 , 23.170765 , 23.417599 ], dtype=float32),\n",
              "  array([ 6.0298233,  5.969549 , 22.938105 , 23.024948 ], dtype=float32),\n",
              "  array([ 5.097191 ,  5.1496816, 24.047237 , 24.049812 ], dtype=float32),\n",
              "  array([ 5.4777527,  5.452778 , 24.231026 , 24.27521  ], dtype=float32),\n",
              "  array([ 5.336502,  5.281661, 24.772955, 24.795918], dtype=float32),\n",
              "  array([ 5.157233,  5.256981, 23.062328, 23.067184], dtype=float32),\n",
              "  array([ 5.2104945,  5.285165 , 24.696701 , 24.715038 ], dtype=float32),\n",
              "  array([ 5.142478,  5.109466, 24.905836, 24.915997], dtype=float32),\n",
              "  array([ 5.520215 ,  5.4982343, 23.640022 , 23.680397 ], dtype=float32),\n",
              "  array([ 5.419539,  5.465574, 24.951965, 25.000004], dtype=float32),\n",
              "  array([ 5.3882823,  5.396046 , 24.15614  , 24.189892 ], dtype=float32),\n",
              "  array([ 7.0716333,  6.8229036, 22.391512 , 22.739838 ], dtype=float32),\n",
              "  array([ 5.365089 ,  5.1974826, 24.843658 , 24.96819  ], dtype=float32),\n",
              "  array([ 5.3830757,  5.335917 , 24.261465 , 24.29931  ], dtype=float32),\n",
              "  array([ 5.221875,  5.299408, 24.540817, 24.508612], dtype=float32),\n",
              "  array([ 5.4899464,  5.440615 , 23.923912 , 23.976192 ], dtype=float32),\n",
              "  array([ 5.701223 ,  5.7140017, 23.320799 , 23.369705 ], dtype=float32),\n",
              "  array([ 6.5377107,  6.31062  , 22.9141   , 23.17532  ], dtype=float32),\n",
              "  array([ 5.308422 ,  5.3568134, 24.236626 , 24.28439  ], dtype=float32),\n",
              "  array([ 5.2744646,  5.2879925, 24.33979  , 24.4044   ], dtype=float32),\n",
              "  array([ 5.375042 ,  5.4578714, 24.359394 , 24.390228 ], dtype=float32),\n",
              "  array([ 5.1541724,  5.1937265, 25.223022 , 25.215544 ], dtype=float32),\n",
              "  array([ 6.275634,  6.145802, 23.423698, 23.561218], dtype=float32),\n",
              "  array([ 5.584471,  5.621385, 24.301735, 24.374329], dtype=float32),\n",
              "  array([ 5.5806346,  5.5676913, 23.521746 , 23.609423 ], dtype=float32),\n",
              "  array([ 5.78869 ,  5.622895, 23.273563, 23.502151], dtype=float32),\n",
              "  array([ 5.6213865,  5.5569444, 23.487606 , 23.57137  ], dtype=float32),\n",
              "  array([ 5.2389393,  5.0662055, 24.872837 , 24.98519  ], dtype=float32),\n",
              "  array([ 5.3931346,  5.371815 , 24.531845 , 24.583397 ], dtype=float32),\n",
              "  array([ 5.858933 ,  5.7418594, 23.870922 , 23.983406 ], dtype=float32),\n",
              "  array([ 5.321908,  5.190864, 24.987976, 25.091713], dtype=float32),\n",
              "  array([ 6.0393543,  6.0152197, 23.20243  , 23.28353  ], dtype=float32),\n",
              "  array([ 5.1628633,  5.266262 , 25.250725 , 25.195707 ], dtype=float32),\n",
              "  array([ 5.30822  ,  5.3830624, 24.236147 , 24.274837 ], dtype=float32),\n",
              "  array([ 5.280122 ,  5.2689047, 23.86531  , 23.874516 ], dtype=float32),\n",
              "  array([ 5.273046 ,  5.2535653, 24.774685 , 24.862495 ], dtype=float32),\n",
              "  array([ 5.4339566,  5.3199716, 24.793316 , 24.918674 ], dtype=float32),\n",
              "  array([ 5.3572206,  5.340576 , 24.819695 , 24.85981  ], dtype=float32),\n",
              "  array([ 6.585331 ,  6.4455214, 22.779675 , 22.917902 ], dtype=float32),\n",
              "  array([ 6.4328194,  6.380246 , 22.595688 , 22.722597 ], dtype=float32),\n",
              "  array([ 5.0491633,  5.0708365, 24.855408 , 24.846327 ], dtype=float32),\n",
              "  array([ 5.4523044,  5.4520717, 22.953331 , 23.007889 ], dtype=float32),\n",
              "  array([ 5.428384 ,  5.4357634, 23.63699  , 23.671944 ], dtype=float32),\n",
              "  array([ 5.9811983,  5.9175315, 23.617632 , 23.69927  ], dtype=float32),\n",
              "  array([ 5.31049 ,  5.343858, 23.922972, 23.942242], dtype=float32),\n",
              "  array([ 5.524144,  5.499896, 24.660519, 24.706264], dtype=float32),\n",
              "  array([ 5.493881,  5.45422 , 24.312153, 24.353   ], dtype=float32),\n",
              "  array([ 5.2374234,  5.2733564, 24.03243  , 24.013527 ], dtype=float32),\n",
              "  array([ 7.0783854,  6.891634 , 22.617325 , 22.850456 ], dtype=float32),\n",
              "  array([ 5.4465027,  5.437898 , 24.30288  , 24.375744 ], dtype=float32),\n",
              "  array([ 5.9599695,  5.9758635, 23.783485 , 23.850592 ], dtype=float32),\n",
              "  array([ 5.1817102,  5.1947136, 24.121422 , 24.169813 ], dtype=float32),\n",
              "  array([ 6.7556314,  6.472023 , 22.092754 , 22.390862 ], dtype=float32),\n",
              "  array([ 5.7650895,  5.762164 , 24.405197 , 24.460352 ], dtype=float32),\n",
              "  array([ 6.0452256,  5.9388237, 22.769089 , 22.87336  ], dtype=float32),\n",
              "  array([ 5.3333664,  5.323074 , 24.352917 , 24.377766 ], dtype=float32),\n",
              "  array([ 5.8523035,  5.7634754, 23.304321 , 23.408352 ], dtype=float32),\n",
              "  array([ 6.5469894,  6.508954 , 22.32021  , 22.4449   ], dtype=float32),\n",
              "  array([ 5.392353 ,  5.3752365, 24.158606 , 24.204641 ], dtype=float32),\n",
              "  array([ 6.0567627,  6.001627 , 22.644745 , 22.740376 ], dtype=float32),\n",
              "  array([ 5.4540963,  5.285875 , 24.359837 , 24.482647 ], dtype=float32),\n",
              "  array([ 5.10948 ,  5.146269, 24.942472, 24.943012], dtype=float32),\n",
              "  array([ 5.2532973,  5.246293 , 24.256859 , 24.276546 ], dtype=float32),\n",
              "  array([ 5.3032722,  5.1667457, 25.230934 , 25.329311 ], dtype=float32),\n",
              "  array([ 5.2287393,  5.213751 , 23.691305 , 23.678738 ], dtype=float32),\n",
              "  array([ 5.7471385,  5.6453824, 24.608234 , 24.68412  ], dtype=float32),\n",
              "  array([ 5.340131,  5.352403, 23.705269, 23.783646], dtype=float32),\n",
              "  array([ 7.4815717,  7.138914 , 22.133972 , 22.507725 ], dtype=float32),\n",
              "  array([ 5.237555,  5.226432, 23.91041 , 23.955742], dtype=float32),\n",
              "  array([ 5.2906165,  5.3175116, 24.611546 , 24.683105 ], dtype=float32),\n",
              "  array([ 5.4797273,  5.4512787, 23.678036 , 23.766655 ], dtype=float32),\n",
              "  array([ 5.2839956,  5.2900457, 24.159122 , 24.203302 ], dtype=float32),\n",
              "  array([ 5.8725843,  5.7513175, 23.127914 , 23.293156 ], dtype=float32),\n",
              "  array([ 5.1182127,  5.212238 , 24.070454 , 24.091492 ], dtype=float32),\n",
              "  array([ 6.144812 ,  6.1541576, 24.213348 , 24.300274 ], dtype=float32),\n",
              "  array([ 5.0158496,  5.0524836, 24.383512 , 24.356289 ], dtype=float32),\n",
              "  ...])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('/content/Data/Test.csv')\n",
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WII_50U0p_U",
        "outputId": "fdae59c5-93ec-45b5-f25b-07c03a4d419d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
            "0         53      54       6       5      48      49       16  Test/00000.png\n",
            "1         42      45       5       5      36      40        1  Test/00001.png\n",
            "2         48      52       6       6      43      47       38  Test/00002.png\n",
            "3         27      29       5       5      22      24       33  Test/00003.png\n",
            "4         60      57       5       5      55      52       11  Test/00004.png\n",
            "...      ...     ...     ...     ...     ...     ...      ...             ...\n",
            "12625     42      41       5       6      37      36       12  Test/12625.png\n",
            "12626     50      51       6       5      45      46       33  Test/12626.png\n",
            "12627     29      29       6       6      24      24        6  Test/12627.png\n",
            "12628     48      49       5       6      43      44        7  Test/12628.png\n",
            "12629     32      31       6       5      27      26       10  Test/12629.png\n",
            "\n",
            "[12630 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for itr in range(0, 10) :\n",
        "  final_fun_1(test_df.iloc[itr])\n"
      ],
      "metadata": {
        "id": "wi9VgWpT8t4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from sklearn.metrics import f1_score, mean_squared_error\n",
        "def final_fun_1(image_path) :\n",
        "    actual_label = image_path[6]\n",
        "    image_path = image_path[7]\n",
        "    label = evaluate_test_images(image_path, model)\n",
        "    #image = Image.open(image_path)\n",
        "    coutor = np.array(label[1])\n",
        "    image = cv2.imread('/content/Data' + '/' + image_path)\n",
        "    x1 = coutor[0][0]\n",
        "    y1 = coutor[0][1]\n",
        "    x2 = coutor[0][2]\n",
        "    y2 = coutor[0][3]\n",
        "    start = (x1,y1)\n",
        "    end = (x2,y2)\n",
        "    # Blue color in BGR\n",
        "    color = (255, 0, 0)\n",
        "  \n",
        "    # Line thickness of 2 px\n",
        "    thickness = 1\n",
        "    image = cv2.rectangle(image, start, end, color, thickness)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    print(\"Predicted Label : {0}\".format(label[0]))\n",
        "    print(\"Actual Label : {0}\".format(actual_label-1))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "mFZFrxIO82Q_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}